{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\Layout\\Horizon_and_SAM\\Horizon\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#abspath = os.path.abspath(__file__)\n",
    "#dname = os.path.dirname(abspath)\n",
    "#os.chdir(dname)\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "#sys.path.append('../file_helper.py')\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "from model import *\n",
    "from file_helper import *\n",
    "\n",
    "# DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#EVAL_NAME= \"faster_rcnn_ep60_test_1k_0107\"\n",
    "EVAL_NAME= \"___Test\"\n",
    "writer = SummaryWriter(EVAL_NAME)\n",
    "\n",
    "from train import *\n",
    "from PE_helper import *\n",
    "\n",
    "transform = T.Compose([\n",
    "        transforms.Resize((512, 1024)),\n",
    "        T.ToTensor(),  # convert PIL image to PyTorch tensor\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # normalize image\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uv_to_box(u,v):\n",
    "    return np.array([u[0],v[0] , u[1],v[2] , u[1],v[3],u[0],v[1]]).reshape(-1,2)    \n",
    "\n",
    "def split_cross_boundary_bbox (bbox , w = 2048 ):\n",
    "    results= []\n",
    "    bbox = bbox.flatten()\n",
    "    max_gt = np.max(bbox.flatten())    \n",
    "    if(max_gt>w):\n",
    "        results.append(np.array([bbox[0]  ,bbox[1]  , w , bbox[1] , w , bbox[5] , bbox[0] , bbox[5]]))  \n",
    "        results.append(np.array([0  ,bbox[1]  , bbox[2]%w , bbox[1] , bbox[2]%w , bbox[5] , 0,bbox[5]]))  \n",
    "    else:\n",
    "        results = [bbox]\n",
    "    pass\n",
    "    #results = np.array(results)\n",
    "    return results\n",
    "def xyxy_to_bbox_polygon(xyxy):\n",
    "    return np.array([xyxy[0] ,xyxy[1] , xyxy[2],xyxy[1] , xyxy[2],xyxy[3] , xyxy[0] , xyxy[3]  ]).reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anno loaded  6249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 22/3125 [00:08<19:01,  2.72it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_43700\\2221127225.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0mmodel_2cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_2cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0map_05\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdo_eval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_2cls\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdata_loader_test\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mprediction_output_folder\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[0mbest_model_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"model_path\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"ap@0.5\"\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0map_05\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_43700\\2221127225.py\u001b[0m in \u001b[0;36mdo_eval\u001b[1;34m(model, data_loader, run_name, prediction_output_folder, show_plt)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m             \u001b[0miou_list\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0meval_helper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_batch_pr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_bbox_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgt_seg_mask\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m             \u001b[1;31m#  Append IoU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mpredict_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'iou'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miou_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Projects\\Layout\\Faster_Rcnn\\PE_helper.py\u001b[0m in \u001b[0;36meval_batch_pr\u001b[1;34m(self, predict_result, gt, score, _debug_iteration)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0miou_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_iou_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredict_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m         \u001b[0mpred_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Projects\\Layout\\Faster_Rcnn\\PE_helper.py\u001b[0m in \u001b[0;36mget_iou_matrix_pixel_level\u001b[1;34m(gts, preds)\u001b[0m\n\u001b[0;32m    185\u001b[0m                         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                                 \u001b[0mintersect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m                                 \u001b[0munion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount_nonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m                                 \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munion\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m                                         \u001b[0miou\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#dataset_test = ZillowDataset(transforms=transform , anno_path= '../anno/test_visiable_10.json' )\n",
    "dataset_test = ZillowDataset(transforms=transform , anno_path= '../anno/test_visiable_all.json' )\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=3, shuffle=False, num_workers=0  , collate_fn = collate_fn )\n",
    "\n",
    "pt_path = os.path.join(os.getcwd() , \"checkpoints\",\"ep60.pth\")\n",
    "model_2cls.load_state_dict(torch.load(pt_path))    \n",
    "model_2cls = model_2cls.to('cuda')\n",
    "\n",
    "prediction_output_folder = create_folder(os.path.join(os.getcwd() , \"eval\"))\n",
    "def do_eval(model , data_loader , run_name , prediction_output_folder , show_plt = False):    \n",
    "\n",
    "    output_file_path = os.path.join(prediction_output_folder , f\"eval_{run_name}.json\")\n",
    "    model.eval()\n",
    "    # create new eval helper object\n",
    "    writer = SummaryWriter(run_name)\n",
    "    eval_helper = PR_Eval_Helper(get_iou_fn = get_iou_matrix_pixel_level , writer= writer)\n",
    "\n",
    "    # record file to write\n",
    "    prediction_outputs = {\"data\":[]}\n",
    "\n",
    "    for data in tqdm(data_loader):\n",
    "        img_b , anno_b = data\n",
    "        anno_b_list = anno_to_list(anno_b)        \n",
    "        output = model(img_b , anno_b_list)\n",
    "\n",
    "        for img , out , gt in zip(img_b , output, anno_b):\n",
    "            predict_out= {\"image\": gt['image_file']  , \"pred\": [] , \"iou\":[] }\n",
    "            gt_seg_mask =[]\n",
    "            out_bbox_mask=[]\n",
    "            '''\n",
    "            #==============================\n",
    "            #           Debug\n",
    "            #==============================\n",
    "            # Pred\n",
    "            debug_img =  debug_draw_bbox(img, out['boxes'].detach().cpu().numpy() , normalize=False)\n",
    "            plt.imshow(debug_img)\n",
    "            plt.show()\n",
    "            \n",
    "            # GT\n",
    "            debug_img =  debug_draw_bbox(img, gt['boxes'].detach().cpu().numpy() , normalize=False , color=(0,0,255))\n",
    "            plt.imshow(debug_img)\n",
    "            plt.show()\n",
    "            '''\n",
    "\n",
    "            h,w = img.shape[-2:]\n",
    "            gt_u , gt_v = torch.as_tensor(gt['u']) , torch.as_tensor(gt['v'])\n",
    "            \n",
    "            #============================\n",
    "            #     Pred Bbox iou                    \n",
    "            #============================            \n",
    "            for box in out['boxes']:   \n",
    "                predict_out['pred'].append(box.detach().cpu().numpy().tolist())\n",
    "                door_parts = split_cross_boundary_bbox(xyxy_to_bbox_polygon(box.detach().cpu().numpy()) , w=w)            \n",
    "                \n",
    "                _mask_canvas = np.zeros((h,w))\n",
    "                for debug_door_part in door_parts:            \n",
    "                    debug_door_part = debug_door_part.reshape(-1,2)\n",
    "\n",
    "                    mask = cv2.fillPoly(_mask_canvas , [np.int32(debug_door_part )]  , (255,255,255) )\n",
    "                    '''\n",
    "                    '''\n",
    "                    if show_plt:\n",
    "                        plt.imshow(mask)\n",
    "                        plt.show()\n",
    "                    out_bbox_mask.append(mask)\n",
    "                pass\n",
    "\n",
    "            #============================\n",
    "            #     GT Seg\n",
    "            #============================\n",
    "            gt_seg_u =  gt_u\n",
    "            gt_seg_vt = gt_v.flatten()[::2].view(-1,2)\n",
    "            gt_seg_vb = gt_v.flatten()[1::2].view(-1,2)\n",
    "            for u,vt,vb in zip(gt_seg_u , gt_seg_vt , gt_seg_vb):\n",
    "                polys , mask = to_distorted_box([u] , [vt] , [vb] , h=h , w = w , show_plt=show_plt , seg_count=5)            \n",
    "                mask= np.max(mask,axis=2)\n",
    "                gt_seg_mask.append(mask)\n",
    "            \n",
    "            \n",
    "            iou_list =  eval_helper.eval_batch_pr(out_bbox_mask,gt_seg_mask ,None )\n",
    "            #  Append IoU\n",
    "            predict_out['iou'] = iou_list\n",
    "            if show_plt:\n",
    "                print(\"iou_list \" , iou_list  )\n",
    "            prediction_outputs['data'].append(predict_out)\n",
    "\n",
    "    mIou = eval_helper.get_all_pr( show_plt = show_plt)\n",
    "    print(\"auc@0.5\" , eval_helper.final_result_dict[1]['ap'])\n",
    "\n",
    "    if show_plt:\n",
    "        print(\"predict_out\" , prediction_outputs)\n",
    "\n",
    "    prediction_outputs[\"mIou\"]   =  mIou.astype(float)\n",
    "    prediction_outputs[\"ap@0.05\"]   =  eval_helper.final_result_dict[0]['ap']\n",
    "    prediction_outputs[\"ap@0.5\"]    =  eval_helper.final_result_dict[1]['ap']\n",
    "    prediction_outputs[\"ap@0.75\"]   =  eval_helper.final_result_dict[2]['ap']\n",
    "    prediction_outputs[\"recall@0.05\"]   =  eval_helper.final_result_dict[0]['recall_rate']\n",
    "    prediction_outputs[\"recall@0.5\"]    =  eval_helper.final_result_dict[1]['recall_rate']\n",
    "    prediction_outputs[\"recall@0.75\"]   =  eval_helper.final_result_dict[2]['recall_rate']\n",
    "    prediction_outputs[\"precision@0.05\"]    =  eval_helper.final_result_dict[0]['precision_rate']\n",
    "    prediction_outputs[\"precision@0.5\"]     =  eval_helper.final_result_dict[1]['precision_rate']\n",
    "    prediction_outputs[\"precision@0.75\"]    =  eval_helper.final_result_dict[2]['precision_rate']\n",
    "\n",
    "    json_object = json.dumps(prediction_outputs) \n",
    "    with open( output_file_path , \"w\" ) as f :\n",
    "        f.write(json_object)\n",
    "        pass\n",
    "\n",
    "    return eval_helper.final_result_dict[1]['ap']\n",
    "\n",
    "#model_folder = os.path.join(os.getcwd() , \"checkpoints\" , \"ToDo_eval_folder\")   # ToDo: set folder\n",
    "model_folder = \"E:/OneDrive - NTHU/Layout/Faster_Rcnn/Lab_0126_for_eval/train_10k_final-4-start_ep60\"\n",
    "model_files = get_files_with_prefix(model_folder , \"\")\n",
    "\n",
    "best_ap = 0\n",
    "best_mode_path =\"\"\n",
    "best_model_list =  []\n",
    "for model_path in model_files:\n",
    "    model_2cls.load_state_dict(torch.load(model_path))    \n",
    "    model_2cls = model_2cls.to('cuda')\n",
    "\n",
    "    ap_05 = do_eval(model_2cls , data_loader_test , os.path.basename(model_path) , prediction_output_folder , False)\n",
    "\n",
    "    best_model_list.append({\"model_path\": model_path , \"ap@0.5\" : ap_05})\n",
    "    if best_ap < ap_05:\n",
    "        best_ap = ap_05\n",
    "        best_mode_path = model_path\n",
    "    \n",
    "print(\"best model\" , best_mode_path)\n",
    "print(\"best ap \" , best_ap)\n",
    "\n",
    "json_object = json.dumps(best_model_list) \n",
    "output_file_path = os.path.join(os.getcwd() , \"eval\" , \"model_performance_list.json\")\n",
    "with open( output_file_path , \"w\" ) as f :\n",
    "    f.write(json_object)\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Layout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
