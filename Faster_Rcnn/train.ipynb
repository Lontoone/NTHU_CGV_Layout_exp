{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import *\n",
    "from tqdm import tqdm\n",
    "from model import *\n",
    "from file_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anno loaded  200\n",
      "anno loaded  20\n",
      "anno loaded  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [02:04<00:00,  6.22s/it]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "100%|██████████| 20/20 [02:03<00:00,  6.16s/it]\n",
      "100%|██████████| 20/20 [02:03<00:00,  6.19s/it]\n",
      "100%|██████████| 20/20 [02:12<00:00,  6.62s/it]\n",
      "100%|██████████| 20/20 [02:17<00:00,  6.89s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.02s/it]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      " 20%|██        | 1/5 [00:00<00:01,  3.02it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      " 40%|████      | 2/5 [00:00<00:01,  2.96it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      " 60%|██████    | 3/5 [00:01<00:00,  2.91it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      " 80%|████████  | 4/5 [00:01<00:00,  2.88it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "100%|██████████| 5/5 [00:01<00:00,  2.88it/s]\n",
      "100%|██████████| 20/20 [02:15<00:00,  6.75s/it]\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      " 45%|████▌     | 9/20 [02:07<02:35, 14.18s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_56476\\2017847215.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    234\u001b[0m     '''\n\u001b[0;32m    235\u001b[0m     '''\n\u001b[1;32m--> 236\u001b[1;33m     \u001b[0mtrain_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_2cls\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_eppch\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdata_loader_train\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlog_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m     \u001b[0mtrain_eppch\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_56476\\2017847215.py\u001b[0m in \u001b[0;36mtrain_fn\u001b[1;34m(model, optimizer, epoch, data_loader, log_folder)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mwrite_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'train'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    250\u001b[0m                  \u001b[0mfused\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fused'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                  \u001b[0mgrad_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                  found_inf=found_inf)\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    314\u001b[0m          \u001b[0mdifferentiable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdifferentiable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m          \u001b[0mgrad_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m          found_inf=found_inf)\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "import torchvision.transforms as T\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.ToTensor(),  # convert PIL image to PyTorch tensor\n",
    "    transforms.Resize((512, 1024)),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # normalize image\n",
    "])\n",
    "transform_no_norm = T.Compose([\n",
    "    T.ToTensor(),  # convert PIL image to PyTorch tensor\n",
    "    transforms.Resize((512, 1024)),    \n",
    "])\n",
    "transform_norm= transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "def uv_to_xyxy(u,v ):\n",
    "    result = torch.zeros_like(v)\n",
    "    result[:,0] = u[:,0] # top left x\n",
    "    result[:,1] = v[:,0]\n",
    "    result[:,2] = u[:,1] # right bottom x\n",
    "    result[:,3] = v[:,3]\n",
    "    return result\n",
    "\n",
    "def debug_draw_bbox(img , bbox , normalize = True ):    \n",
    "    h,w = img.shape[-2:]\n",
    "    debug_img = img.permute(1,2,0).detach().cpu().numpy()\n",
    "    debug_img = np.ascontiguousarray(debug_img)\n",
    "\n",
    "    boxes = bbox.reshape(-1,4)\n",
    "    for box in boxes:\n",
    "        if(normalize):\n",
    "            p0 = np.int32([box[0] * w , box[1] * h])\n",
    "            p1 = np.int32([box[2] * w , box[3] * h])\n",
    "        else:\n",
    "            p0 = np.int32([box[0]  , box[1] ])\n",
    "            p1 = np.int32([box[2]  , box[3] ])\n",
    "        debug_img = cv2.rectangle(debug_img, p0 , p1 , (0,255,0) , 2 )\n",
    "    return debug_img\n",
    "\n",
    "# Define your custom collate_fn\n",
    "def collate_fn(data):\n",
    "    # data is a list of tuples with (example, label)\n",
    "    tensors, targets = zip(*data)\n",
    "    '''\n",
    "    # Pad the tensors and stack the targets\n",
    "    tensors = pad_sequence(tensors, batch_first=True)\n",
    "    targets = torch.stack(targets)\n",
    "    '''\n",
    "    \n",
    "    return tensors, targets\n",
    "\n",
    "class ZillowDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, transforms=None , anno_path=\"\" , mode =\"train\" , device = 'cuda'):        \n",
    "        self.transforms = transforms\n",
    "        self.mode= mode\n",
    "        self.annos = []\n",
    "        self.device = device\n",
    "\n",
    "        with open(anno_path  , 'r') as f:\n",
    "            self.annos =  json.load(f)\n",
    "            print(\"anno loaded \" , len(self.annos))        \n",
    "        \n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # TODO: Load your data here        \n",
    "        img_path = os.path.join(ZILLOW_DATASET_FOLDER , self.annos[idx]['image'] )        \n",
    "        img = Image.open(img_path)\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        u = torch.as_tensor(self.annos[idx]['u'])\n",
    "        v = torch.as_tensor(self.annos[idx]['sticks_v'])\n",
    "\n",
    "        target = {}\n",
    "        bboxes = uv_to_xyxy(  u , v)        \n",
    "        target['boxes'] = bboxes.to(self.device)\n",
    "        target['labels'] = torch.ones(len(self.annos[idx]['u'])).view(-1).to(torch.int64) .to(self.device)\n",
    "        \n",
    "        # [Debug: ]\n",
    "        '''\n",
    "        for box in bboxes:\n",
    "            debug_img = debug_draw_bbox(img , box)\n",
    "            plt.imshow(debug_img)\n",
    "            plt.show()\n",
    "        '''\n",
    "\n",
    "        #return img, target\n",
    "        return img.to(self.device) , target\n",
    "\n",
    "    def __len__(self):        \n",
    "        return len(self.annos)\n",
    "\n",
    "\n",
    "dataset_train = ZillowDataset(transforms=transform , anno_path= '../anno/train_visiable_200_no_cross.json' )\n",
    "dataset_test = ZillowDataset(transforms=transform , anno_path= '../anno/test_visiable_20_no_cross.json' )\n",
    "dataset_test_no_norm = ZillowDataset(transforms=transform_no_norm , anno_path= '../output/test_visiable_10_no_cross.json' )\n",
    "data_loader_train = torch.utils.data.DataLoader(dataset_train, batch_size=10, shuffle=True, num_workers=0  , collate_fn = collate_fn)\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=10, shuffle=False, num_workers=0  , collate_fn = collate_fn)\n",
    "data_loader_test_no_norm = torch.utils.data.DataLoader(dataset_test_no_norm, batch_size=10, shuffle=False, num_workers=0  , collate_fn = collate_fn)\n",
    "\n",
    "#=========================================\n",
    "#               Setting \n",
    "#=========================================\n",
    "MAX_TRAIN_EPOCHES = 50\n",
    "RUN_NAME = 'SMALL_TEST_200'\n",
    "\n",
    "model_2cls = model_2cls.to('cuda')\n",
    "optimizer = optim.Adam(model_2cls.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "writer = SummaryWriter(RUN_NAME)\n",
    "\n",
    "def loss_fn(output):\n",
    "    losses = sum(loss for loss in output.values())\n",
    "    return losses\n",
    "def inf_loss_fn(output):\n",
    "    labels = []\n",
    "    boxes = []\n",
    "    for b_out in output:\n",
    "        label = b_out['labels']\n",
    "        box = b_out['boxes']\n",
    "\n",
    "        labels.append(label)\n",
    "        boxes.append(box)\n",
    "    labels = torch.cat(labels)\n",
    "    boxes = torch.cat(boxes)\n",
    "\n",
    "@torch.no_grad()\n",
    "def write_loss(output , type='train' , step=0 ):\n",
    "    for key, value in output.items():\n",
    "        writer.add_scalar(f\"{type}/{key}\" , value , step)\n",
    "    pass\n",
    "\n",
    "@torch.no_grad()\n",
    "def inf_fn(model , data_loader , vis_data , epoch , log_folder= \"\"):    \n",
    "    model.train()    \n",
    "    \n",
    "    cnt = 0\n",
    "    '''\n",
    "    '''\n",
    "    for data in tqdm(data_loader):\n",
    "        img_b , anno_b = data\n",
    "        output = model(img_b , anno_b)\n",
    "        write_loss(output , 'test' , epoch * len(data_loader) + cnt)           \n",
    "        cnt+=1\n",
    "\n",
    "    # visualize\n",
    "    model.eval()        \n",
    "    for i in tqdm(range(5)):\n",
    "        img , anno      = vis_data[i]                \n",
    "        img_b_norm      = transform_norm(img).unsqueeze(0)\n",
    "        \n",
    "        output_b        = model(img_b_norm)\n",
    "        \n",
    "        for j , out in enumerate(output_b):\n",
    "            box = out['boxes'].detach().cpu().numpy()                        \n",
    "            debug_img = debug_draw_bbox(img, box , normalize=True)\n",
    "\n",
    "            gt_box = anno['boxes'].detach().cpu().numpy()                    \n",
    "            debug_img_gt =  debug_draw_bbox(img, gt_box , normalize=True)\n",
    "\n",
    "            fig, axs = plt.subplots(1, 2 ,  figsize=(20, 5))                                     \n",
    "            # Plot the images\n",
    "            axs[0].imshow(debug_img)\n",
    "            axs[0].axis(\"off\")\n",
    "            axs[1].imshow(debug_img_gt)\n",
    "            axs[1].axis(\"off\")\n",
    "            \n",
    "            plt.savefig(os.path.join(log_folder , f\"vis_test_ep{epoch}-it{i}.jpg\") , dpi = 150)\n",
    "            plt.close(fig)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# Test Train\n",
    "def train_fn(model,optimizer  , epoch , data_loader , log_folder=\"\"):\n",
    "    cnt = 0\n",
    "    for data in tqdm(data_loader):\n",
    "        model.train()\n",
    "        img_b , anno_b = data\n",
    "        \n",
    "        output = model(img_b , anno_b)\n",
    "        loss = loss_fn(output)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()    \n",
    "\n",
    "        write_loss(output , 'train' , epoch * len(data_loader) + cnt)\n",
    "        cnt+=1\n",
    "            #break\n",
    "\n",
    "        # [ Test ]\n",
    "        '''\n",
    "        '''\n",
    "    if (epoch % 5 ==0):\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            output_b        = model(img_b)\n",
    "            debug_cnt = 0\n",
    "            for img , anno , out in zip(img_b , anno_b , output_b):        \n",
    "                pred_box = out['boxes'].detach().cpu().numpy()                        \n",
    "                debug_img = debug_draw_bbox(img, pred_box , normalize=True)\n",
    "\n",
    "                gt_bbox = anno['boxes']        \n",
    "                debug_img_gt = debug_draw_bbox(img, gt_bbox.detach().cpu().numpy())\n",
    "                fig, axs = plt.subplots(1, 2 ,  figsize=(20, 5))                                     \n",
    "                # Plot the images\n",
    "                axs[0].imshow(debug_img)\n",
    "                axs[0].axis(\"off\")\n",
    "                axs[1].imshow(debug_img_gt)\n",
    "                axs[1].axis(\"off\")\n",
    "                \n",
    "                plt.savefig(os.path.join(log_folder , f\"vis_train_ep{epoch}-it{debug_cnt}.jpg\") , dpi = 150)\n",
    "                plt.close(fig)\n",
    "\n",
    "                debug_cnt+=1\n",
    "    return model\n",
    "\n",
    "\n",
    "train_eppch = 0\n",
    "eval_eppch = 0\n",
    "log_folder = create_folder( os.path.join(os.getcwd() , \"output\" , RUN_NAME) )\n",
    "for epoch in range(1,MAX_TRAIN_EPOCHES+1):\n",
    "    '''\n",
    "    '''\n",
    "    train_fn(model_2cls , optimizer, train_eppch , data_loader_train , log_folder)\n",
    "    train_eppch+=1\n",
    "\n",
    "    if(epoch % 5 ==0):\n",
    "        inf_fn(model_2cls , data_loader_test , dataset_test_no_norm , eval_eppch , log_folder)\n",
    "        eval_eppch+=1\n",
    "    #inf_fn(model_2cls , data_loader_test , dataset_test_no_norm , eval_eppch , log_folder)\n",
    "    #break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Layout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
