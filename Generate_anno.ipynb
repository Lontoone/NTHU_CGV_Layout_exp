{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把Zillow輸出成Horizon Net資料格式。\n",
    "剛上一版差在此腳本會trim掉門框過小的annotation，保留其他的。 (上一版版本是整筆刪掉)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "from wdoUtils import *\n",
    "def wdo_3D2pixel_list_withbc(wdo_bbox_3D_list, wdo_bbox_pixel_list):\n",
    "    has_cross_image =[]\n",
    "    depths=[]\n",
    "    for wdo_bbox_3D in wdo_bbox_3D_list:\n",
    "        wdo_bbox_pixel = []\n",
    "        pixs , d = wdo_3D2pixel_withbc(wdo_bbox_3D, wdo_bbox_pixel , depths)\n",
    "        print()\n",
    "        wdo_bbox_pixel_list.append(wdo_bbox_pixel[:-1])\n",
    "\n",
    "        #檢查跨越影像的門框. 跟門框中心點對比\n",
    "        pixs= np.array(pixs)\n",
    "        bbox = pixs[:-1]\n",
    "        \n",
    "        min = bbox.min()\n",
    "        max = bbox.max()\n",
    "        check_point = pixs[-1]        \n",
    "\n",
    "        if(min < check_point < max):\n",
    "            has_cross_image.append(False)\n",
    "        else:\n",
    "            has_cross_image.append(True)\n",
    "        \n",
    "    return has_cross_image , depths\n",
    "\n",
    "\n",
    "# for pano only\n",
    "def wdo_3D2pixel_withbc(wdo_bbox_3D, wdo_bbox_pixel , depths):\n",
    "    horizontal_start = np.array([0, -1, 0])\n",
    "    vertical_start = np.array([0, 0, 1])\n",
    "    pixs=[]\n",
    "    # get door pixel coordinates in pano    \n",
    "    top_center_3d = (np.array(wdo_bbox_3D[0])+  np.array(wdo_bbox_3D[1]))/2\n",
    "    wdo_bbox_3D_check = list(wdo_bbox_3D.copy())\n",
    "    wdo_bbox_3D_check.append(top_center_3d)\n",
    "\n",
    "    # project onto xy plane \n",
    "    np_bbox_3d = np.array(wdo_bbox_3D)     \n",
    "    \n",
    "    d =  np.linalg.norm(np_bbox_3d[:,],axis=1)   \n",
    "    depths.append(d)\n",
    "    \n",
    "    #for point in wdo_bbox_3D:\n",
    "    for point in wdo_bbox_3D_check:            \n",
    "        tmp_horizontal = np.array([point[0], point[1], 0])\n",
    "        horizontal_theta = getTheta(tmp_horizontal, horizontal_start)\n",
    "        if point[0] > 0:\n",
    "            horizontal_theta *= -1        \n",
    "            \n",
    "        vertical_theta = getTheta(point, vertical_start)\n",
    "        horizontal_pixel = getPixel(horizontal_theta, 360, 2048)\n",
    "        if point[0] > 0:\n",
    "            horizontal_pixel += 2048\n",
    "\n",
    "        pixs.append(horizontal_pixel)\n",
    "        \n",
    "        vertical_pixel = getPixel(vertical_theta, 180, 1024)\n",
    "        tmp_np = np.around(np.array([horizontal_pixel, vertical_pixel]).astype(np.float32), decimals=2)\n",
    "        wdo_bbox_pixel.append(tmp_np.tolist())\n",
    "    return pixs , depths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Sort points by bbox\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered\n",
    "    # such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the\n",
    "    # bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas\n",
    "    # the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, the\n",
    "    # top-right point will have the smallest difference,\n",
    "    # whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "def uv_to_polygons(us,vs):\n",
    "    polys =[]\n",
    "    for u,v in zip(us,vs):\n",
    "        box = (\n",
    "            (u[0],v[0]) ,\n",
    "            (u[1],v[2]) ,\n",
    "            (u[1],v[3]) ,\n",
    "            (u[0],v[1]) ,\n",
    "        )\n",
    "        \n",
    "        polys.append(box)\n",
    "    return polys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "#from wdoUtils import *\n",
    "import matplotlib.pyplot as plt \n",
    "from matplotlib.patches import Rectangle\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def MakeData( src_file , mode =\"train\" , img_folder=\"\" , max_count = -1 , remove_small =True , remove_cross =True  , debug_visualize_rate = 3 ):\n",
    "\n",
    "    #Read data to pano coordinates:\n",
    "    annotation_list = []\n",
    "    categories_list = []\n",
    "    all_images_list=[]\n",
    "    images_list = []\n",
    "    persp_img_num = 0\n",
    "    door_num = 0\n",
    "\n",
    "    debug_it=2\n",
    "    all_predict_result=[]\n",
    "    processed_data_counter = 0\n",
    "    empty_count = 0\n",
    "    #================================================\n",
    "    #                 Parameters\n",
    "    #================================================\n",
    "    REMOVE_SMALL= remove_small\n",
    "    SMALL_WIDTH_THRESHOLD = 0.01\n",
    "    SMALL_HEIGHT_THRESHOLD = 0.01\n",
    "    REMOVE_CROSS= remove_cross\n",
    "    REMOVE_EMPTY = True\n",
    "    SAMPLE_RATE = debug_visualize_rate\n",
    "    MAX_DATA_COUNT = max_count\n",
    "\n",
    "    img_h = 0\n",
    "\n",
    "\n",
    "    #for room_number in part['test']:    \n",
    "    for room_number in src_file[mode]:        \n",
    "        max_door_area = 0\n",
    "        room_number = int(room_number)   \n",
    "\n",
    "        src_path = os.path.join( img_folder , '{0:04d}'.format(room_number) )\n",
    "        json_path = os.path.join(src_path , 'zind_data.json' )\n",
    "        #Read Data from Zillow \n",
    "        with open(json_path, 'r') as f: \n",
    "            label = json.load(f)\n",
    "            #parse_zind_data(label , src_path , room_number)\n",
    "            for floor_list in label['merger']:\n",
    "                print(f'floor {floor_list}')\n",
    "                for complete_room_list in label['merger'][floor_list]:\n",
    "                    print(f'complete room {complete_room_list}')\n",
    "                    \n",
    "                    it_count =0\n",
    "                    for partial_room_list in label['merger'][floor_list][complete_room_list]:\n",
    "                        print(f'partial room {partial_room_list}')       \n",
    "\n",
    "                        for pano_list in label['merger'][floor_list][complete_room_list][partial_room_list]:\n",
    "                            it_count+=1\n",
    "\n",
    "                            # debug 採樣用\n",
    "                            show_sample = random.randint(0, SAMPLE_RATE) == 1\n",
    "\n",
    "                            #print(f'pano  {pano_list}')\n",
    "                            pano_name = floor_list + '_' + partial_room_list + '_' + pano_list\n",
    "                            pano_src_partial = label['merger'][floor_list][complete_room_list][partial_room_list][pano_list]['image_path']\n",
    "                            pano_src = src_path + '/' + pano_src_partial\n",
    "                            pano_src_partial = '{0:04d}'.format(room_number) + '/' + pano_src_partial\n",
    "\n",
    "                            \n",
    "                            if img_h ==0:\n",
    "                                input_Img = cv2.imread(pano_src)\n",
    "                            #wdo_vertices = label['merger'][floor_list][complete_room_list][partial_room_list][pano_list]['layout_raw']['doors']\n",
    "                            try:\n",
    "                                wdo_vertices = label['merger'][floor_list][complete_room_list][partial_room_list][pano_list]['layout_visible']['doors']\n",
    "                            except:\n",
    "                                wdo_vertices=[]\n",
    "                            if(REMOVE_EMPTY and len(wdo_vertices)==0):\n",
    "                                empty_count+=1\n",
    "                                print(pano_src + \" is Empty\")\n",
    "                                continue\n",
    "                            \n",
    "                            #all_predict_result[pano_src_partial]=[]             \n",
    "                            #----------- Get complete pano mask --------------------\n",
    "                            wdo_bbox_3D_list = wdo_vertices23D(wdo_vertices)\n",
    "                            wdo_bbox_pixel_list =[]\n",
    "                            has_cross_imgs , depths = wdo_3D2pixel_list_withbc(wdo_bbox_3D_list , wdo_bbox_pixel_list)\n",
    "                            \n",
    "                            if img_h ==0:\n",
    "                                img_h,img_w , c = input_Img.shape                            \n",
    "                                             \n",
    "                            sticks=[]\n",
    "                            u_list =[]\n",
    "                            \n",
    "                            #For each door anno in the image:\n",
    "                            #elp =np.array([1e-3 , 0])# 避免過窄的門框x offset為0\n",
    "                            for i, door in enumerate( wdo_bbox_pixel_list):                            \n",
    "                                do_log = True\n",
    "                                door = np.array(door)\n",
    "                                sorted_door = order_points(door)\n",
    "                                \n",
    "                                if(has_cross_imgs[i]):                            \n",
    "                                    sorted_door = np.array([ sorted_door[1] , sorted_door[0] , sorted_door[3], sorted_door[2]])\n",
    "                                    sorted_door[1]+=[2048 , 0]\n",
    "                                    sorted_door[2]+=[2048 , 0]                                \n",
    "                                    center = (sorted_door[0] + sorted_door[2])/2 \n",
    "                                    #bbox = np.array([sorted_door[0] , sorted_door[2]+elp ]) /[2048,1024]                                \n",
    "                                    bbox = np.array([sorted_door[0] , sorted_door[2]  ]) /[2048,1024]                                \n",
    "                                    bbox = bbox.flatten().tolist()\n",
    "                                    pass                         \n",
    "                                else:                                                            \n",
    "                                    door_min = sorted_door[0]\n",
    "                                    door_max = sorted_door[2]                            \n",
    "                                    center = np.array( (door_min + door_max)/2)\n",
    "                                    #bbox = np.array([door_min, door_max  +elp ]) /[2048,1024]                                \n",
    "                                    bbox = np.array([door_min, door_max  ]) /[2048,1024]                                \n",
    "                                    bbox = bbox.flatten().tolist()\n",
    "                                \n",
    "                                # [過濾] 遇到就直接跳過整筆\n",
    "                                if (REMOVE_CROSS):\n",
    "                                    if True in has_cross_imgs:                                    \n",
    "                                        do_log=False\n",
    "                                        #break\n",
    "                                if (REMOVE_SMALL):\n",
    "                                    #高度限制\n",
    "                                    if (bbox[3] - bbox[1] < SMALL_HEIGHT_THRESHOLD) :\n",
    "                                        do_log=False\n",
    "                                        #break\n",
    "                                    #寬度限制\n",
    "                                    if (bbox[2] - bbox[0] <SMALL_WIDTH_THRESHOLD) :\n",
    "                                        do_log=False\n",
    "                                        #break\n",
    "\n",
    "                                # [ Debug 畫點 ]    \n",
    "                                if(show_sample):\n",
    "                                    cv2.circle(input_Img, np.int32(center), 15,(255,0,255) , thickness= -1)\n",
    "                                    for p in door:              \n",
    "                                        textPose= np.round(p , 2)\n",
    "                                        #cv2.putText(input_Img , f'{textPose[0]}, {textPose[1]}' , np.int32(p) ,cv2.FONT_HERSHEY_SIMPLEX , 2 ,0.1,cv2.LINE_AA )\n",
    "                                        cv2.circle(input_Img, np.int32(p), 15,(0,0,255) , thickness= -1)\n",
    "\n",
    "                                # 主要輸出邏輯 + [轉 0~1 ]    \n",
    "                                if(not do_log):\n",
    "                                    print(f\"Skip {src_path} {bbox}\" )\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    #print(f\"Save width {bbox[2] - bbox[0] }\")\n",
    "                                    pass\n",
    "                                \n",
    "                                uv = sorted_door / [img_w , img_h ]\n",
    "                                \n",
    "                                # 兩兩一組                                                                \n",
    "                                flatten_u = uv[:,0].reshape(-1)                                \n",
    "                                flatten_v = uv[:,1].reshape(-1)                                                                                                                                \n",
    "\n",
    "                                stick = np.concatenate( (\n",
    "                                            np.concatenate((flatten_v[::4] ,flatten_v[3::4] )), \n",
    "                                            np.concatenate((flatten_v[1::4] ,flatten_v[2::4] )))\n",
    "                                )\n",
    "                                \n",
    "                                sticks.append(stick)\n",
    "\n",
    "                                _u = np.concatenate( \n",
    "                                    (flatten_u[::4] ,flatten_u[2::4] )\n",
    "                                )                                                                \n",
    "                                u_list.append(_u)                                \n",
    "\n",
    "\n",
    "                            #若無資料\n",
    "                            if(len(u_list)<1):\n",
    "                                continue\n",
    "                            \n",
    "                            #移除重複的                            \n",
    "                            u_list = np.array(u_list)\n",
    "                            sticks = np.array(sticks)\n",
    "                            pair,idx = np.unique(u_list, axis=0 , return_index=True)\n",
    "                            u_list = pair\n",
    "                            sticks = sticks[idx]\n",
    "\n",
    "                            # [Testify]\n",
    "                            if(show_sample):\n",
    "                                polys = uv_to_polygons( u_list , sticks )                                    \n",
    "                                for poly in polys:\n",
    "                                    poly = np.array(poly)  * [img_w , img_h ]  \n",
    "                                    input_Img = cv2.polylines(input_Img, np.int32([poly]) , True, (255,255,0),5)  \n",
    "\n",
    "                            all_predict_result.append({\n",
    "                                \"image\": pano_src_partial,\n",
    "                                'u':np.array(u_list).tolist(),\n",
    "                                'sticks_v':np.array(sticks).tolist(), #每個點的v軸座標，[n,4]\n",
    "\n",
    "                            })                        \n",
    "\n",
    "                            if(show_sample):\n",
    "                                plt.imshow(input_Img)\n",
    "                                plt.show()\n",
    "                            processed_data_counter+=1\n",
    "                            if MAX_DATA_COUNT >0 and processed_data_counter >=MAX_DATA_COUNT:                            \n",
    "                                return all_predict_result\n",
    "\n",
    "                            '''\n",
    "                            #print(wdo_bbox_pixel_list)                            \n",
    "                            print(processed_data_counter)\n",
    "                            if processed_data_counter >5:\n",
    "                                break\n",
    "                        break\n",
    "                    break\n",
    "                break\n",
    "            break\n",
    "        break\n",
    "                            '''\n",
    "    \n",
    "    print(\"empty count\" , empty_count)\n",
    "    return all_predict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "158\n"
     ]
    }
   ],
   "source": [
    "# Load Ground Truth Pano Data.\n",
    "#Zind資料分區，包含train , test, val組合\n",
    "partation_path = ZILLOW_ZIND_JSON_PATH\n",
    "with open(partation_path, 'r') as file:\n",
    "    part = json.load(file)\n",
    "\n",
    "print(len(part['test']))  # Folder count\n",
    "\n",
    "# Test \n",
    "#data =MakeData(src_file= part , img_folder= ZILLOW_DATASET_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floor floor_01\n",
      "complete room complete_room_02\n",
      "partial room partial_room_02\n",
      "\n",
      "complete room complete_room_03\n",
      "partial room partial_room_06\n",
      "\n",
      "complete room complete_room_01\n",
      "partial room partial_room_04\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Skip F:/THU/DoorSeg/OneDrive_2023-01-07/Door_Detection/data/data\\0990 [0.21959473192691803, 0.4075976610183716, 0.21959473192691803, 0.7081347703933716]\n",
      "\n",
      "partial room partial_room_05\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "data =MakeData(src_file= part , img_folder= ZILLOW_DATASET_FOLDER , mode='test' ,max_count=10  , debug_visualize_rate=5000 , remove_cross=False )\n",
    "json_path = os.path.join(os.getcwd(), 'anno', 'test_visiable_10.json') \n",
    "with open(json_path, \"w\") as outfile:\n",
    "    json.dump(data, outfile)\n",
    "'''\n",
    "''' \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "floor floor_01\n",
      "complete room complete_room_02\n",
      "partial room partial_room_02\n",
      "pano  pano_35\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_02_pano_35.jpg\n",
      "\n",
      "Save width 0.49495117366313934\n",
      "complete room complete_room_03\n",
      "partial room partial_room_03\n",
      "pano  pano_25\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_03_pano_25.jpg\n",
      "\n",
      "Save width 0.3482128828763962\n",
      "complete room complete_room_04\n",
      "partial room partial_room_07\n",
      "pano  pano_40\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_07_pano_40.jpg\n",
      "\n",
      "Save width 0.10517087578773499\n",
      "complete room complete_room_05\n",
      "partial room partial_room_08\n",
      "pano  pano_11\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_08_pano_11.jpg\n",
      "\n",
      "\n",
      "Save width 0.028666973114013672\n",
      "Save width 0.2282128930091858\n",
      "complete room complete_room_06\n",
      "partial room partial_room_10\n",
      "pano  pano_29\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_10_pano_29.jpg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Save width 0.04752928018569946\n",
      "Save width 0.056015610694885254\n",
      "Save width 0.202880859375\n",
      "Save width 0.11904788017272949\n",
      "complete room complete_room_01\n",
      "partial room partial_room_09\n",
      "pano  pano_48\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_09_pano_48.jpg\n",
      "\n",
      "\n",
      "\n",
      "Save width 0.05847656726837158\n",
      "Save width 0.017485350370407104\n",
      "Skip f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919 [0.3609277307987213, 0.4691113233566284, 0.3677392601966858, 0.5709375143051147]\n",
      "partial room partial_room_06\n",
      "pano  pano_44\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_06_pano_44.jpg\n",
      "\n",
      "Save width 0.014340877532958984\n",
      "partial room partial_room_04\n",
      "pano  pano_41\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_04_pano_41.jpg\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Save width 0.03782707452774048\n",
      "Save width 0.07592284679412842\n",
      "Save width 0.04065430164337158\n",
      "Save width 0.012036144733428955\n",
      "partial room partial_room_05\n",
      "pano  pano_22\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_05_pano_22.jpg\n",
      "\n",
      "\n",
      "\n",
      "Save width 0.07999515533447266\n",
      "Skip f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919 [0.7892382740974426, 0.4038378894329071, 0.7892382740974426, 0.7056933641433716]\n",
      "Save width 0.21892094612121582\n",
      "partial room partial_room_01\n",
      "pano  pano_52\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_01_partial_room_01_pano_52.jpg\n",
      "\n",
      "\n",
      "Save width 0.16293460130691528\n",
      "Save width 0.010424792766571045\n",
      "floor floor_02\n",
      "complete room complete_room_02\n",
      "partial room partial_room_02\n",
      "pano  pano_65\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_02_partial_room_02_pano_65.jpg\n",
      "\n",
      "Save width 0.015742182731628418\n",
      "partial room partial_room_03\n",
      "pano  pano_70\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_02_partial_room_03_pano_70.jpg\n",
      "\n",
      "\n",
      "Save width 0.11394041776657104\n",
      "Save width 0.11741703748703003\n",
      "complete room complete_room_03\n",
      "partial room partial_room_04\n",
      "pano  pano_73\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_02_partial_room_04_pano_73.jpg\n",
      "\n",
      "Save width 0.16050291061401367\n",
      "complete room complete_room_01\n",
      "partial room partial_room_01\n",
      "pano  pano_76\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0919/panos/floor_02_partial_room_01_pano_76.jpg\n",
      "\n",
      "Save width 0.1668359339237213\n",
      "floor floor_01\n",
      "complete room complete_room_02\n",
      "partial room partial_room_03\n",
      "pano  pano_28\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0422/panos/floor_01_partial_room_03_pano_28.jpg\n",
      "\n",
      "\n",
      "Save width 0.1383007913827896\n",
      "Skip f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0422 [0.7224169969558716, 0.3434765636920929, 0.7224169969558716, 0.776074230670929]\n",
      "pano  pano_29\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0422/panos/floor_01_partial_room_03_pano_29.jpg\n",
      "\n",
      "\n",
      "Save width 0.07227051258087158\n",
      "Save width 0.05953127145767212\n",
      "pano  pano_30\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0422/panos/floor_01_partial_room_03_pano_30.jpg\n",
      "\n",
      "\n",
      "Save width 0.04469722509384155\n",
      "Save width 0.23912596702575684\n",
      "complete room complete_room_03\n",
      "partial room partial_room_04\n",
      "pano  pano_19\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0422/panos/floor_01_partial_room_04_pano_19.jpg\n",
      "\n",
      "\n",
      "Save width 0.22844231128692627\n",
      "Save width 0.07481935620307922\n",
      "pano  pano_20\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0422/panos/floor_01_partial_room_04_pano_20.jpg\n",
      "\n",
      "\n",
      "Save width 0.07539549469947815\n",
      "Save width 0.15544438362121582\n",
      "complete room complete_room_04\n",
      "partial room partial_room_06\n",
      "pano  pano_17\n",
      "f:\\THU\\DoorSeg\\OneDrive_2023-01-07\\Door_Detection\\data/data/0422/panos/floor_01_partial_room_06_pano_17.jpg\n",
      "\n",
      "Save width 0.17835447192192078\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Write Processed Zind Data.\n",
    "import json\n",
    "import os\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_complete.json')\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_complete_10.json')\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_complete_10.json')\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_complete_10-v1.json')\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_complete_10-fixedv1.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_complete_10-fixedv2.json')\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_big_doors.json')\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_complete_all.json')\n",
    "\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_all.json') # 0610 ALL\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_all_noEmpty.json') # 0610 ALL\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_small.json')\n",
    "\n",
    "data =MakeData()\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_noramll_200.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_noramll_200.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_all1.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_all1.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_200_no_cross.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_16_no_cross.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_horizon_big_10.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_horizon_big_unique2k.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_horizon_normalbig_all.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_horizon_w0.01_2k.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_horizon_w0.01_200.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_horizon_unique_w0.01_all.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_horizon_unique_w0.01_all.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_horizon_unique_w0.01_all_fixedbug.json') \n",
    "json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_horizon_unique_w0.01_20_fixedbug.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_horizon_unique_w0.01_20_fixedbug.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_horizon_unique_w0.01_all_fixedbug.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_horizon_normalbig_unique2k.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_horizon_big_unique200.json') \n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_horizon_unique_all.json') \n",
    "with open(json_path, \"w\") as outfile:\n",
    "    json.dump(data, outfile)\n",
    "'''\n",
    "''' \n",
    "print(len(data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Coco Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "# Prepaire default coco data:\n",
    "coco_data = get_default_coco()\n",
    "\n",
    "#load json\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_complete_10.json')\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_complete_all.json')\n",
    "#json_path = os.path.join(os.getcwd(), 'output', 'train_visiable_complete_10.json')\n",
    "json_path = os.path.join(os.getcwd(), 'output', 'test_visiable_complete_10.json')\n",
    "f= open(json_path)\n",
    "visiable_door_anno = json.loads(f.read())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "print(visiable_door_anno[0].keys())\n",
    "ind =1\n",
    "print(visiable_door_anno[ind]['cross_img'])\n",
    "print(visiable_door_anno[ind]['3d_pos'])\n",
    "img_path = os.path.join(os.getcwd() , \"data/data/\", visiable_door_anno[ind]['image'])\n",
    "img = cv2.imread(img_path)\n",
    "plt.imshow(img)\n",
    "plt.show"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 檔案處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "img_anno_list = []\n",
    "kp_anno_list=[]\n",
    "it=0\n",
    "#for data in visiable_door_anno[40:43]:\n",
    "for data in visiable_door_anno[:]:\n",
    "    img_path = os.path.join(os.getcwd() , \"data/data/\", data['image'])\n",
    "    img = cv2.imread(img_path)\n",
    "    h,w,_ = img.shape\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "\n",
    "    img_anno ={\n",
    "        \"license\": 6,\n",
    "\t\t\"file_name\": data['image'],\n",
    "\t\t\"height\": h,\n",
    "\t\t\"width\": w,\n",
    "\t\t#\"coco_url\": \"http://images.cocodataset.org/val2017/000000153669.jpg\",\n",
    "\t\t#\"date_captured\": \"2013-11-19 19:44:15\",\n",
    "\t\t#\"flickr_url\": \"http://farm5.staticflickr.com/4023/4659511777_06fdc54df9_z.jpg\",\n",
    "\t\t\"id\": it\n",
    "    }\n",
    "    img_anno_list.append(img_anno)\n",
    "    anno = {\n",
    "        'segmentations':[],\n",
    "        'num_keypoints':0,\n",
    "        \"area\": [],\n",
    "        \"iscrowd\": 0,\n",
    "        \"keypoints\": [],\n",
    "        \"image_id\": it,\n",
    "        \"bbox\": [],\n",
    "        \"category_id\": 1,\n",
    "        \"labels\": 1,\n",
    "        \"id\": it,        \n",
    "    }\n",
    "    #-------------- [Fill in anno] -----------------    \n",
    "    # 複數的門\n",
    "   \n",
    "    \n",
    "    #-------------- [Fill in anno] -----------------    \n",
    "    # sort 2D points\n",
    "    doors_2d = np.array(data['2d_pos'])   \n",
    "    door_segs=[]\n",
    "    door_kps=[]\n",
    "\n",
    "    min_bbox_x=9999\n",
    "    min_bbox_y=9999\n",
    "    max_bbox_x=0\n",
    "    max_bbox_y=0\n",
    "    #for door in doors_2d:                    \n",
    "    for i, door in enumerate(doors_2d):                    \n",
    "        #data_2d = np.array( doors)\n",
    "        #sort_data = order_points(door)  \n",
    "        door = order_points(door)  \n",
    "\n",
    "        # Flip door if cross image\n",
    "        #anno['hasCross'] = data['cross_img'][i]\n",
    "        seg = {\n",
    "            \"cross_img\":data['cross_img'][i],\n",
    "            \"segmentation\":[]\n",
    "        }\n",
    "        \n",
    "        if(data['cross_img'][i]):\n",
    "            # Area:\n",
    "            area = float( abs( door[0][0]*(door[0][1] - door[3][1])) + abs( (2048-door[1][0])*(door[1][1] - door[2][1])))\n",
    "            anno['area'].append(area)\n",
    "            # Flip door order\n",
    "            door_copy = door.copy()\n",
    "            door[0],door[1],door[2],door[3] = door_copy[1],door_copy[0],door_copy[3],door_copy[2] \n",
    "            #bbox = biggest boarder  format:[x1, y1, x2, y2]            \n",
    "            #anno['bbox'].append([0 , door[0][1] , 2047 , door[2][1]])  #This is Wrong!            \n",
    "\n",
    "                   \n",
    "        else:\n",
    "            area =float( abs(door[1][0]-door[0][0]) * abs(door[2][1]-door[0][1]) )\n",
    "            anno['area'].append(area)\n",
    "            #anno['bbox'].append([min_bbox_x , min_bbox_y , max_bbox_x , max_bbox_y])\n",
    "            #anno['bbox'].append([door[0][0] , door[0][1] , door[2][0] , door[2][1]])\n",
    "            \n",
    "\n",
    "        door_count , point_count ,xy= doors_2d.shape\n",
    "        temp = np.array( [np.tile( np.array([0,0,2]) , (point_count,1))]*door_count)\n",
    "        temp[:,:,0:2] = doors_2d[:,:,0:2]        \n",
    "\n",
    "        #keypoints=[[door[0,:],2] , [door[1,:],2] , [door[2,:],2] , [door[3,:],2] ]\n",
    "\n",
    "        keypoints = temp.tolist()\n",
    "        door=door.tolist()\n",
    "\n",
    "        #紀錄資料\n",
    "        #door_segs.append([door[0],door[1],door[2],door[3]])  # TODO:取代\n",
    "        seg['segmentation']= [door[0],door[1],door[2],door[3]]\n",
    "        door_segs.append(seg)\n",
    "        door_kps.append(keypoints)\n",
    "\n",
    "\n",
    "        #[DEBUG] Plot all point in order\n",
    "        i=0\n",
    "        for point in door:            \n",
    "            point= np.array(point)\n",
    "            cv2.circle(img,center=point.astype(int) , radius=25 , color=(255,0,0), thickness=-1)\n",
    "            cv2.putText(img , text=str(i) , org=point.astype(int) ,  fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale=5.0,\n",
    "                color=(0, 255, 0),\n",
    "                thickness=2,\n",
    "                lineType=cv2.LINE_4)\n",
    "            i+=1  \n",
    "\n",
    "    #算bbox\n",
    "    x,y = (min_bbox_x) ,(min_bbox_y)     \n",
    "    bbox_w , bbox_h = max_bbox_x - min_bbox_x , abs(max_bbox_y- min_bbox_y)\n",
    "    anno['labels']=1\n",
    "    #anno['bbox'] = np.array(anno['bbox'] ).tolist()    \n",
    "    anno['keypoints'] = np.array(door_kps).flatten().tolist()\n",
    "    #anno['segmentation'] = np.array(door_segs).reshape((-1,8)).tolist()    \n",
    "    anno['segmentations'] = door_segs\n",
    "\n",
    "    #結算本筆data\n",
    "    kp_anno_list.append(anno)\n",
    "\n",
    "    it+=1\n",
    "    #plt.imshow(img)\n",
    "    #plt.show()\n",
    "coco_data['annotations'] = kp_anno_list\n",
    "coco_data['images'] = img_anno_list\n",
    "print(coco_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#寫出檔案\n",
    "#json_out_path = os.path.join(os.getcwd(),\"output\",\"keypoint_coco_v_0-100.json\")\n",
    "#json_out_path = os.path.join(os.getcwd(),\"output\",\"keypoint_coco_v_0-300.json\")\n",
    "#json_out_path = os.path.join(os.getcwd(),\"output\",\"keypoint_coco_v3-10.json\")\n",
    "json_out_path = os.path.join(os.getcwd(),\"output\",\"keypoint_coco_test_v1-10.json\")\n",
    "json_obj = json.dumps(coco_data )\n",
    "with open(json_out_path , 'w') as output:\n",
    "    output.write(json_obj)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "import os\n",
    "train_dataset_name = \"test_v8\"\n",
    "train_images_path = os.path.join(os.getcwd() , \"data/data/\")\n",
    "#train_json_annot_path = os.path.join(os.getcwd() , \"output\",\"keypoint_coco_v1.json\")\n",
    "#train_json_annot_path = os.path.join(os.getcwd() , \"output\",\"keypoint_coco_v1_0-300.json\")\n",
    "train_json_annot_path = os.path.join(os.getcwd() , \"output\",\"train_visiable_small.json\")\n",
    "\n",
    "#註冊資料集\n",
    "register_coco_instances(name=train_dataset_name , metadata={} , json_file=train_json_annot_path , image_root= train_images_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.engine import DefaultTrainer\n",
    "import torch, detectron2\n",
    "from detectron2.data import DatasetCatalog,MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import random\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#視覺化\n",
    "#--- 以下程式碼缺少bbox，不能跑 ---\n",
    "def plot_samples(dataset_name , n=2 ):\n",
    "    dataset_custom = DatasetCatalog.get(dataset_name)\n",
    "    dataset_custom_metadata = MetadataCatalog.get(dataset_name)\n",
    "    \n",
    "    for s in random.sample(dataset_custom,n):\n",
    "        print( 'fileName ',s['file_name'])\n",
    "        print(s.keys())\n",
    "        print(s['annotations'])\n",
    "        #img_path = os.path.join( os.getcwd(),\"data/data/\",os.path.basename( s['file_name']))\n",
    "        img_path =s['file_name']\n",
    "        img = cv2.imread(img_path) #cv load in BGR format\n",
    "        print(img_path)\n",
    "        v = Visualizer(img[:,:,::-1] , metadata=dataset_custom_metadata , scale=0.5) #deteron2 need RGB format. use ::-1 to swap red and blue channel\n",
    "        v = v.draw_dataset_dict(s)\n",
    "        #out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "        plt.figure(figsize=(10,15))\n",
    "        plt.imshow(v.get_image())\n",
    "        plt.show()\n",
    "\n",
    "print( DatasetCatalog.get(train_dataset_name))\n",
    "plot_samples(train_dataset_name )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 有些門的標記點看起來歪歪的，檢查是不是原始資料問題?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "maximum_filter() got an unexpected keyword argument 'min'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_35992\\1799682586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.9\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmax_v\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'wrap'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_v\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: maximum_filter() got an unexpected keyword argument 'min'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.ndimage\n",
    "a = np.array([0.1,0.5,0.3,0.5,0.1,0.9 ,1])\n",
    "max_v = scipy.ndimage.maximum_filter(a, size=3, mode='wrap', min=0.4)\n",
    "print (max_v)\n",
    "\n",
    "idx = np.where(max_v == a)[0]\n",
    "print(idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
