{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "#device = 'cpu'  # TODO: CHANGE THIS!!!\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from tensorboardX import SummaryWriter\n",
    "from torch import optim\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import cv2\n",
    "#os.environ['CUDA_LAUNCH_BLOCKING']='1'\n",
    "\n",
    "#======= [ SETTING ] =======\n",
    "\n",
    "MAX_PREDICTION_COUNT = 90\n",
    "BATCH_SIZE=6\n",
    "C = 0.1\n",
    "R = 10\n",
    "CONFIDENCE_THRESHOLD = 0.05\n",
    "\n",
    "MODEL_FOLDER =r'./output/'\n",
    "\n",
    "#LONAD_MODEL_NAME =\"n90-c0.1-r10-0913-all-Aug-1023-with_aug_ep166.pth\"  \n",
    "LONAD_MODEL_NAME =\"\"  \n",
    "DO_AUG= False\n",
    "#TRAIN_NAME = f\"n90-c0.1-r10-10k-noAug-0104\"\n",
    "TRAIN_NAME = f\"__Test__orign\"\n",
    "writer = SummaryWriter(TRAIN_NAME)\n",
    "\n",
    "LOADED_EPOCH = None\n",
    "LOADED_AP = None\n",
    "\n",
    "TRAIN_DATASET_NAME  = \"../../train_visiable_20_no_cross.json\"\n",
    "TEST_DATASET_NAME   = \"../../test_visiable_10_no_cross.json\"\n",
    "#==============\n",
    "\n",
    "#========= [ Log Setting ] ==========\n",
    "MAX_LOG_GAP = 5\n",
    "MAX_LOG_IT_COUNT = 5\n",
    "EVAL_GAP = 5\n",
    "save_auc = 0.2\n",
    "log_folder = os.path.join(os.getcwd() , \"output\" , TRAIN_NAME )\n",
    "if (not os.path.exists(log_folder)):\n",
    "    os.makedirs(log_folder)   \n",
    "#====================================\n",
    "\n",
    "def reset_ncr_config(n, c, r ):\n",
    "    global MAX_PREDICTION_COUNT\n",
    "    global C\n",
    "    global R\n",
    "    global TRAIN_NAME\n",
    "    global writer\n",
    "    global log_folder\n",
    "\n",
    "    MAX_PREDICTION_COUNT = n\n",
    "    C = c \n",
    "    R = r\n",
    "    #TRAIN_NAME = f\"n{MAX_PREDICTION_COUNT}-c{C}-r{R}-0908\"\n",
    "    #TRAIN_NAME = f\"n{MAX_PREDICTION_COUNT}-c{C}-r{R}-0913-all-Aug-1023\"\n",
    "    writer = SummaryWriter(TRAIN_NAME)\n",
    "\n",
    "    log_folder = os.path.join(os.getcwd() , \"output\" , TRAIN_NAME )\n",
    "    if (not os.path.exists(log_folder)):\n",
    "        os.makedirs(log_folder)   \n",
    "\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "c:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#======= [ Load Model ] =======\n",
    "from horizon_model_direct import HorizonNet\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "net = HorizonNet('resnet50', True , MAX_PREDICTION_COUNT).to(device)   # For server (small memory)\n",
    "\n",
    "if (LONAD_MODEL_NAME is not \"\" or None):          \n",
    "    #state_dict = torch.load(f'./output/{LONAD_MODEL_NAME}', map_location='cpu')\n",
    "    model_path = os.path.join(MODEL_FOLDER , LONAD_MODEL_NAME)\n",
    "    state_dict = torch.load(model_path, map_location='cpu')\n",
    "    print(state_dict.keys())\n",
    "    net.load_state_dict(state_dict['state_dict'])\n",
    "    LOADED_EPOCH    = state_dict['epoch']\n",
    "    LOADED_AP       = state_dict['ap']\n",
    "    save_auc        = LOADED_AP  \n",
    "    print(LOADED_EPOCH,LOADED_AP)\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, net.parameters()),\n",
    "        lr=1e-4, betas=(0.9, 0.999))\n",
    "'''\n",
    "'''\n",
    "\n",
    "def reset_model():\n",
    "    global net\n",
    "    global optimizer\n",
    "    net = HorizonNet('resnet50', True , MAX_PREDICTION_COUNT).to(device)\n",
    "    optimizer = optim.Adam(\n",
    "        filter(lambda p: p.requires_grad, net.parameters()),\n",
    "        lr=1e-4, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None\n"
     ]
    }
   ],
   "source": [
    "print(LOADED_EPOCH,LOADED_AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final iou_matrix [[0.21522403]\n",
      " [0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "from shapely.geometry import Polygon\n",
    "def predict (data):    \n",
    "    imgs = data['image'].to(device)        \n",
    "    out = net(imgs)\n",
    "    \n",
    "    return out\n",
    "    \n",
    "\n",
    "# 輸出 [b , 5 , max_door_count]\n",
    "#   Note: [b,0]為x座標，非原本的u_grad\n",
    "def filter_peak_data(predict , min_threshold=-1):\n",
    "    u  , v_top ,v_btm , d_top , d_btm  = predict\n",
    "\n",
    "    b,n, _, w  = u.shape\n",
    "\n",
    "    result = torch.zeros((b,5,n)).to(device)\n",
    "    u = u .reshape(b,n,-1)\n",
    "    v_top = v_top.reshape(b,n,-1)\n",
    "    v_btm = v_btm.reshape(b,n,-1)\n",
    "    d_top = d_top.reshape(b,n,-1)\n",
    "    d_btm = d_btm.reshape(b,n,-1)\n",
    "\n",
    "    peak_col_idx = torch.argmax(u,2)     \n",
    "\n",
    "    #print(\"peak_idx\" , peak_col_idx)\n",
    "    for i in range(b):\n",
    "        _t = torch.arange(MAX_PREDICTION_COUNT).to(device)\n",
    "        idx = _t * w + peak_col_idx[i]             \n",
    "        \n",
    "        result[i,0,:]=peak_col_idx[i] / w  \n",
    "        result[i,1,:]=v_top.reshape(b , -1)[i,idx]\n",
    "        result[i,2,:]=v_btm.reshape(b , -1)[i,idx]\n",
    "        result[i,3,:]=d_top.reshape(b , -1)[i,idx]\n",
    "        result[i,4,:]=d_btm.reshape(b , -1)[i,idx]\n",
    "\n",
    "        if(min_threshold>0):\n",
    "            u_max_value_each_cha = torch.max(u[i] , 1)[0]            \n",
    "            low_u_idx = torch.where(u_max_value_each_cha < min_threshold)[0]            \n",
    "            result[i,0,low_u_idx] = -9999\n",
    "        pass\n",
    "        \n",
    "        \n",
    "        pass    \n",
    "    return result\n",
    "\n",
    "def encode(packed_data):\n",
    "    _esp = 0.000001  # 避免有些門寬=0的爆炸 (真的會爆炸)\n",
    "    packed_data[:,1] = torch.log( 0.5 - packed_data[:,1])  #v_top\n",
    "    packed_data[:,2] = torch.log( packed_data[:,2] - 0.5)  #v_btm\n",
    "    packed_data[:,3] = torch.log( packed_data[:,3] + _esp )  #du\n",
    "    #packed_data[:,3] = torch.log( packed_data[:,3] )  #du\n",
    "    packed_data[:,4] = torch.log( 0.5 - packed_data[:,4] + _esp)  #v_top2\n",
    "    packed_data[:,5] = torch.log( packed_data[:,5] - 0.5 + _esp)  #v_btm2\n",
    "\n",
    "    zeros = torch.zeros_like(packed_data)\n",
    "    is_nan = torch.isnan(packed_data)\n",
    "    packed_data = torch.where(is_nan , zeros , packed_data)    \n",
    "    #packed_data = torch.nan_to_num(packed_data)\n",
    "    return packed_data\n",
    "    pass\n",
    "\n",
    "#from scipy.spatial import distance_matrix\n",
    "#def match_gt(gt_u , predict_u ):\n",
    "def match_gt(gt_data , predict_data):\n",
    "    \n",
    "    # Filter out zero\n",
    "    #zeros_mask = torch.zeros_like(gt_data[:,0,:])\n",
    "    #ones_mask = torch.ones_like(gt_data[:,0,:])\n",
    "    #print(\"gt_data[:,0,:]\" , gt_data[:,0,:])\n",
    "    nonZero_idx = torch.where(gt_data[:,0,:] != 0)[0]\n",
    "    nonZero_idx = torch.unique(nonZero_idx ,return_counts=True)[1]\n",
    "    #print(\"nonZero_idx\" , nonZero_idx)\n",
    "    \n",
    "    \n",
    "    gt_u = gt_data[:,0,:]    \n",
    "    #print(\"filtered gt u \" , gt_u )\n",
    "    predict_u = predict_data[:,0,:]\n",
    "\n",
    "\n",
    "    #print(\"mt u\",gt_u.shape)\n",
    "    #print(\"mt pu\",predict_u.shape)\n",
    "    #b , n , _ , __ = predict_u.shape\n",
    "    b , n   = predict_u.shape\n",
    "    #print(predict_u.shape)\n",
    "\n",
    "    matched_gt_u = []\n",
    "    matched_gt_vtop = []\n",
    "    matched_gt_vbtm = []\n",
    "    matched_gt_du = []\n",
    "    matched_gt_dvtop = []\n",
    "    matched_gt_dvbtm = []\n",
    "\n",
    "    matched_prd_u = []\n",
    "    matched_prd_vtop = []\n",
    "    matched_prd_vbtm = []\n",
    "    matched_prd_du = []\n",
    "    matched_prd_dvtop = []\n",
    "    matched_prd_dvbtm = []\n",
    "    gt_idxs=[]\n",
    "    #print(\"gt_before sort\" , gt_data)\n",
    "    #pos_idxs =[]\n",
    "    #neg_idxs =[]\n",
    "    #neg_pred_u = []\n",
    "    u_interval = 1 / MAX_PREDICTION_COUNT    \n",
    "    for i in range(b):\n",
    "        #dist_mat = distance_matrix(gt_u[i] , predict_u[i] )\n",
    "        # Sort by u distance\n",
    "        pos_count =nonZero_idx[i]        \n",
    "\n",
    "        sorted_gt_u , sorted_gt_idx  = torch.sort(gt_u[i,:pos_count] , dim=0)        \n",
    "        #gt_data[i,:,:pos_count] = gt_data[i,:,sorted_gt_idx]       \n",
    "        gt_data[i,:-1,:pos_count] = gt_data[i,:-1,sorted_gt_idx]        # -1: dont sort u_grad\n",
    "        \n",
    "        u_interval_idx = (sorted_gt_u / u_interval).type(torch.long)\n",
    "        gt_idxs.append(u_interval_idx)\n",
    "        #print(\"u_interval_idx\" , u_interval_idx)\n",
    "\n",
    "        target = torch.zeros((6,MAX_PREDICTION_COUNT)).to(device)                                \n",
    "        target[0] = gt_data[i,-1]   # u_grad\n",
    "        target[0,u_interval_idx] = 1   # 分類問題\n",
    "        target[1:,u_interval_idx] = gt_data[i,1:-1,:pos_count]\n",
    "        #target[1:,u_interval_idx] = gt_data[i,1:,:pos_count]\n",
    "\n",
    "\n",
    "        matched_gt_u.append(target[0,:])\n",
    "        matched_gt_vtop.append(target[1,:])\n",
    "        matched_gt_vbtm.append(target[2,:])\n",
    "        matched_gt_du.append(target[3,:])\n",
    "        matched_gt_dvtop.append(target[4,:])\n",
    "        matched_gt_dvbtm.append(target[5,:])\n",
    "\n",
    "\n",
    "        matched_prd_u.append(predict_data[i,0,:])\n",
    "        matched_prd_vtop.append(predict_data[i,1,:])\n",
    "        matched_prd_vbtm.append(predict_data[i,2,:])\n",
    "        matched_prd_du.append(predict_data[i,3,:])\n",
    "        matched_prd_dvtop.append(predict_data[i,4,:])\n",
    "        matched_prd_dvbtm.append(predict_data[i,5,:])\n",
    "        #neg_pred_u.append(predict_data[i,0,neg_u_idx])\n",
    "        \n",
    "    '''\n",
    "    return  matched_gt_u , matched_gt_vtop , matched_gt_vbtm ,\\\n",
    "            matched_gt_dtop ,matched_gt_dbtm , matched_prd_u , \\\n",
    "            matched_prd_vtop ,matched_prd_vbtm ,matched_prd_dtop , matched_prd_dbtm, \\\n",
    "            #pos_idxs,neg_idxs #neg_pred_u\n",
    "    '''\n",
    "    return  (matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\\\n",
    "            (matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,),\\\n",
    "            gt_idxs\n",
    "    \n",
    "    pass\n",
    "def get_grad_u(u ,_width = 1024):    \n",
    "    u_len = u.shape[0]\n",
    "    width = _width\n",
    "    dist = torch.arange(0, width)\n",
    "    #dist = dist.tile((u.shape[0],1) )            \n",
    "    dist = dist.repeat((u.shape[0],1) )            \n",
    "    dist = torch.abs( dist.float() - u.reshape((-1,1))*width )        \n",
    "    c_dist = C ** dist              \n",
    "    \n",
    "    #c_dist[:u_len//2] = torch.max(c_dist[ 0::2 ] , c_dist[ 1::2 ])\n",
    "    \n",
    "    return c_dist\n",
    "\n",
    "def get_grad_u_keep_batch(batch_u , pair =False , width = 1024):\n",
    "    result =[]\n",
    "    for u in batch_u:            \n",
    "        w = u.shape[0]\n",
    "        if (pair):\n",
    "            u1 = get_grad_u(u[:w//2].cpu().detach() , width)\n",
    "            u2 = get_grad_u(u[w//2:].cpu().detach() , width)\n",
    "            result.append( torch.max(u1,u2))\n",
    "        else:\n",
    "            result.append(get_grad_u(u.cpu().detach() , width) )\n",
    "    \n",
    "    return result\n",
    "def u_interval_to_real_u(u_interval , threshold = 0.25):\n",
    "    \n",
    "    mid_offset = 1/MAX_PREDICTION_COUNT *0.5\n",
    "    line = torch.arange(MAX_PREDICTION_COUNT).to(device).float() /  float( MAX_PREDICTION_COUNT) + mid_offset    \n",
    "    i = 0\n",
    "    masks = []    \n",
    "    for ui in u_interval:            \n",
    "        zero_mask = torch.zeros_like(ui)\n",
    "        one_mask = torch.ones_like(ui)\n",
    "        #mask = (torch.sigmoid(ui) > threshold)\n",
    "        mask = torch.where(torch.sigmoid(ui) > threshold , one_mask , zero_mask)\n",
    "        masks.append(mask)\n",
    "        u_interval[i] = mask * line\n",
    "        i+=1\n",
    "    \n",
    "    return u_interval , masks\n",
    "from scipy import ndimage\n",
    "def find_N_peaks(signal, r=29, min_v=0.05, N=None):\n",
    "    max_v = ndimage.maximum_filter(signal, size=r, mode='wrap')    \n",
    "    pk_loc = np.where(max_v == signal)[0]\n",
    "    pk_loc = pk_loc[signal[pk_loc] > min_v]\n",
    "    if N is not None:\n",
    "        order = np.argsort(-signal[pk_loc])\n",
    "        pk_loc = pk_loc[order[:N]]\n",
    "        pk_loc = pk_loc[np.argsort(pk_loc)]\n",
    "    return pk_loc, signal[pk_loc]\n",
    "\n",
    "def cal_loss(pred , gt , pk_idxs):\n",
    "    #b = len(gt)\n",
    "    l1_loss =  torch.nn.L1Loss()\n",
    "    bce = torch.nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    gt_u = torch.cat( gt[0])    \n",
    "    pred_u = torch.cat( pred[0])    \n",
    "    #print(\"gt vtop data \" , gt[1])\n",
    "    #print(\"pred vtop data \" , pred[1])\n",
    "    \n",
    "    #u_loss = F.binary_cross_entropy_with_logits( pred_u , gt_u)            \n",
    "    u_loss = bce( pred_u , gt_u)            \n",
    "    #print(\"u_loss pred u \",  pred_u)\n",
    "    #print(\"u_loss gt u \",  gt_u)\n",
    "    \n",
    "    #non_zero_idx = torch.where(gt_u > 0)[0]  \n",
    "    non_zero_idx=[]\n",
    "    i=0\n",
    "    for pk in pk_idxs:\n",
    "        non_zero_idx.append(pk + i * MAX_PREDICTION_COUNT)\n",
    "        i+=1\n",
    "    non_zero_idx = torch.cat(non_zero_idx)\n",
    "    #print(\"cal loss idx\" , non_zero_idx) \n",
    "\n",
    "    # other loss\n",
    "    gt_vtop = torch.cat(gt[1])[non_zero_idx]    \n",
    "    pred_vtop = torch.cat(pred[1])[non_zero_idx]\n",
    "    \n",
    "    v_top_loss = l1_loss(pred_vtop , gt_vtop )   \n",
    "\n",
    "    pred_vbtm   = torch.cat(pred[2])[non_zero_idx]\n",
    "    gt_vbtm     = torch.cat(gt[2])[non_zero_idx]\n",
    "    v_btm_loss = l1_loss(pred_vbtm , gt_vbtm )\n",
    "    #print(\"gt_vbtm\" ,gt_vbtm)\n",
    "    #print(\"pred_vbtm\" ,pred_vbtm)\n",
    "\n",
    "    pred_du = torch.cat(pred[3])[non_zero_idx]    \n",
    "    gt_du = torch.cat(gt[3])[non_zero_idx]\n",
    "    du_loss = l1_loss(pred_du , gt_du )\n",
    "\n",
    "    pred_dtop = torch.cat(pred[4])[non_zero_idx]    \n",
    "    gt_dtop = torch.cat(gt[4])[non_zero_idx]\n",
    "    d_top_loss = l1_loss(pred_dtop , gt_dtop )\n",
    "\n",
    "    pred_dbtm = torch.cat(pred[5])[non_zero_idx]    \n",
    "    gt_dbtm = torch.cat(gt[5])[non_zero_idx]\n",
    "    d_btm_loss = l1_loss(pred_dbtm , gt_dbtm )\n",
    "\n",
    "    #losses = {\"u_loss\":u_loss *10, \"v_top\":v_top_loss , \"v_btm\":v_btm_loss,\"du\":du_loss ,\"d_top\":d_top_loss ,\"d_btm\":d_btm_loss }    \n",
    "    #losses = {\"u_loss\":u_loss , \"v_top\":v_top_loss  , \"v_btm\":v_btm_loss  }    \n",
    "    losses = {\"u_loss\":u_loss *20, \"v_top\":v_top_loss , \"v_btm\":v_btm_loss ,\"du\":du_loss ,\"d_top\":d_top_loss ,\"d_btm\":d_btm_loss }    \n",
    "    #losses = {\"u_loss\":u_loss }    \n",
    "    \n",
    "    '''\n",
    "    '''\n",
    "    #print(losses)\n",
    "\n",
    "    return losses\n",
    "    '''\n",
    "    [Debug]\n",
    "    _img =  gt_grad_u[0].tile((10,1)).cpu().detach().numpy()\n",
    "    _img2 =  pred_grad_u[0].tile((10,1)).cpu().detach().numpy()\n",
    "    plt.imshow(_img , cmap='gray')\n",
    "    plt.show()\n",
    "    plt.imshow(_img2,cmap='gray')\n",
    "    plt.show()\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "def to_bbox( u_pack , vt_pack , vb_pack ):\n",
    "\n",
    "    u_flatten  = torch.cat(u_pack)\n",
    "    vt_flatten  = torch.cat(vt_pack)\n",
    "    vb_flatten  = torch.cat(vb_pack)\n",
    "\n",
    "    non_zero_idx = torch.where(u_flatten>0)[0]\n",
    "    u_flatten = u_flatten[non_zero_idx]\n",
    "    vt_flatten = vt_flatten[non_zero_idx].reshape(-1 , 2)\n",
    "    vb_flatten = vb_flatten[non_zero_idx].reshape(-1 , 2)\n",
    "\n",
    "    vt_flatten = torch.min(vt_flatten , 1)[0]\n",
    "    vb_flatten = torch.max(vb_flatten , 1)[0]\n",
    "\n",
    "    bboxes=[]\n",
    "    for i in range(vt_flatten.shape[0]):\n",
    "        x1 = u_flatten[2*i]\n",
    "        x2 = u_flatten[2*i+1]\n",
    "        y1 = vt_flatten[i]\n",
    "        y2 = vb_flatten[i]\n",
    "        bboxes.append((x1,y1,x2,y2))\n",
    "    bboxes = torch.as_tensor(bboxes).reshape(-1,4)\n",
    "    return bboxes \n",
    "    pass\n",
    "\n",
    "def decode(bdata , u_thresh = 0.25 , get_raw_u = False ):    \n",
    "    #b ,c ,w = datas.shape\n",
    "    #for bdata in datas:\n",
    "    \n",
    "    u = bdata[0] \n",
    "    vt = bdata[1]\n",
    "    vb = bdata[2]\n",
    "    du = bdata[3]\n",
    "    dvt = bdata[4]\n",
    "    dvb = bdata[5]        \n",
    "    pk_idxs =[]\n",
    "    #masks=[]\n",
    "    #real_gt_u=[]\n",
    "    for u_grad in u:\n",
    "        #pk_idx = find_N_peaks(u_grad.cpu().detach().numpy() , r=r , min_v = u_thresh )[0]\n",
    "        u_grad = torch.sigmoid (u_grad)    \n",
    "        pk_idx = find_N_peaks(u_grad.cpu().detach().numpy() , r= R , min_v = u_thresh )        \n",
    "        pk_idxs.append(pk_idx[0])\n",
    "     \n",
    "    \n",
    "    b = len(u)    \n",
    "    us =[]\n",
    "    vts = []\n",
    "    vbs = []\n",
    "    scores= []\n",
    "    for i in range(b):        \n",
    "        du[i]  = torch.exp(du[i])\n",
    "        pk_idx = pk_idxs[i]        \n",
    "        with torch.no_grad():\n",
    "            sig_u = torch.sigmoid(u[i][pk_idx])\n",
    "        #scores.append(u[i][pk_idx])\n",
    "        \n",
    "        scores.append(sig_u)\n",
    "\n",
    "        real_gt_u = pk_idx/MAX_PREDICTION_COUNT\n",
    "        real_gt_u = torch.from_numpy(real_gt_u).to(device)\n",
    "        if not get_raw_u:\n",
    "            #_u = torch.hstack(( real_gt_u[i] , real_gt_u[i]+ du[i] * masks[i] )) % 1            \n",
    "            #_u = torch.cat(( real_gt_u[i].float() , real_gt_u[i].float()+ du[i].float() * masks[i].float() ),0) % 1\n",
    "            _u = torch.cat(( real_gt_u.float() , real_gt_u.float()  + du[i][pk_idx].float()   ),0) % 1\n",
    "        else:\n",
    "            #_u = torch.hstack(( real_gt_u[i] , real_gt_u[i]+ du[i] * masks[i] ))\n",
    "            #_u = torch.cat(( real_gt_u[i].float() , real_gt_u[i].float()+ du[i].float() * masks[i].float() ),0)         \n",
    "            _u = torch.cat(( real_gt_u .float() , real_gt_u.float()  + du[i][pk_idx].float()   ),0)\n",
    "\n",
    "        vt1 = 0.5 - torch.exp(vt[i][pk_idx]) \n",
    "        vt2 = 0.5 - torch.exp(dvt[i][pk_idx]) \n",
    "\n",
    "        vb1 = torch.exp(vb[i][pk_idx]) +0.5\n",
    "        vb2 = torch.exp(dvb[i][pk_idx]) +0.5\n",
    "\n",
    "        #_vt = torch.hstack((vt1 , vt2 ))    \n",
    "        #_vb = torch.hstack(( vb1, vb2))\n",
    "        _vt = torch.cat((vt1 , vt2 ))    \n",
    "        _vb = torch.cat(( vb1, vb2))\n",
    "        \n",
    "        us.append(_u)\n",
    "        vts.append(_vt)\n",
    "        vbs.append(_vb)\n",
    "\n",
    "    #u_grads = get_grad_u_keep_batch(us , True)\n",
    "\n",
    "    #return u,vt,vb , u_grad\n",
    "    #return us ,vts,vbs , u_grads\n",
    "    return us ,vts,vbs ,scores\n",
    "\n",
    "def uv_to_xyz(u,v):\n",
    "    uu = ( u*360-180) * 0.01745\n",
    "    vv = ( v*180 -90) * 0.01745        \n",
    "    \n",
    "    # uv to 3D\n",
    "    x =  np.cos(uu) * np.cos(vv)    \n",
    "    y =  np.sin(uu) * np.cos(vv)\n",
    "    z =  np.sin(vv)\n",
    "    return x,y,z\n",
    "\n",
    "def xyz_to_uv(x,y,z):\n",
    "    theta   = np.arctan2(y,x)\n",
    "    phi     = np.arcsin(z/(np.sqrt(x**2 +y**2+z**2)))\n",
    "\n",
    "    theta   = (theta/ 0.01745 +180)/360\n",
    "    phi     = (phi/0.01745 + 90)/180\n",
    "    return theta,phi\n",
    "    \n",
    "def interplate_uv(u,v , count = 20):\n",
    "    xs,ys,zs =[],[],[]\n",
    "\n",
    "    for uu,vv in zip( u, v ):                    \n",
    "        x,y,z = uv_to_xyz(uu,vv)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        zs.append(z)\n",
    "\n",
    "    # 插值\n",
    "    '''\n",
    "    intp_x  = np.linspace(np.min(xs) , np.max(xs) , num=count )\n",
    "    intp_y  = np.linspace(np.min(ys) , np.max(ys) , num=count )\n",
    "    intp_z  = np.linspace(np.min(zs) , np.max(zs), num=count )\n",
    "    '''\n",
    "    intp_x  = np.linspace(xs[0] , xs[1] , num=count )\n",
    "    intp_y  = np.linspace(ys[0] , ys[1] , num=count )\n",
    "    intp_z  = np.linspace(zs[0] , zs[1], num=count )\n",
    "\n",
    "    # 3D to uv\n",
    "    thetas  =[]\n",
    "    phis    =[]\n",
    "    for x,y,z in zip (intp_x, intp_y, intp_z):\n",
    "        theta , phi = xyz_to_uv(x,y,z)\n",
    "        thetas.append(theta)\n",
    "        phis.append(phi)\n",
    "    return thetas , phis\n",
    "\n",
    "def to_distorted_box(u,vt,vb , image = None  ,seg_cnt = None):\n",
    "\n",
    "    canvas = np.zeros((512,1024,3)) if image is None else image    \n",
    "    polys_per_img = []  #這張image的門，每個門可能有數個部位\n",
    "    \n",
    "    for _u , _vt , _bv  in zip(u, vt , vb):\n",
    "        cross_idx = -1        \n",
    "        previous_x = 0        \n",
    "        seg_count =max(int((_u[1] -_u[0])*1024)//10 , 5) if seg_cnt is None else seg_cnt\n",
    "        \n",
    "        # Upper line\n",
    "        all_points = [[None]*seg_count*2][0]\n",
    "        thetas , phis= interplate_uv(_u,_vt , seg_count)\n",
    "        i=0\n",
    "        for t, p in zip(thetas , phis):            \n",
    "            canvas = cv2.circle(canvas , (int(t*1024) , int(p *512)) , 3 , (255,0,0) ,-1 )            \n",
    "\n",
    "            if(t< previous_x):\n",
    "                cross_idx = i \n",
    "            \n",
    "            previous_x = t\n",
    "            all_points[i] = [t , p]\n",
    "\n",
    "            i+=1\n",
    "\n",
    "        # Bottom line\n",
    "        thetas , phis= interplate_uv(_u,_bv , seg_count)        \n",
    "        i=1\n",
    "        for t, p in zip(thetas , phis):\n",
    "            canvas = cv2.circle(canvas , (int(t*1024) , int(p *512)) , 3 , (255,0,0) ,-1 )            \n",
    "            all_points[len(all_points)- i] = [t , p]\n",
    "            i+=1\n",
    "        \n",
    "        # check cross      \n",
    "        if(cross_idx >0):\n",
    "            left_start_top = [0 ,all_points[cross_idx][1] ]\n",
    "            left_start_btm = [0 ,all_points[seg_count + cross_idx][1] ]\n",
    "            \n",
    "            right_mid_top = [1 ,all_points[ cross_idx][1] ]\n",
    "            right_mid_btm = [1 ,all_points[seg_count + cross_idx][1] ]\n",
    "\n",
    "            part_right = all_points[:cross_idx] +[right_mid_top] +[right_mid_btm]+ all_points[seg_count + (seg_count - cross_idx):]\n",
    "            #part_left = all_points[cross_idx: seg_count + (seg_count - cross_idx)]             \n",
    "            part_left = [left_start_top] + \\\n",
    "                all_points[cross_idx: seg_count + (seg_count - cross_idx)] + [left_start_btm]            \n",
    "\n",
    "            # ============= Clipping ===============\n",
    "            \n",
    "            part_left = np.array(part_left)\n",
    "            part_right = np.array(part_right)\n",
    "            right_min = part_right[0][0]\n",
    "            right_clip_idx = np.where(part_right.flatten()[::2]<right_min)[0]\n",
    "\n",
    "            if (right_clip_idx.size > 0):\n",
    "                part_right[right_clip_idx,0]=1+0.00001\n",
    "\n",
    "            left_max = part_left[len(part_left)//2][0] \n",
    "            left_clip_idx = np.where(part_left.flatten()[::2] > left_max)[0]\n",
    "\n",
    "\n",
    "            '''\n",
    "            print(\"all_points\" , all_points)\n",
    "            print(\"cross_idx\" , cross_idx)\n",
    "            print(\"seg_count\" , seg_count)\n",
    "            print(\"part_left\" , part_left)\n",
    "            print(\"part_right\" , part_right)\n",
    "            '''\n",
    "\n",
    "            if (left_clip_idx.size > 0):\n",
    "                part_left[left_clip_idx,0]=left_max+0.0001\n",
    "            # ============= Clipping ===============\n",
    "\n",
    "            polys = [part_left , part_right]\n",
    "\n",
    "        else:\n",
    "            polys = [all_points]\n",
    "\n",
    "        polys_per_img.append(polys)\n",
    "    '''\n",
    "    # [DEBUG--- Show Result]\n",
    "        for poly in polys:            \n",
    "            poly = np.array(poly)\n",
    "            poly = poly.reshape((-1 , 2)) * np.tile(np.array([1024 , 512]) , (poly.size//2 , 1) )\n",
    "            poly = poly.astype('int32')               \n",
    "            canvas =  cv2.polylines(canvas, [poly], True, (0,255,0), 2)\n",
    "\n",
    "    plt.imshow(canvas)\n",
    "    plt.show()\n",
    "    '''\n",
    "    return polys_per_img\n",
    "\n",
    "def rearng(x):    \n",
    "    half_idx = len(x)//2\n",
    "    x1= x[:half_idx]\n",
    "    x2= x[half_idx:]\n",
    "    if(isinstance(x , np.ndarray)):\n",
    "        arr = np.zeros_like(x)\n",
    "    else:\n",
    "        arr = torch.zeros_like(x)\n",
    "    arr[::2] = x1    \n",
    "    arr[1::2] = x2      \n",
    "\n",
    "    return arr\n",
    "def rearrange_decoded(u,vt,vb):    \n",
    "    us ,vts ,vbs= [],[],[]\n",
    "    for batch_u , batch_vt , batch_vb in zip(u,vt,vb):   \n",
    "        if(isinstance(batch_u , np.ndarray)):\n",
    "            ru = rearng(batch_u)        \n",
    "            rvt = rearng(batch_vt)\n",
    "            rvb = rearng(batch_vb)\n",
    "        else:\n",
    "            ru = rearng(batch_u.detach().cpu().numpy())        \n",
    "            rvt = rearng(batch_vt.detach().cpu().numpy())\n",
    "            rvb = rearng(batch_vb.detach().cpu().numpy())\n",
    "\n",
    "        us.append(ru)\n",
    "        vts.append(rvt)\n",
    "        vbs.append(rvb)\n",
    "    \n",
    "    return us,vts,vbs\n",
    "\n",
    "'''\n",
    "boxu = [np.array([0.9556, 0.9921])]\n",
    "boxvt = [np.array([0.3810, 0.4109])]\n",
    "boxvb = [np.array([0.7335, 0.6852])]\n",
    "'''\n",
    "#Cross Image Set\n",
    "boxu = [np.array([0.7444, 1.0161])]\n",
    "boxvt = [np.array([0.2220, 0.2190])]\n",
    "boxvb = [np.array([0.8964, 0.8982])]\n",
    "'''\n",
    "\n",
    "# Multi door\n",
    "boxu = [np.array([0.8111, 0.3778, 1.2295, 0.6528])]\n",
    "boxvt = [np.array([0.4642, 0.2425, 0.4658, 0.2188])]\n",
    "boxvb = [np.array([0.5735, 0.8770, 0.5703, 0.8927])]\n",
    "'''\n",
    "\n",
    "gt_boxu = [ np.array([0.7111, 0.3578, 1.1095, 0.6528])]\n",
    "gt_boxvt =[ np.array([0.4642, 0.2425, 0.4658, 0.2188])]\n",
    "gt_boxvb =[ np.array([0.5735, 0.8770, 0.5703, 0.8927])]\n",
    "\n",
    "'''\n",
    "boxu = [np.array([0.1222, 0.6778, 0.7111, 0.1364, 0.6922, 0.7348])]\n",
    "boxvt = [np.array([0.4698, 0.4242, 0.4627, 0.4723, 0.4376, 0.4620])]\n",
    "boxvb = [np.array([0.5649, 0.6636, 0.5813, 0.5593, 0.6373, 0.5829])]\n",
    "'''\n",
    "boxu , boxvt , boxvb = rearrange_decoded(boxu , boxvt, boxvb)\n",
    "gt_boxu , gt_boxvt , gt_boxvb = rearrange_decoded(gt_boxu , gt_boxvt, gt_boxvb)\n",
    "#gt = [(0.8 , 0.23) , (1.1 , 0.23)  , (1.1 , 0.8) , (0.8 , 0.75) ]  # todo: gt不會cross borader\n",
    "from shapely.validation import make_valid,explain_validity\n",
    "def cal_poly_iou(poly_a , poly_b):\n",
    "    \n",
    "    if( len(poly_a) ==1 and len(poly_b) ==1): #比對的兩扇門都沒有跨畫面\n",
    "        a_pg = Polygon(poly_a[0])\n",
    "        b_pg = Polygon(poly_b[0])\n",
    "        \n",
    "        a_pg.buffer(0.0001)\n",
    "        a_pg = a_pg.simplify(0.0001 ,preserve_topology=False)\n",
    "        b_pg.buffer(0.0001)\n",
    "        b_pg = b_pg.simplify(0.0001 , preserve_topology=False)\n",
    "\n",
    "        poly_intersection   = a_pg.intersection(b_pg)\n",
    "        poly_union          = a_pg.union(b_pg)\n",
    "        if( poly_union.area== 0):\n",
    "            iou=0\n",
    "        else :\n",
    "            iou                 = poly_intersection.area / poly_union.area\n",
    "        #print(\"iou\" , iou)\n",
    "        return iou\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        iou_matrix = np.zeros((len(poly_a) , len(poly_b)))      \n",
    "        for i , a_points in enumerate( poly_a):\n",
    "            a_pg = Polygon(a_points)\n",
    "            a_pg.buffer(0.0001)\n",
    "            a_pg = a_pg.simplify(0.001 ,preserve_topology=False)\n",
    "\n",
    "            if(not a_pg.is_valid):                \n",
    "                a_pg = make_valid(a_pg)\n",
    "                print(\"a\",a_pg.is_valid , explain_validity(a_pg))\n",
    "\n",
    "            for j , b_points in enumerate( poly_b):\n",
    "                b_pg = Polygon(b_points)\n",
    "                b_pg.buffer(0.0001)\n",
    "                b_pg = b_pg.simplify(0.001 , preserve_topology=False)\n",
    "\n",
    "                if(not b_pg.is_valid):\n",
    "                    b_pg = make_valid(b_pg)\n",
    "                    print(\"b\" , b_pg.is_valid , explain_validity(b_pg))\n",
    "                \n",
    "                poly_intersection   = a_pg.intersection(b_pg)\n",
    "                poly_union          = a_pg.union(b_pg)\n",
    "                if( poly_union.area== 0):\n",
    "                    iou =0\n",
    "                else:                \n",
    "                    iou                 = poly_intersection.area / poly_union.area\n",
    "                iou_matrix[i][j] =  np.float32( iou)\n",
    "                #print(\"iou    \" ,iou    )\n",
    "        total_iou = np.sum(iou_matrix)/2\n",
    "        #print(\"iou_matrix\" , iou_matrix)\n",
    "        #print(\"total iou\" , total_iou)\n",
    "\n",
    "        return total_iou\n",
    "    pass\n",
    "\n",
    "def get_iou_matrix_distored(gt , pred):    \n",
    "    iou_matrix = np.zeros((len(gt) , len(pred)))        \n",
    "    for i , _gt in  enumerate(gt):        \n",
    "        for j , _pred in enumerate(pred):            \n",
    "            iou  = cal_poly_iou(_gt, _pred)\n",
    "            iou_matrix[i][j] = np.float32( iou)\n",
    "    \n",
    "    return iou_matrix\n",
    "\n",
    "\n",
    "for batched_uvv in zip(boxu , boxvt , boxvb ):  #each image in batch\n",
    "    #print(\"batched_uvv\" , batched_uvv)\n",
    "    u = batched_uvv[0].reshape(-1,2)\n",
    "    vt = batched_uvv[1].reshape(-1,2)\n",
    "    vb = batched_uvv[2].reshape(-1,2)    \n",
    "\n",
    "    polys_point = to_distorted_box(u , vt , vb)\n",
    "\n",
    "    u   = gt_boxu[0].reshape(-1,2)\n",
    "    vt  = gt_boxvt[0].reshape(-1,2)\n",
    "    vb  = gt_boxvb[0].reshape(-1,2)    \n",
    "\n",
    "    gt_polys_point = to_distorted_box(u , vt , vb,seg_cnt=5)\n",
    "    iou_matrix = get_iou_matrix_distored(gt_polys_point , polys_point)\n",
    "    print(\"final iou_matrix\",iou_matrix)\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#dataset = CustomDataset( \"./output/train_visiable_horizon_2k.json\"   ) \\n#dataset = CustomDataset( \"./output/train_visiable_horizon_200.json\"   ) \\ntrain_dataset = CustomDataset( f\"./output/{TRAIN_DATASET_NAME}\"  ,debug_doTrans= False ) \\n#eval_dataset = CustomDataset( f\"./output/{TEST_DATASET_NAME}\"   ) \\n#eval_dataset = CustomDataset( \"./output/train_visiable_horizon_20.json\"   ) \\n#train_dataloader = DataLoader(train_dataset, BATCH_SIZE , shuffle=True, drop_last =True)\\ntrain_dataloader = DataLoader(train_dataset, BATCH_SIZE , shuffle=False, drop_last =True)\\n#eval_dataloader = DataLoader(eval_dataset, BATCH_SIZE , shuffle=True, drop_last =True)\\n\\ndata = next(iter(train_dataloader)) \\n#pack_gt = (data[\\'u\\'] , data[\\'v_top\\'] , data[\\'v_btm\\'] , data[\\'d_top\\'] , data[\\'v_top\\'] )\\nprint(data[\\'u\\'])\\n#print(\"vtop\" ,data[\\'v_top\\'])\\n#print(\"vbtm\" ,data[\\'v_btm\\'])\\nprint(\"du\" , data[\\'du\\'])\\n#print(data)\\nprint(data[\\'u_grad\\'])\\nvisualize_2d(     \\n    data[\\'u\\'],\\n    data[\\'v_top\\'],\\n    data[\\'v_btm\\'],\\n    data[\\'image\\'],\\n    data[\\'u_grad\\'],\\n    #out_u\\n    #get_grad_u_keep_batch( real_gt_u)\\n)\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定義dataloader\n",
    "# [Load Data]\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms as T\n",
    "from torchvision.transforms import Lambda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image, ImageOps\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import random_split\n",
    "import json\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "IMG_SIZE =  np.array([1024,512]) # [w,h]\n",
    "#MAX_PREDICTION_COUNT = 256\n",
    "#MAX_PREDICTION_COUNT = 20\n",
    "\n",
    "#EPSILON = 0.00001\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "    \n",
    "debug_current_imgs_path =[\"\"]* BATCH_SIZE \n",
    "debug_count=0\n",
    "\n",
    "def gauss_noise_tensor(img):\n",
    "    if np.random.rand() < 0.5 and DO_AUG:\n",
    "        sigma = np.random.rand() *0.125\n",
    "        out = img + sigma * torch.randn_like(img)\n",
    "        return out\n",
    "    return img\n",
    "\n",
    "def blank(img):    \n",
    "    return img\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    global debug_current_imgs_path\n",
    "    def __init__(self, annotations_file_path , img_size=[1024,512] , debug_doTrans= True):\n",
    "        # Open json file        \n",
    "        json_path =  annotations_file_path\n",
    "        f= open(json_path)\n",
    "        anno = json.loads(f.read())\n",
    "        f.close()\n",
    "        self.anno = anno\n",
    "        self.img_size = img_size\n",
    "\n",
    "        do_jitter = np.random.rand() > 0.5 if DO_AUG else False        \n",
    "        self.debug_doTrans = debug_doTrans\n",
    "        \n",
    "        self.transform = transforms.Compose([    \n",
    "            transforms.ToPILImage(),                    \n",
    "            transforms.Resize((img_size[1], img_size[0])),            \n",
    "            transforms.ColorJitter((0.4 , 1) , (0.7,1) , (0.6,1) , (-0.5, 0.5)) if self.debug_doTrans else blank,\n",
    "            #transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),            \n",
    "            gauss_noise_tensor if self.debug_doTrans else blank,\n",
    "        ])\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.anno)\n",
    "    def get_bbox_count(self ):\n",
    "        count =0\n",
    "        for data in self.anno:            \n",
    "            count += len(data['bboxes'])\n",
    "        return count\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        global epoch\n",
    "        global train_itr\n",
    "\n",
    "        #img_path = os.path.join(\"./\", self.anno[idx]['image'])\n",
    "        #img_path = os.path.join(\"/CGVLAB3/datasets/chingjia/data/data/\", self.anno[idx]['image'])\n",
    "        img_path = os.path.join(\"F:/THU/DoorSeg/OneDrive_2023-01-07/Door_Detection/data/data\", self.anno[idx]['image'])\n",
    "        #print(img_path)\n",
    "        #image = read_image(img_path)           \n",
    "        image = cv2.imread(img_path)        \n",
    "        #plt.imshow(image)\n",
    "        #plt.title(\"origin img\")\n",
    "        #plt.show()\n",
    "\n",
    "        if(self.transform!=None):\n",
    "            image= self.transform( image)\n",
    "\n",
    "        if self.debug_doTrans:\n",
    "            do_flip = np.random.rand() > 0 \n",
    "            do_roll = np.random.rand() > 0       \n",
    "        else:   \n",
    "            do_flip=False\n",
    "            do_roll=False\n",
    "\n",
    "        _, h,w = image.shape\n",
    "\n",
    "        target = self.anno[idx]\n",
    "        data = {}\n",
    "\n",
    "        u = torch.tensor(target['u'])\n",
    "        u_0idx = torch.where(u==0)[0]  #避免u = 0在match上出error\n",
    "        u[u_0idx] = 0.0000001\n",
    "        \n",
    "        v = torch.tensor(target['sticks_v'])        \n",
    "        du = u.flatten()[1::2] - u.flatten()[0::2]\n",
    "\n",
    "        #============ Transform ===========\n",
    "        if do_flip:\n",
    "            image = torch.flip(image, dims=[2])            \n",
    "            u = torch.flip( 1 - u , [1])\n",
    "            u_is_cross =  (u.flatten()[::2]<0).to(torch.float32)\n",
    "            u_is_cross = u_is_cross.repeat_interleave(2)            \n",
    "            u = (u.flatten() + 1* u_is_cross).reshape((-1,2))\n",
    "\n",
    "            # 左右交換 => 0跟2互換 , 1跟3互換\n",
    "            v_idx_all = torch.arange(v.numel())      \n",
    "            v_idx = v_idx_all.clone()\n",
    "            v_idx[0::4] = v_idx_all[2::4]\n",
    "            v_idx[1::4] = v_idx_all[3::4]\n",
    "            v_idx[2::4] = v_idx_all[0::4]\n",
    "            v_idx[3::4] = v_idx_all[1::4]\n",
    "            v= (v.flatten()[v_idx]).reshape(-1,4)\n",
    "\n",
    "        if do_roll:\n",
    "            shift_rand = torch.rand(1)\n",
    "            shift = int((w * shift_rand ).tolist()[0])\n",
    "            image = torch.roll(image , shift , 2 )            \n",
    "            u = (u + shift_rand) % 1\n",
    "        #============            ===========        \n",
    "        u_grad = get_grad_u(u.flatten()[::2].reshape((-1,1)) , _width=MAX_PREDICTION_COUNT)        \n",
    "        u_grad = torch.max(u_grad,0)[0]  \n",
    "        \n",
    "        #padding_count = (MAX_PREDICTION_COUNT - u.shape[0])\n",
    "        padding_count = (MAX_PREDICTION_COUNT - u.numel()//2)\n",
    "        padding_count = max(padding_count ,  0)        \n",
    "        \n",
    "        padding_count = abs( MAX_PREDICTION_COUNT*2 - u.numel())\n",
    "        u_pad = torch.cat(( u.reshape(-1) , torch.zeros((padding_count )) )  )                \n",
    "        du_pad = torch.cat(( du.reshape(-1) , torch.zeros((MAX_PREDICTION_COUNT - du.numel() )) )  )                \n",
    "\n",
    "        \n",
    "        v= v.flatten()        \n",
    "        \n",
    "        padding_count = abs( MAX_PREDICTION_COUNT *4 - v.numel() )\n",
    "        v_top_pad = torch.cat(( v[::2] , torch.zeros((padding_count//2 )) )  )        \n",
    "        v_btm_pad = torch.cat(( v[1::2] , torch.zeros((padding_count//2 )) )  )      \n",
    "        \n",
    "\n",
    "        #data['data_count'] = u.numel()\n",
    "        data['image'] = image\n",
    "        #data['u_grad'] = c_dist\n",
    "        data['u_grad'] = u_grad\n",
    "        data['u'] = u_pad [::2]\n",
    "        #data['door_count'] = u.numel()//2\n",
    "        #data['u'] = u_pad\n",
    "        data['v_top'] = v_top_pad[::2]\n",
    "        data['v_btm'] = v_btm_pad[::2]\n",
    "\n",
    "\n",
    "        #data['du'] = torch.abs( u_pad[1::2] - u_pad[0::2])\n",
    "        data['du'] = du_pad\n",
    "        \n",
    "        data['dv_top'] = v_top_pad[1::2]\n",
    "        data['dv_btm'] = v_btm_pad[1::2]\n",
    "\n",
    "        '''\n",
    "        data['d_top'] = depth_top_pad\n",
    "        data['d_btm'] = depth_btm_pad\n",
    "\n",
    "        '''\n",
    "\n",
    "        #=====================\n",
    "        #|    output shape   |\n",
    "        #=====================\n",
    "        #   u: [n,2]\n",
    "        #   u_grad: [n,1024]\n",
    "        #   v_top: [n]\n",
    "        #   v_btm: [n]\n",
    "\n",
    "        return data\n",
    "\n",
    "        #return data        \n",
    "\n",
    "# [ Test  : Can Delete]\n",
    "'''\n",
    "#dataset = CustomDataset( \"./output/train_visiable_horizon_2k.json\"   ) \n",
    "#dataset = CustomDataset( \"./output/train_visiable_horizon_200.json\"   ) \n",
    "train_dataset = CustomDataset( f\"./output/{TRAIN_DATASET_NAME}\"  ,debug_doTrans= False ) \n",
    "#eval_dataset = CustomDataset( f\"./output/{TEST_DATASET_NAME}\"   ) \n",
    "#eval_dataset = CustomDataset( \"./output/train_visiable_horizon_20.json\"   ) \n",
    "#train_dataloader = DataLoader(train_dataset, BATCH_SIZE , shuffle=True, drop_last =True)\n",
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE , shuffle=False, drop_last =True)\n",
    "#eval_dataloader = DataLoader(eval_dataset, BATCH_SIZE , shuffle=True, drop_last =True)\n",
    "\n",
    "data = next(iter(train_dataloader)) \n",
    "#pack_gt = (data['u'] , data['v_top'] , data['v_btm'] , data['d_top'] , data['v_top'] )\n",
    "print(data['u'])\n",
    "#print(\"vtop\" ,data['v_top'])\n",
    "#print(\"vbtm\" ,data['v_btm'])\n",
    "print(\"du\" , data['du'])\n",
    "#print(data)\n",
    "print(data['u_grad'])\n",
    "visualize_2d(     \n",
    "    data['u'],\n",
    "    data['v_top'],\n",
    "    data['v_btm'],\n",
    "    data['image'],\n",
    "    data['u_grad'],\n",
    "    #out_u\n",
    "    #get_grad_u_keep_batch( real_gt_u)\n",
    ")\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon\n",
    "def to_polybox(u_pack , vt_pack , vb_pack):\n",
    "    \n",
    "    batches = []\n",
    "    for u,vt,vb in zip(u_pack , vt_pack , vb_pack):\n",
    "        '''\n",
    "    # input:\n",
    "    u_flatten  = torch.cat(u_pack)\n",
    "    vt_flatten  = torch.cat(vt_pack)\n",
    "    vb_flatten  = torch.cat(vb_pack)\n",
    "        '''\n",
    "\n",
    "        non_zero_idx = torch.where(u>0)[0]\n",
    "        u_flatten = u[non_zero_idx].cpu().detach()\n",
    "        vt_flatten = vt[non_zero_idx].cpu().detach()\n",
    "        vb_flatten = vb[non_zero_idx].cpu().detach()\n",
    "\n",
    "        poly_boxes= []\n",
    "        box_count = u_flatten.shape[0]//2\n",
    "        for i in range(box_count):\n",
    "            _box = ( \n",
    "                u_flatten[2*i] , vt_flatten[2*i] , # top left\n",
    "                u_flatten[2*i+1] , vt_flatten[2*i+1] , # top right\n",
    "                u_flatten[2*i+1] , vb_flatten[2*i+1] , # btm right\n",
    "                u_flatten[2*i] , vb_flatten[2*i] , # left btm\n",
    "            )\n",
    "            poly_boxes.append(torch.as_tensor(_box))\n",
    "        batches.append(poly_boxes)\n",
    "\n",
    "    return batches\n",
    "\n",
    "def uv_to_distorted_box(u,vt,vb):\n",
    "    polys =[]\n",
    "    _boxu , _boxvt , _boxvb = rearrange_decoded(u, vt , vb)\n",
    "    for bu,bvt,bvb  in zip(_boxu , _boxvt , _boxvb ):    \n",
    "        _u = bu.reshape(-1,2)\n",
    "        _vt = bvt.reshape(-1,2)\n",
    "        _vb = bvb.reshape(-1,2)    \n",
    "\n",
    "        p =to_distorted_box(_u , _vt , _vb )\n",
    "        polys.append(p)\n",
    "        \n",
    "    return polys\n",
    "\n",
    "class PR_Eval_Helper():    \n",
    "    def __init__(self, writer=None , ep=0):\n",
    "        self.iou_thresh = [0.05,0.5,0.75]\n",
    "        self.gt_count=0\n",
    "        self.all_iou=0\n",
    "        self.results_per_batch = [{\"tp\":[],\"fp\":[],\"scores\":[]} for _ in self.iou_thresh]\n",
    "        self.writer = writer\n",
    "        self.ep = ep\n",
    "        pass\n",
    "    \n",
    "    #==== [ Not Using ] =======\n",
    "    def get_iou_matrix(self):\n",
    "        # row: prediction\n",
    "        # col: gt\n",
    "        #iou_matrix = np.zeros((self.gt.shape[0] , self.predict_result.shape[0]))\n",
    "        iou_matrix = np.zeros((len(self.gt) , len(self.predict_result)))        \n",
    "        \n",
    "        for i , gt in enumerate(self.gt):            \n",
    "            polygon_gt = Polygon (gt.reshape((-1,2)))     \n",
    "            polygon_gt.buffer(0.01)     \n",
    "            for j , pred in enumerate(self.predict_result):                \n",
    "                polygon_pred = Polygon( pred.reshape((-1,2)))  \n",
    "                polygon_pred.buffer(0.01)     \n",
    "                try:\n",
    "                #if(polygon_pred.is_valid):\n",
    "                    poly_intersection   = polygon_pred.intersection(polygon_gt)\n",
    "                    poly_union          = polygon_pred.union(polygon_gt)\n",
    "                    iou                 = poly_intersection.area / poly_union.area\n",
    "                except:\n",
    "                #else:\n",
    "                    print(\"error\",polygon_pred )\n",
    "                    print(\"error origin\", pred)\n",
    "                    print(\"error gt\", polygon_gt)\n",
    "                    iou=0\n",
    "                iou_matrix[i][j] = np.float32( iou)\n",
    "                pass       \n",
    "        return iou_matrix\n",
    "\n",
    "    def eval_batch_pr( self, predict_result , gt , score ,  _debug_iteration =0 ):        \n",
    "        '''\n",
    "        #依照score排序                \n",
    "        '''\n",
    "        self.scores = score\n",
    "        self.predict_result = predict_result\n",
    "        self.gt = gt\n",
    "        \n",
    "        self.gt_count+= len(gt)              \n",
    "            \n",
    "        #iou_matrix = self.get_iou_matrix()\n",
    "        iou_matrix = get_iou_matrix_distored(gt,predict_result)\n",
    "        #print(\"iou_matrix\" , iou_matrix)\n",
    "        \n",
    "        pred_count = len(self.predict_result)\n",
    "        \n",
    "        for i,iou_thersh in enumerate( self.iou_thresh):\n",
    "            #print(\"iou_thersh\", iou_thersh)\n",
    "            #if self.predict_result.shape[0] > 1:\n",
    "            if pred_count >= 1:\n",
    "                iou_thresh_mask = np.where(iou_matrix >= iou_thersh , 1 , 0 )                \n",
    "                masked_iou_matrix = iou_matrix * iou_thresh_mask                \n",
    "                each_gt_best_iou_idx = np.argmax(masked_iou_matrix , axis=1)                \n",
    "                \n",
    "                # 過濾掉同個gt box有多個符合的box，只保留最好的\n",
    "                mono_gt = np.zeros_like(iou_matrix)\n",
    "                mono_gt[[i for i in range(len(mono_gt))] , [each_gt_best_iou_idx]] = iou_matrix[[i for i in range(len(mono_gt))] , [each_gt_best_iou_idx]]\n",
    "                # 紀錄miou\n",
    "                if(i==0):\n",
    "                    self.all_iou += np.sum(mono_gt)\n",
    "\n",
    "                mono_gt *= iou_thresh_mask  # 沒達到threshold的設為0\n",
    "\n",
    "                #找到單列最好的 (?)\n",
    "                pred_filtered_mask = np.zeros(pred_count)                \n",
    "                for row_gt in mono_gt:\n",
    "                    _max_idx = np.argmax(row_gt)\n",
    "                    if( row_gt[_max_idx]>0 ):\n",
    "                        pred_filtered_mask[_max_idx]=1                                                                \n",
    "                \n",
    "                tp_list = np.where(pred_filtered_mask > 0 , 1 , 0 )   \n",
    "                fp_list = np.where(pred_filtered_mask ==0 , 1 , 0 )    \n",
    "                \n",
    "                #print(\"batch append tp\" , tp_list.shape , tp_list)\n",
    "                #print(\"batch append self.scores\" , self.scores)\n",
    "                self.results_per_batch[i]['tp'].append(tp_list.flatten())\n",
    "                self.results_per_batch[i]['fp'].append(fp_list.flatten())\n",
    "                self.results_per_batch[i]['scores'].append(self.scores)    \n",
    "                \n",
    "            else:\n",
    "                batch_ap = 0\n",
    "                \n",
    "            '''\n",
    "                batch_pr , batch_rc , batch_ap = self.list_to_pr_auc(tp_list, fp_list , len(self.gt))\n",
    "                if self.writer is not None:\n",
    "                    self.writer.add_scalars(\"batch_eval\",{f\"ap_iou_{iou_thersh}\": batch_ap} ,  _debug_iteration)\n",
    "                    self.writer.close()  \n",
    "                print(f\"batch ap_{iou_thersh}\",batch_ap)\n",
    "            elif pred_count == 1:               \n",
    "                #filter_mask = iou_matrix.flatten() > \n",
    "                iou_thresh_mask = np.where(iou_matrix >= iou_thersh , 1 , 0 )    \n",
    "                tp_list = np.where(iou_thresh_mask > 0 , 1 , 0 )   \n",
    "                fp_list = np.where(iou_thresh_mask ==0 , 1 , 0 )   \n",
    "                \n",
    "                self.results_per_batch[i]['tp'].append(tp_list.flatten())\n",
    "                self.results_per_batch[i]['fp'].append(fp_list.flatten())             \n",
    "                self.results_per_batch[i]['scores'].append(self.scores)                       \n",
    "            '''\n",
    "\n",
    "    \n",
    "    def list_to_pr_auc(self, tp_list , fp_list , gt_count):\n",
    "        tp = np.cumsum(tp_list)     \n",
    "        fp = np.cumsum(fp_list) \n",
    "        all_prediction = tp+fp\n",
    "        precision = tp / all_prediction\n",
    "        recall = tp / gt_count            \n",
    "        self.all_prediction = precision\n",
    "        \n",
    "        recall = np.insert(recall , 0 , 0)\n",
    "        precision = np.insert(precision , 0 , 1)\n",
    "\n",
    "        print(\"gt_count\" , gt_count)\n",
    "        #print(\"tp\" , tp)\n",
    "        #print(\"fp\" , fp)\n",
    "\n",
    "        print(\"all_prediction\" , all_prediction)\n",
    "        print(\"recall\" , recall)\n",
    "        print(\"precision\" , precision)\n",
    "\n",
    "        auc = metrics.auc(recall,precision)\n",
    "        return precision , recall,auc\n",
    "    \n",
    "    def get_all_pr(self):\n",
    "        # combine each batch result and sort by scores\n",
    "        # print(\"self.results_per_batch\", self.results_per_batch)\n",
    "        self.final_result_dict =  [{} for _ in self.iou_thresh]        \n",
    "        for i , thresh in enumerate(self.iou_thresh):\n",
    "            #print(\"len\" , len(self.results_per_batch[i]['scores']))\n",
    "            if len(self.results_per_batch[i]['scores']) > 0 :            \n",
    "                all_tp = np.concatenate(self.results_per_batch[i]['tp'][:])\n",
    "                all_fp = np.concatenate(self.results_per_batch[i]['fp'][:])\n",
    "\n",
    "                sum_tp = np.sum(all_tp)\n",
    "                sum_fp = np.sum(all_fp)\n",
    "\n",
    "                recall_rate = sum_tp / self.gt_count\n",
    "                precision_rate = sum_tp / (sum_tp + sum_fp)\n",
    "                \n",
    "            if len(self.results_per_batch[i]['scores']) >1 :                        \n",
    "                precision , recall , auc = self.list_to_pr_auc(all_tp , all_fp , self.gt_count)\n",
    "            else:\n",
    "                precision = []\n",
    "                recall=[]\n",
    "                auc=0\n",
    "                recall_rate =0\n",
    "                precision_rate=0\n",
    "\n",
    "            self.final_result_dict[i]=(\n",
    "                {\"iou_thresh\": thresh ,\n",
    "                    \"recall\":recall,\n",
    "                    \"precision\":precision,\n",
    "                    \"recall_rate\": recall_rate,\n",
    "                    \"precision_rate\": precision_rate,\n",
    "                    \"ap\":auc} \n",
    "            )\n",
    "            print(f\"ap_{thresh}\",auc)\n",
    "        if self.writer is not None:\n",
    "            self.write_tensorboard()\n",
    "        \n",
    "        return precision,recall,auc\n",
    "    \n",
    "    def write_tensorboard(self, subName =\"sub\"):        \n",
    "        writer = self.writer\n",
    "        for i , thresh in enumerate(self.iou_thresh):            \n",
    "            #prcs = np.ascontiguousarray(self.final_result_dict[i][\"precision\"] )\n",
    "            #recs = np.ascontiguousarray(self.final_result_dict[i][\"recall\"] )\n",
    "            prcs = self.final_result_dict[i][\"precision\"] \n",
    "            recs = self.final_result_dict[i][\"recall\"] \n",
    "            \n",
    "            step = 0\n",
    "            for prc, rec in zip(prcs , recs ):\n",
    "                if(self.writer is not None):\n",
    "                    #writer.add_scalar(f\"{subName}/Precision_{thresh}-ep{self.ep}\" , prc , step)\n",
    "                    #writer.add_scalar(f\"{subName}/Recall_{thresh}-ep{self.ep}\" , rec , step)\n",
    "                    #writer.add_scalar(f\"{subName}/AUC_{thresh}-ep{self.ep}\" ,  prc , rec )  # tensor board bug                                                    \n",
    "                    writer.add_scalars(f\"Eval/Precision_{thresh}\",{f\"ep{self.ep}\":prc}  , step)\n",
    "                    writer.add_scalars(f\"Eval/Recall_{thresh}\" ,{f\"ep{self.ep}\":rec}, step)\n",
    "                    #writer.add_scalars(f\"Eval/AUC_{thresh}\" ,{f\"ep{self.ep}\": prc},  self.ep )  # tensor board bug                                                    \n",
    "                \n",
    "                step+=1\n",
    "\n",
    "            writer.add_scalar(f\"Eval/Precision_rate_{thresh}\", self.final_result_dict[i]['precision_rate'] , self.ep)\n",
    "            writer.add_scalar(f\"Eval/Recall_rate_{thresh}\" ,   self.final_result_dict[i]['recall_rate'] , self.ep)\n",
    "            writer.add_scalar(f\"Eval/AUC_{thresh}\" ,  self.final_result_dict[i]['ap'] , self.ep )  # tensor board bug                                                    \n",
    "            writer.add_scalar(f\"Eval/mIou\" ,  self.all_iou/self.gt_count , self.ep )  # tensor board bug                                                    \n",
    "\n",
    "            print(\"all_iou\" , self.all_iou)\n",
    "            print(\"mIOU\" , self.all_iou/self.gt_count)\n",
    "            \n",
    "            \n",
    "            plt.plot( recs ,prcs )            \n",
    "            #plt.xlim([0, 1])\n",
    "            #plt.ylim([0, 1])\n",
    "            plt.title(f\"PR_curve-{thresh} ap : {self.final_result_dict[i]['ap']}\")\n",
    "            plt.savefig(log_folder+f\"/_PR_curve-{thresh}-{subName}-ep{self.ep}.jpg\")\n",
    "            #self.writer.add_figure(f\"PR_curve-{thresh}-ep{self.ep}-{subName}.jpg\" , plt.figure())\n",
    "            plt.show()\n",
    "            \n",
    "            \n",
    "        self.writer.close()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import gridspec\n",
    "def visualize_2d(us, v_tops , v_btms, imgs, u_grad=None  , title =None , do_sig_u =False , polys = None ,  save_path=\"\"):\n",
    "    out_imgs=[]    \n",
    "    length =  imgs.shape[0] if torch.is_tensor(imgs) else  len(imgs)        \n",
    "\n",
    "    for i in range(length):\n",
    "        if polys  is not None and u_grad is not None:            \n",
    "            img =visualize_2d_single(us[i] , v_tops[i] ,v_btms[i] , imgs[i] , u_grad[i] , title ,do_sig_u , polys[i]  , save_path= f\"{save_path}/{title}_{i}.jpg\")\n",
    "        elif u_grad is not None:            \n",
    "            img =visualize_2d_single(us[i] , v_tops[i] ,v_btms[i] , imgs[i] , u_grad[i] , title ,do_sig_u ,polys, save_path= f\"{save_path}/{title}_{i}.jpg\" )\n",
    "        else:\n",
    "            img = visualize_2d_single(us[i] , v_tops[i] ,v_btms[i] , imgs[i] , None , title , do_sig_u , polys, save_path= f\"{save_path}/{title}_{i}.jpg\")\n",
    "\n",
    "        out_imgs.append(img)\n",
    "    return out_imgs\n",
    "\n",
    "\n",
    "\n",
    "def visualize_2d_single(us, v_tops , v_btms, imgs, u_grad=None , title=None , do_sig_u =False , poly =None , save_path=\"\"):\n",
    "    us = us.cpu().detach().numpy().flatten()\n",
    "    v_tops = v_tops.cpu().detach().numpy().flatten()\n",
    "    v_btms = v_btms.cpu().detach().numpy().flatten()\n",
    "    \n",
    "    uvs=[]\n",
    "    for u, v_t , v_b in zip( us , v_tops ,v_btms):                    \n",
    "        uvs.append( (u , v_t) )\n",
    "        uvs.append( (u , v_b) )        \n",
    "        \n",
    "    img = imgs.permute(1,2,0).cpu().detach().numpy()\n",
    "    img = np.ascontiguousarray(img)\n",
    "\n",
    "    if(poly is not None):        \n",
    "        for doors in poly:            \n",
    "            for part_door in doors:            \n",
    "                part_door = np.array(part_door)                \n",
    "                part_door = part_door.reshape((-1 , 2)) * np.tile(np.array([1024 , 512]) , (part_door.size//2 , 1) )\n",
    "                part_door = part_door.astype('int32')               \n",
    "                img =  cv2.polylines(img, [part_door], True, (0,255,0), 2)\n",
    "        pass\n",
    "    \n",
    "    h,w,c = img.shape\n",
    "    img_size = [w,h]\n",
    "    for point in uvs:\n",
    "        #p = np.float32(point) * img_size % img_size       # clamp to boarder     \n",
    "        p = np.float32(point) * img_size         \n",
    "        p = np.int32(p)\n",
    "        img = cv2.circle( img, tuple( (p[0] , p[1])), 5,(255,0,0) , thickness= -1)\n",
    "\n",
    "    # Preview Confidence map\n",
    "    if u_grad is not None:        \n",
    "        fig = plt.figure()\n",
    "        spec = gridspec.GridSpec(ncols=1, nrows=3,)\n",
    "        fig.tight_layout()        \n",
    "        if do_sig_u ==True:\n",
    "            u_grad = torch.sigmoid( u_grad)\n",
    "        dist_graph = u_grad.repeat((10,1)).cpu().detach().numpy()            \n",
    "            \n",
    "        ax0 = fig.add_subplot(spec[0])\n",
    "        ax0.imshow(dist_graph , cmap=\"gray\" )\n",
    "        ax0.axis(\"off\")        \n",
    "\n",
    "        ax0 = fig.add_subplot(spec[1:])\n",
    "        ax0.imshow(img , aspect='auto' )\n",
    "        ax0.axis(\"off\")        \n",
    "        \n",
    "        if(title is not None):\n",
    "            fig.suptitle(title)\n",
    "        if save_path != \"\":\n",
    "            plt.savefig(save_path)\n",
    "            plt.close() \n",
    "        '''\n",
    "        plt.show()\n",
    "        '''\n",
    "        return fig_to_img(fig)\n",
    "    else:\n",
    "        #plt.title(title)\n",
    "        #plt.imshow(img)\n",
    "        #plt.show()\n",
    "        return img\n",
    "    pass\n",
    "\n",
    "from PIL import Image\n",
    "def fig_to_img(fig):    \n",
    "    img = np.asarray(fig.canvas.buffer_rgba())\n",
    "    return img\n",
    "\n",
    "def uv_to_3d(u , v_top , v_btm , d_top , d_btm):\n",
    "    # input [b , n]    \n",
    "    points_3d=[]    \n",
    "    for b in range((len(u))) :              \n",
    "        u = u[b]*360 - 180\n",
    "        vt = v_top[b]*180 - 90\n",
    "        vb = v_btm[b]*180 - 90\n",
    "\n",
    "        u=u* 0.01745329252\n",
    "        vt=vt* 0.01745329252        \n",
    "        vb=vb* 0.01745329252        \n",
    "\n",
    "        #points_3d.append((u,v_top))        \n",
    "        #points_3d.append((u,v_btm))\n",
    "        #for _u , _vt , _vb, _dt, _db in zip(  )\n",
    "        '''\n",
    "        for uvd in zip(u,v , depth[0]):\n",
    "            x = uv[2] * cos(uv[1]) * cos(uv[0])\n",
    "            y = uv[2] * sin(uv[1])\n",
    "            z = uv[2] * cos(uv[1]) * sin(uv[0])\n",
    "            points_3d.append((x,y,z))\n",
    "            print(\"uv\" , uv  , x , y , z)\n",
    "            pass\n",
    "    draw_3d(points_3d)\n",
    "        '''\n",
    "    pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(net, path , epoch =0 , ap = 0):\n",
    "    state_dict = {\n",
    "        #'args': args.__dict__,\n",
    "        'kwargs': {\n",
    "            'backbone': net.backbone,\n",
    "            'use_rnn': net.use_rnn,\n",
    "        },\n",
    "        'state_dict': net.state_dict(),\n",
    "        'epoch':epoch,\n",
    "        'ap':ap\n",
    "    }\n",
    "    torch.save(state_dict, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_u (batched_u , title = \"Visulize u\"):\n",
    "    for _g in batched_u:\n",
    "        if(_g.is_cuda):\n",
    "            _g = _g.detach().cpu().numpy()\n",
    "        else:\n",
    "            _g = _g.numpy()\n",
    "        _g = np.tile(_g , (1,1))        \n",
    "        plt.title(title)\n",
    "        plt.imshow(_g)\n",
    "        plt.show()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#device ='cpu'\n",
    "#state_dict = torch.load('./output/horizonn256u20d20.pth', map_location='cpu')\n",
    "#net.load_state_dict(state_dict['state_dict'])\n",
    "train_dataset = CustomDataset( f\"./output/{TEST_DATASET_NAME}\" ,debug_doTrans=False   )  \n",
    "train_dataset_noTrans = CustomDataset( f\"./output/{TRAIN_DATASET_NAME}\"  ,debug_doTrans=False )  \n",
    "#train_dataset = CustomDataset( f\"./output/testerr.json\"   )  \n",
    "BATCH_SIZE = 3\n",
    "train_dataloader = DataLoader(train_dataset,  BATCH_SIZE , shuffle=True, drop_last =True)\n",
    "train_dataloader_noTrans = DataLoader(train_dataset_noTrans,  1 , shuffle=False, drop_last =True)\n",
    "#_t_loader = DataLoader(_t_dataset, BATCH_SIZE , shuffle=True, drop_last =True)\n",
    "\n",
    "data = next(iter(train_dataloader))\n",
    "data2 = next(iter(train_dataloader_noTrans))\n",
    "\n",
    "\n",
    "#data = next(iter(eval_dataloader))\n",
    "for k, v in data.items():    \n",
    "    data[k]=data[k].to(device)\n",
    "\n",
    "for k, v in data2.items():    \n",
    "    data2[k]=data2[k].to(device)\n",
    "'''\n",
    "'''\n",
    "out = predict(data)   #[b , max_count , 5 ]\n",
    "out = torch.transpose(out , 1 , 2) #[b , 5 , max_count ]\n",
    "\n",
    "\n",
    "\n",
    "pack_gt = (data['u'] , data['v_top'] , data['v_btm'] , data['du'] , data['dv_top'] , data['dv_btm'] , data['u_grad'] )\n",
    "pack_gt = torch.cat(pack_gt , 1)\n",
    "\n",
    "pack_gt2 = (data2['u'] , data2['v_top'] , data2['v_btm'] , data2['du'] , data2['dv_top'] , data2['dv_btm'] , data2['u_grad'] )\n",
    "pack_gt2 = torch.cat(pack_gt2 , 1)\n",
    "\n",
    "\n",
    "b, _ = pack_gt.shape\n",
    "#out = torch.rand(b , 7 , MAX_PREDICTION_COUNT ).to(device)\n",
    "\n",
    "pack_gt = pack_gt.reshape((b , 7 , -1 ))\n",
    "pack_gt = encode(pack_gt)\n",
    "\n",
    "pack_gt2 = pack_gt2.reshape((b , 7 , -1 ))\n",
    "pack_gt2 = encode(pack_gt2)\n",
    "#print(\"encoded pack_gt\" , pack_gt)\n",
    "\n",
    "(matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\\\n",
    "(matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,),gt_idxs  = match_gt(pack_gt , out )\n",
    "\n",
    "#print(\"matched_gt_u\",matched_gt_u)\n",
    "#print(\"matched_prd_u\",matched_prd_u)\n",
    "\n",
    "# [debug] :\n",
    "#show_u(matched_gt_u , \"gt u\")\n",
    "#show_u(matched_prd_u , \"pred u\")\n",
    "\n",
    "_loss = cal_loss(\n",
    "    (matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,),\n",
    "    (matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\n",
    "    gt_idxs\n",
    "    )\n",
    "print(_loss)\n",
    "#u,vt,vb =  decode(out)\n",
    "#real_gt_u = u_interval_to_real_u(matched_prd_u)\n",
    "#u,vt,vb,u_grad =  decode((matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,CONFIDENCE_THRESHOLD)\n",
    "pred_u,pred_vt,pred_vb,pred_u_grad =  decode((matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm) , CONFIDENCE_THRESHOLD , True)\n",
    "u,vt,vb,u_grad =  decode((matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) , 0.5 , True)\n",
    "#u,vt,vb,scores =  decode((matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm) ,0.05 )\n",
    "\n",
    "#u_grad = get_grad_u_keep_batch(data['u'] , width= 256)\n",
    "\n",
    "#print(\"u\",u)\n",
    "#print(\"vt\",vt)\n",
    "#print(\"vb\",vb)\n",
    "\n",
    "print(\"raw pred boxu\" , pred_u)\n",
    "with torch.no_grad():\n",
    "    boxu , boxvt , boxvb = rearrange_decoded(u, vt , vb)\n",
    "    pred_boxu , pred_boxvt , pred_boxvb = rearrange_decoded(pred_u, pred_vt , pred_vb)\n",
    "    #print(\"gt  boxu\" , boxu)\n",
    "    #print(\"pred boxu\" , pred_boxu)\n",
    "\n",
    "    gt_polys =[]\n",
    "    pred_polys =[]\n",
    "\n",
    "    for bu,bvt,bvb ,img in zip(boxu , boxvt , boxvb ,data['image']):    \n",
    "        _u = bu.reshape(-1,2)\n",
    "        _vt = bvt.reshape(-1,2)\n",
    "        _vb = bvb.reshape(-1,2)    \n",
    "\n",
    "        img = img.permute(1,2,0).cpu().detach().numpy()\n",
    "        img = np.ascontiguousarray(img)\n",
    "        p =to_distorted_box(_u , _vt , _vb , img)\n",
    "        gt_polys.append(p)\n",
    "\n",
    "    for bu,bvt,bvb ,img in zip(pred_boxu , pred_boxvt , pred_boxvb ,data['image']):    \n",
    "        _u = bu.reshape(-1,2)\n",
    "        _vt = bvt.reshape(-1,2)\n",
    "        _vb = bvb.reshape(-1,2)    \n",
    "\n",
    "        img = img.permute(1,2,0).cpu().detach().numpy()\n",
    "        img = np.ascontiguousarray(img)\n",
    "        p = to_distorted_box(_u , _vt , _vb , img)\n",
    "        pred_polys.append(p)\n",
    "    \n",
    "    for b in range(BATCH_SIZE) :\n",
    "        iou_matrix = get_iou_matrix_distored(gt_polys[b] , pred_polys[b])\n",
    "        print(\"final iou_matrix\",iou_matrix)\n",
    "\n",
    "    plt_imgs = visualize_2d(         \n",
    "        pred_u,\n",
    "        pred_vt,\n",
    "        pred_vb,\n",
    "        data['image'],\n",
    "        #matched_prd_u,\n",
    "        matched_prd_u,\n",
    "        #u_grad\n",
    "        #get_grad_u_keep_batch(real_gt_u)    \n",
    "        polys= pred_polys\n",
    "    )\n",
    "    plt_imgs = visualize_2d( \n",
    "        #matched_gt_u,\n",
    "        u,\n",
    "        #scores,\n",
    "        vt,\n",
    "        vb,\n",
    "        data['image'],\n",
    "        #matched_prd_u,\n",
    "        data['u_grad']   ,\n",
    "        #u_grad\n",
    "        #get_grad_u_keep_batch(real_gt_u)    \n",
    "        polys= gt_polys\n",
    "    )\n",
    "\n",
    "'''\n",
    "#=============== [ DEBUG] =================\n",
    "(matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\\\n",
    "(matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,),gt_idxs  = match_gt(pack_gt2 , out )\n",
    "\n",
    "u,vt,vb,u_grad =  decode((matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) , 0.5)\n",
    "plt_imgs = visualize_2d( \n",
    "    #matched_gt_u,\n",
    "    u,\n",
    "    #scores,\n",
    "    vt,\n",
    "    vb,\n",
    "    data2['image'],\n",
    "    #matched_prd_u,\n",
    "    data2['u_grad']   ,\n",
    "    #u_grad\n",
    "    #get_grad_u_keep_batch(real_gt_u)    \n",
    ")\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nep_count = 1\\nMAX_LOG_IT_COUNT=5\\n\\nwith torch.no_grad():                \\n    eval_loop(train_dataloader)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torchvision import ops\n",
    "#data = next(iter(train_dataloader))\n",
    "#print(data)\n",
    "\n",
    "'''\n",
    "'''\n",
    "def create_folder(path):\n",
    "\t#inf_output_folder   = os.path.join(os.getcwd() , \"inf_out_anime_1109\")\n",
    "\tif not os.path.exists(path):\n",
    "\t\tos.makedirs(path)\n",
    "\treturn path\n",
    "\n",
    "def train_loop(dataloader ):\n",
    "    #it_count =1    \n",
    "    global ep_count\n",
    "    global MAX_LOG_IT_COUNT\n",
    "    global MAX_LOG_GAP\n",
    "    global log_folder\n",
    "    #global it_count    \n",
    "    it_count = 0    \n",
    "    for data in tqdm(dataloader , desc=\"ep \"+str(ep_count) , ):       \n",
    "\n",
    "        #data =  next(iter(dataloader))                \n",
    "        for k, v in data.items():    \n",
    "            data[k]=data[k].to(device)       \n",
    "            \n",
    "        '''\n",
    "        '''\n",
    "        pack_gt = (data['u'] , data['v_top'] , data['v_btm'] , data['du'] , data['dv_top'] , data['dv_btm'] , data['u_grad']  )        \n",
    "        pack_gt = torch.cat(pack_gt , 1)\n",
    "        b, _ = pack_gt.shape\n",
    "        pack_gt = pack_gt.reshape((b,7,-1))\n",
    "        #pack_gt = pack_gt.reshape((b,6,-1))\n",
    "        pack_gt = encode(pack_gt)        \n",
    "        \n",
    "        #out_u, out_v_top , out_v_btm , out_d_top , out_d_btm = predict(data)        \n",
    "        #peak_out_data = filter_peak_data( (out_u, out_v_top , out_v_btm , out_d_top , out_d_btm ) ) # [b , 5 , max_door_count]\n",
    "        out = predict(data)   #[b , max_count , 5 ]\n",
    "        out = torch.transpose(out , 1 , 2) #[b , 5 , max_count ]        \n",
    "        try :\n",
    "            (matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\\\n",
    "            (matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,),gt_idxs  = match_gt(pack_gt , out )\n",
    "        except Exception as error:\n",
    "            print (\"Error! : \" , error)        \n",
    "            import datetime            \n",
    "            current_time = datetime.datetime.now()\n",
    "            current_time_str = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "            log = {\n",
    "                'timestamp': current_time_str ,\n",
    "                'u' : pack_gt[0],\n",
    "                'v_top' : pack_gt[1],\n",
    "                'v_btm' : pack_gt[2],\n",
    "                'du' : pack_gt[3],\n",
    "                'dv_top' : pack_gt[4],\n",
    "                'dv_btm' : pack_gt[5],\n",
    "            }\n",
    "            print(log)            \n",
    "            json_object = json.dumps(log, indent=4)                        \n",
    "            with open(f\"./output/error_log-{TRAIN_NAME}.json\", \"w\") as outfile:\n",
    "                outfile.write(json_object)\n",
    "\n",
    "        losses = cal_loss(                \n",
    "            (matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,) ,         \n",
    "            (matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\n",
    "            gt_idxs\n",
    "        )        \n",
    "        it_loss = sum(l for l in losses.values())              \n",
    "\n",
    "        #for k, v in losses.items():    \n",
    "            #writer.add_scalar('loss/'+k, v.item(),it_count)\n",
    "        for k, v in losses.items():    \n",
    "            writer.add_scalars('loss/'+k ,{'train':v.item()} , it_count + ep_count*len(dataloader))\n",
    "\n",
    "        if((ep_count % MAX_LOG_GAP==0 ) and (it_count < MAX_LOG_IT_COUNT)):\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                train_save_path = create_folder( os.path.join(log_folder , f\"train_{ep_count}\"))\n",
    "                u,vt,vb,scores =  decode((matched_prd_u ,matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm), CONFIDENCE_THRESHOLD )\n",
    "                plt_imgs = visualize_2d( \n",
    "                    u,\n",
    "                    vt ,\n",
    "                    vb , \n",
    "                    data['image'],\n",
    "                    matched_prd_u,\n",
    "                    #None,#u_grad\n",
    "                    \"Trainging Prediction\",\n",
    "                    True,                    \n",
    "                    save_path=train_save_path\n",
    "                \n",
    "                )\n",
    "                for im in plt_imgs:\n",
    "                    #writer.add_image('vis/pred/train-ep'+str(ep_count), im , dataformats=\"HWC\")\n",
    "                    cv2.imwrite(log_folder + f\"/pred-train-ep{ep_count}-{it_count}.png\" , im )\n",
    "\n",
    "                u,vt,vb,scores =  decode((matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm),0.5 )\n",
    "                plt_imgs = visualize_2d( \n",
    "                    u,\n",
    "                    vt ,\n",
    "                    vb , \n",
    "                    data['image'],\n",
    "                    #None , #u_grad\n",
    "                    data['u_grad'] ,\n",
    "                    \"GT\",                    \n",
    "                    save_path=train_save_path\n",
    "                )\n",
    "                for im in plt_imgs:\n",
    "                    #writer.add_image('vis/gt/train-ep'+str(ep_count), im , dataformats=\"HWC\")\n",
    "                    cv2.imwrite(log_folder+f\"/gt-train-ep{ep_count}-{it_count}.png\" , im )\n",
    "        it_count+=1        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        it_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(net.parameters(), 3.0, norm_type='inf')\n",
    "        optimizer.step()\n",
    "\n",
    "        '''\n",
    "        if(it_count >21):\n",
    "            break        \n",
    "        '''\n",
    "def eval_loop( dataloader ):\n",
    "    global ep_count\n",
    "    global log_folder\n",
    "    global MAX_LOG_IT_COUNT\n",
    "    global MAX_LOG_GAP\n",
    "    it_count    =0\n",
    "    net.eval()\n",
    "\n",
    "    pr_helper = PR_Eval_Helper(writer=writer ,ep= ep_count)\n",
    "    #all_max_iou_pre_reg=[]\n",
    "    #gt_count=0\n",
    "\n",
    "    for data in tqdm(dataloader , desc=\"ep \"+str(ep_count) , ):    \n",
    "                \n",
    "        for k, v in data.items():    \n",
    "            data[k]=data[k].to(device)            \n",
    "        \n",
    "        pack_gt = (data['u'] , data['v_top'] , data['v_btm'] , data['du'] , data['dv_top'] , data['dv_btm'] , data['u_grad']  )        \n",
    "        pack_gt = torch.cat(pack_gt , 1)\n",
    "        b, _ = pack_gt.shape\n",
    "        pack_gt = pack_gt.reshape((b,7,-1))\n",
    "        pack_gt = encode(pack_gt)\n",
    "\n",
    "        out = predict(data)   #[b , max_count , 6 ]\n",
    "        out = torch.transpose(out , 1 , 2) #[b , 6 , max_count ]\n",
    "        pack_out = (out[:,0] , out[:,1],out[:,2],out[:,3],out[:,4],out[:,5])\n",
    "\n",
    "        # ====== Eval Loss ======\n",
    "        (matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\\\n",
    "        (matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,),gt_idxs  = match_gt(pack_gt , out )\n",
    "\n",
    "        losses = cal_loss(                \n",
    "            (matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,) ,         \n",
    "            (matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\n",
    "            gt_idxs\n",
    "        )        \n",
    "        it_loss = sum(l for l in losses.values())              \n",
    "\n",
    "        for k, v in losses.items():    \n",
    "            writer.add_scalars('loss/'+k ,{'test' :v.item()} ,it_count + ep_count*len(dataloader))\n",
    "\n",
    "\n",
    "        pred_u,pred_vt,pred_vb , pred_scores =  decode(pack_out , CONFIDENCE_THRESHOLD , True)                    \n",
    "        gt_u,gt_vt,gt_vb,gt_u_grad =  decode((matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) , 0.5 , True)\n",
    "        \n",
    "        pred_poly = uv_to_distorted_box(pred_u,pred_vt,pred_vb)\n",
    "        gt_poly = uv_to_distorted_box(gt_u,gt_vt,gt_vb)\n",
    "      \n",
    "        # ========= PR Curve ===========\n",
    "        #for pred , gt ,score in zip(pred_bboxes , gt_bboxes , scores  ): # each image                                    \n",
    "        for pred , gt  in zip(pred_poly , gt_poly ): # each image                                    \n",
    "            pr_helper.eval_batch_pr(pred , gt , None , ep_count)\n",
    "\n",
    "        #if((ep_count % MAX_LOG_GAP==0 ) and (it_count < MAX_LOG_IT_COUNT)):    \n",
    "                \n",
    "        if(it_count < MAX_LOG_IT_COUNT):        \n",
    "            test_save_path = create_folder( os.path.join(log_folder , f\"test_{ep_count}\"))\n",
    "            plt_imgs = visualize_2d( \n",
    "                pred_u,\n",
    "                pred_vt ,\n",
    "                pred_vb , \n",
    "                data['image'],\n",
    "                #None,#u_grad,\n",
    "                out[:,0],                \n",
    "                \"inf\",\n",
    "                True,\n",
    "                pred_poly,                \n",
    "                save_path=test_save_path\n",
    "\n",
    "            )\n",
    "           \n",
    "            plt_imgs = visualize_2d( \n",
    "                gt_u,\n",
    "                gt_vt ,\n",
    "                gt_vb , \n",
    "                data['image'],\n",
    "                #None,\n",
    "                data['u_grad'],\n",
    "                \"gt\",\n",
    "                False,\n",
    "                gt_poly,                \n",
    "                save_path=test_save_path\n",
    "            )\n",
    "          \n",
    "        it_count +=1\n",
    "\n",
    "    p , r ,auc = pr_helper.get_all_pr()\n",
    "    #pr_helper.write_tensorboard()\n",
    "    ap_50 = pr_helper.final_result_dict[1]['ap']   \n",
    "\n",
    "    #return p , r ,auc\n",
    "    return ap_50\n",
    "\n",
    "\n",
    "'''\n",
    "ep_count = 1\n",
    "MAX_LOG_IT_COUNT=5\n",
    "\n",
    "with torch.no_grad():                \n",
    "    eval_loop(train_dataloader)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  [ONLY DO EVAl]\n",
    "ep_count=LOADED_EPOCH\n",
    "#eval_dataset = CustomDataset( f\"./output/test_visiable_horizon_unique_w0.01_4_fixedbug.json\"   ) \n",
    "eval_dataset = CustomDataset( f\"./output/{TEST_DATASET_NAME}\" ,debug_doTrans=False ) \n",
    "eval_dataloader = DataLoader(eval_dataset, BATCH_SIZE , shuffle=False, drop_last =True)\n",
    "with torch.no_grad():                \n",
    "    auc =eval_loop(eval_dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Eval Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep 1: 100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\n",
      "ep 2: 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "ep 3: 100%|██████████| 3/3 [00:02<00:00,  1.24it/s]\n",
      "ep 4: 100%|██████████| 3/3 [00:02<00:00,  1.25it/s]\n",
      "ep 5:   0%|          | 0/3 [00:00<?, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "ep 5:  33%|███▎      | 1/3 [00:02<00:04,  2.04s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "ep 5:  67%|██████▋   | 2/3 [00:04<00:02,  2.03s/it]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "ep 5: 100%|██████████| 3/3 [00:06<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== EVAL =========\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep 5:   0%|          | 0/1 [00:00<?, ?it/s]Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "ep 5: 100%|██████████| 1/1 [00:01<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_count 9\n",
      "all_prediction [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54]\n",
      "recall [0.         0.         0.         0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111\n",
      " 0.11111111 0.11111111 0.11111111 0.11111111 0.11111111 0.22222222\n",
      " 0.22222222 0.22222222 0.22222222 0.22222222 0.22222222 0.22222222\n",
      " 0.22222222 0.22222222 0.22222222 0.22222222 0.22222222 0.22222222\n",
      " 0.22222222 0.22222222 0.22222222 0.22222222 0.22222222 0.22222222\n",
      " 0.22222222 0.33333333 0.33333333 0.33333333 0.33333333 0.33333333\n",
      " 0.33333333 0.44444444 0.44444444 0.44444444 0.44444444 0.44444444\n",
      " 0.44444444 0.44444444 0.44444444 0.44444444 0.55555556 0.66666667\n",
      " 0.66666667]\n",
      "precision [1.         0.         0.         0.33333333 0.25       0.2\n",
      " 0.16666667 0.14285714 0.125      0.11111111 0.1        0.09090909\n",
      " 0.08333333 0.07692308 0.07142857 0.06666667 0.0625     0.11764706\n",
      " 0.11111111 0.10526316 0.1        0.0952381  0.09090909 0.08695652\n",
      " 0.08333333 0.08       0.07692308 0.07407407 0.07142857 0.06896552\n",
      " 0.06666667 0.06451613 0.0625     0.06060606 0.05882353 0.05714286\n",
      " 0.05555556 0.08108108 0.07894737 0.07692308 0.075      0.07317073\n",
      " 0.07142857 0.09302326 0.09090909 0.08888889 0.08695652 0.08510638\n",
      " 0.08333333 0.08163265 0.08       0.07843137 0.09615385 0.11320755\n",
      " 0.11111111]\n",
      "ap_0.05 0.06658419267014153\n",
      "gt_count 9\n",
      "all_prediction [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54]\n",
      "recall [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n",
      "precision [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n",
      "ap_0.5 0.0\n",
      "gt_count 9\n",
      "all_prediction [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50 51 52 53 54]\n",
      "recall [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n",
      "precision [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0.]\n",
      "ap_0.75 0.0\n",
      "all_iou 0.7009002659469843\n",
      "mIOU 0.0778778073274427\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_iou 0.7009002659469843\n",
      "mIOU 0.0778778073274427\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGxCAYAAACwbLZkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAq0klEQVR4nO3deXSUVZ7G8afIHiDFEghEYtgEgwFtw7BODJuBYNMi9ICNArKMxG6lAZeRxgGk1QCnm4PdstjIotOoiIAHeqKSllUCSjA0DIm2CJgICTFRkygQSLjzh5MaiyykYsJN4fdzznuOdeveen/3mkM99b5vveUwxhgBAABY0sh2AQAA4KeNMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijAC1MC6devkcDhcm6+vr9q1a6dJkybp9OnTrn67du1y6+fj46NWrVppxIgRSktLsziDhiUvL08PPPCAQkNDFRwcrL59++q9996r0dj58+e7rXH5FhgYWM9V168TJ05o1KhRatasmZo0aaI777xTH330UY3Hf/TRRxoyZIiaNGmiZs2aadSoUTpx4kQ9VgzUHV/bBQDeZO3atbr55pt1/vx57dmzR0lJSdq9e7eOHj2qxo0bu/o999xzGjhwoC5duqT09HQ9/fTTiouL0+HDh3XTTTdZnIF9JSUlGjx4sL755hs9//zzat26tZYtW6Zhw4bp73//u+Li4mr0Ou+8846cTqfrcaNG3vvZ6ssvv1RsbKyaN2+uNWvWKDAwUElJSRowYIAOHjyorl27Vjv+448/1oABA3TbbbfpjTfe0IULFzR37lzFxsbq8OHDatWq1TWaCVBLBsBVrV271kgyBw8edGv/z//8TyPJ/PWvfzXGGLNz504jyWzcuNGt38svv2wkmblz516zmmvqu+++u6b7W7ZsmZFkUlNTXW2XLl0y3bp1M7169brq+Hnz5hlJ5ssvv6zPMq+pxx9/3Pj5+ZlTp0652goLC01oaKgZM2bMVcf/27/9mwkNDTWFhYWutlOnThk/Pz/zxBNP1EvNQF3y3o8SQAPQp08fSdLnn39ebb+ePXtKks6ePevxPk6fPq0HH3xQERER8vf3V3h4uH75y1+6Xqv8FNKpU6fcxpWfMtq1a5erbcCAAYqOjtaePXvUr18/BQcHa/LkyRo5cqQiIyN1+fLlCvvv3bu3br/9dtdjY4yWL1+u2267TUFBQWrevLl++ctf1viUwJYtW9S1a1f17dvX1ebr66v7779fH374odtpr/qwYcMGxcfHq23btgoKClJUVJSefPJJfffdd279HnjgATVp0kTHjh3T4MGD1bhxY7Vq1UoPP/ywzp07V6c1bdmyRYMGDVJkZKSrLSQkRKNGjdK2bdtUWlpa5djS0lL97W9/0+jRoxUSEuJqj4yM1MCBA7Vly5Y6rRWoD4QR4Ec4fvy4JF31MPjJkyclSV26dPHo9U+fPq1/+Zd/0ZYtWzRr1iy9/fbbWrp0qZxOp77++uta1ZyTk6P7779f48aNU3Jysn79619r8uTJysrK0o4dO9z6fvzxx/rwww81adIkV9u0adM0Y8YMDRkyRG+99ZaWL1+uY8eOqV+/fjUKW//zP/+jHj16VGgvbzt27FiN5tG9e3f5+PgoLCxMEyZMUFZWVo3Gffrppxo+fLhWr16td955RzNmzNAbb7yhESNGVOh76dIlDR8+XIMHD9Zbb72lhx9+WC+++KLGjh171f2Uh8H58+dX2+/8+fP67LPPqlyT8+fPVxv0PvvsM50/f77K8cePH9eFCxeuWi9gE9eMAB4oKytTaWmpLly4oN27d+uZZ55R06ZN9Ytf/MKt3+XLl1VaWuq6ZuTRRx9Vt27dNHnyZI/2N3fuXOXn5+sf//iHoqKiXO1jxoyp9Ry++uorbdy4UYMGDXK1lZaWKiwsTGvXrtWQIUNc7WvXrpW/v7/GjRsnSTpw4IBWrVqlP/7xj5o1a5arX2xsrLp06aIlS5Zo0aJF1e6/oKBALVq0qNBe3lZQUFDt+E6dOunZZ5/Vz372MwUGBurDDz/U4sWLtX37dh06dEg33HBDteOfeuop138bY9S/f39FRUUpLi5OR44ccXtTv3jxoh599FFNnz5dknTnnXfKz89Pc+bM0b59+9S/f/8q91N+AfPVrmX5+uuvZYyp9ZqUP1fVeGOMvv76a7Vt27baOgCbCCOAB8pPy5Tr3r27VqxYobCwMLf2Kz85t23bVqmpqWrWrJlH+3v77bc1cOBAtyDyYzVv3twtiEj/f5pk2bJlKiwslNPpVFlZmf7rv/5Ld999t1q2bClJ+tvf/iaHw6H777/f7dRBmzZtdOutt7pOCRljVFZWVmEf5RwOR5X1VfecJI0fP97t8cCBAzVw4ED17dtXixcv1vPPP1/t+BMnTuipp57Sjh07lJeXJ2OM67nMzMwKRxjuu+8+t8fjxo3TnDlztHPnzmrDSFxcXLWnV670Y9akLsYDNnGaBvDAK6+8ooMHDyo9PV1nzpzRkSNHKn1DWrRokQ4ePKjdu3drzpw5Onv2rEaOHKmSkhKP9vfll1+qXbt2dVW+JFX5CXny5Mm6cOGCXn/9dUnSu+++q5ycHLdTNGfPnpUxRmFhYfLz83PbDhw4oPz8fEnSyy+/XOH5ci1btqz0k/5XX30lqfJP+FfTq1cvdenSRQcOHKi237fffqvY2Fh98MEHeuaZZ7Rr1y4dPHhQmzdvlvT9KZMf8vX1dQWxcm3atJF09SM4NdW8eXM5HI5ar0l5fVWNdzgcHodg4FrjyAjggaioKNfFqNXp2LGjq98dd9yhoKAgPfXUU/rzn/+sxx57rMb7a9Wqlb744otq+5TfX+PKoFMeDK5U1afkbt26qVevXlq7dq2mTZumtWvXKjw8XPHx8a4+oaGhcjgc2rt3rwICAiq8RnnbiBEjdPDgwUr30717dx09erRCe3lbdHR0peOuxhhz1VMiO3bs0JkzZ7Rr1y63rxB/8803lfYvLS1VQUGBWyDJzc2VpAohpbaCgoLUuXPnKtckKChIHTt2rHJ8p06dFBQUVOX4zp07e/09WHD948gIcA088cQT6ty5sxYuXKji4uIaj0tISNDOnTv1ySefVNmnffv2kqQjR464tW/dutXjOidNmqQPPvhA77//vrZt26aJEyfKx8fH9fzPf/5zGWN0+vRp9ezZs8LWvXt3Sd+/UV/5XLl77rlHH3/8sT744ANXW2lpqf7617+qd+/eCg8P97juAwcO6NNPP61wGu1K5UHsyiD14osvVjlm/fr1bo9fffVVSd9/M6mu3HPPPdqxY4eys7NdbcXFxdq8ebN+8YtfuJ3iupKvr69GjBihzZs3u/1tZWVlaefOnRo1alSd1QnUG2tfKga8SFX3GblSVfcZMcaYN954w0gyv//972u83y+++MK0bdvWtG7d2ixdutS89957ZtOmTebf//3fTWZmpjHGmNLSUtO1a1dz4403mldffdW8/fbb5sEHHzQdOnQwkszOnTtdrxcXF2duueWWKvf3zTffmKCgINOuXTsjyXzyyScV+jz44IMmODjYPP7442bbtm1mx44dZv369eahhx4yy5cvv+qcLly4YG655RYTERFh1q9fb1JSUsw999xjfH19za5du9z6Dho0yPj4+Li19ejRwyxevNhs27bNpKSkmGeffdY0a9bMhIeHmzNnzlS77/z8fNO8eXNz6623ms2bN5tt27aZe++919x0001Gklm7dq2r78SJE42/v7+58cYbzbPPPmu2b99u5s+fb3x9fU1CQsJV57lr1y7j4+Njnn766av2zcvLM23btjXdu3c3W7ZsMcnJyeaOO+4wTZs2df1/LtepUyfTqVMnt7bMzEzTpEkTc8cdd5jk5GSzefNmEx0dbcLDw01eXt5V9w/YRhgBaqAuwogxxvTu3ds0b97cfPPNNzXed3Z2tpk8ebJp06aN8fPzM+Hh4WbMmDHm7Nmzrj7//Oc/TXx8vAkJCTGtWrUyjzzyiPnv//5vj8OIMcaMGzfOSDL9+/evss+aNWtM7969TePGjU1QUJDp1KmTmTBhgklLS6vRnHJzc82ECRNMixYtTGBgoOnTp49JSUmp0C8uLs5c+Znp3nvvNZ07dzaNGzc2fn5+JjIy0iQmJl41iJRLTU01ffv2NcHBwaZVq1Zm6tSp5qOPPqo0jDRu3NgcOXLEDBgwwAQFBZkWLVqYhx56yHz77bdX3U/538K8efNqVNfx48fNyJEjTUhIiAkODjaDBw82hw4dqtAvMjLSREZGVmhPS0szgwcPNsHBwSYkJMSMHDnSHD9+vEb7BmxzGPODS8kBAJK+v+nZm2++qW+//dZ2KcB1j2tGAACAVXybBrDAVHIfjiv5+PhwfwgAPwkcGQEsqOw+HFduu3fvtl3mT9q6des4RQNcI1wzAlhQUFDg+r2aqnTt2lVNmza9RhUBgD2EEQAAYBWnaQAAgFVecQHr5cuXdebMGTVt2pQL+gAA8BLGGBUXFys8PLzan2vwijBy5swZRURE2C4DAADUQnZ2drU/+ukVYaT8Ir7s7GyFhIRYrgYAANREUVGRIiIirnoxvleEkfJTMyEhIYQRAAC8zNUuseACVgAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFjlcRjZs2ePRowYofDwcDkcDr311ltXHbN7927FxMQoMDBQHTt21MqVK2tTKwAAuA55HEa+++473XrrrXrhhRdq1P/kyZMaPny4YmNjlZ6ert/97neaPn26Nm3a5HGxAK4vxhidu1iqcxdLZYyxXQ4ASzz+obyEhAQlJCTUuP/KlSt14403aunSpZKkqKgopaWl6Q9/+INGjx5d6ZiSkhKVlJS4HhcVFXlaJgAvcP5SmbrNfVeSlLFgqIL9veK3OwHUsXq/ZmT//v2Kj493axs6dKjS0tJ06dKlSsckJSXJ6XS6toiIiPouEwAAWFLvYSQ3N1dhYWFubWFhYSotLVV+fn6lY2bPnq3CwkLXlp2dXd9lAgAAS67JMVGHw+H2uPzc8JXt5QICAhQQEFDvdQEAAPvq/chImzZtlJub69aWl5cnX19ftWzZsr53DwAAGrh6DyN9+/ZVSkqKW9v27dvVs2dP+fn51ffuAQBAA+dxGPn22291+PBhHT58WNL3X909fPiwsrKyJH1/vceECRNc/RMTE/X5559r1qxZyszM1Jo1a7R69Wo99thjdTMDAADg1Ty+ZiQtLU0DBw50PZ41a5YkaeLEiVq3bp1ycnJcwUSSOnTooOTkZM2cOVPLli1TeHi4/vSnP1X5tV4AAPDT4nEYGTBgQLU3J1q3bl2Ftri4OH300Uee7goAAPwE8Ns0AADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKtqFUaWL1+uDh06KDAwUDExMdq7d2+1/devX69bb71VwcHBatu2rSZNmqSCgoJaFQwAAK4vHoeRDRs2aMaMGZozZ47S09MVGxurhIQEZWVlVdr//fff14QJEzRlyhQdO3ZMGzdu1MGDBzV16tQfXTwAAPB+HoeRJUuWaMqUKZo6daqioqK0dOlSRUREaMWKFZX2P3DggNq3b6/p06erQ4cO+td//VdNmzZNaWlpP7p4AADg/TwKIxcvXtShQ4cUHx/v1h4fH6/U1NRKx/Tr109ffPGFkpOTZYzR2bNn9eabb+quu+6qcj8lJSUqKipy2wAAwPXJozCSn5+vsrIyhYWFubWHhYUpNze30jH9+vXT+vXrNXbsWPn7+6tNmzZq1qyZ/vznP1e5n6SkJDmdTtcWERHhSZkAAMCL1OoCVofD4fbYGFOhrVxGRoamT5+uuXPn6tChQ3rnnXd08uRJJSYmVvn6s2fPVmFhoWvLzs6uTZkAAMAL+HrSOTQ0VD4+PhWOguTl5VU4WlIuKSlJ/fv31+OPPy5J6tGjhxo3bqzY2Fg988wzatu2bYUxAQEBCggI8KQ0AADgpTw6MuLv76+YmBilpKS4taekpKhfv36Vjjl37pwaNXLfjY+Pj6Tvj6gAAICfNo9P08yaNUsvvfSS1qxZo8zMTM2cOVNZWVmu0y6zZ8/WhAkTXP1HjBihzZs3a8WKFTpx4oT27dun6dOnq1evXgoPD6+7mQAAAK/k0WkaSRo7dqwKCgq0YMEC5eTkKDo6WsnJyYqMjJQk5eTkuN1z5IEHHlBxcbFeeOEFPfroo2rWrJkGDRqkRYsW1d0sAACA13IYLzhXUlRUJKfTqcLCQoWEhNguB0AdOXexVN3mvitJylgwVMH+Hn8+AtCA1fT9m9+mAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhVqzCyfPlydejQQYGBgYqJidHevXur7V9SUqI5c+YoMjJSAQEB6tSpk9asWVOrggEAwPXF19MBGzZs0IwZM7R8+XL1799fL774ohISEpSRkaEbb7yx0jFjxozR2bNntXr1anXu3Fl5eXkqLS390cUDAADv53EYWbJkiaZMmaKpU6dKkpYuXap3331XK1asUFJSUoX+77zzjnbv3q0TJ06oRYsWkqT27dv/uKoBAMB1w6PTNBcvXtShQ4cUHx/v1h4fH6/U1NRKx2zdulU9e/bU4sWLdcMNN6hLly567LHHdP78+Sr3U1JSoqKiIrcNAABcnzw6MpKfn6+ysjKFhYW5tYeFhSk3N7fSMSdOnND777+vwMBAbdmyRfn5+fr1r3+tr776qsrrRpKSkvT00097UhoAAPBStbqA1eFwuD02xlRoK3f58mU5HA6tX79evXr10vDhw7VkyRKtW7euyqMjs2fPVmFhoWvLzs6uTZkAAMALeHRkJDQ0VD4+PhWOguTl5VU4WlKubdu2uuGGG+R0Ol1tUVFRMsboiy++0E033VRhTEBAgAICAjwpDQAAeCmPjoz4+/srJiZGKSkpbu0pKSnq169fpWP69++vM2fO6Ntvv3W1/fOf/1SjRo3Url27WpQMAACuJx6fppk1a5ZeeuklrVmzRpmZmZo5c6aysrKUmJgo6ftTLBMmTHD1HzdunFq2bKlJkyYpIyNDe/bs0eOPP67JkycrKCio7mYCAAC8ksdf7R07dqwKCgq0YMEC5eTkKDo6WsnJyYqMjJQk5eTkKCsry9W/SZMmSklJ0SOPPKKePXuqZcuWGjNmjJ555pm6mwUAAPBaDmOMsV3E1RQVFcnpdKqwsFAhISG2ywFQR85dLFW3ue9KkjIWDFWwv8efjwA0YDV9/+a3aQAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABW1SqMLF++XB06dFBgYKBiYmK0d+/eGo3bt2+ffH19ddttt9VmtwAA4DrkcRjZsGGDZsyYoTlz5ig9PV2xsbFKSEhQVlZWteMKCws1YcIEDR48uNbFAgCA64/HYWTJkiWaMmWKpk6dqqioKC1dulQRERFasWJFteOmTZumcePGqW/fvrUuFgAAXH88CiMXL17UoUOHFB8f79YeHx+v1NTUKsetXbtWn332mebNm1ej/ZSUlKioqMhtAwAA1yePwkh+fr7KysoUFhbm1h4WFqbc3NxKx3z66ad68skntX79evn6+tZoP0lJSXI6na4tIiLCkzIBAIAXqdUFrA6Hw+2xMaZCmySVlZVp3Lhxevrpp9WlS5cav/7s2bNVWFjo2rKzs2tTJgAA8AI1O1Txf0JDQ+Xj41PhKEheXl6FoyWSVFxcrLS0NKWnp+vhhx+WJF2+fFnGGPn6+mr79u0aNGhQhXEBAQEKCAjwpDQAAOClPDoy4u/vr5iYGKWkpLi1p6SkqF+/fhX6h4SE6OjRozp8+LBrS0xMVNeuXXX48GH17t37x1UPAAC8nkdHRiRp1qxZGj9+vHr27Km+ffvqL3/5i7KyspSYmCjp+1Msp0+f1iuvvKJGjRopOjrabXzr1q0VGBhYoR0AAPw0eRxGxo4dq4KCAi1YsEA5OTmKjo5WcnKyIiMjJUk5OTlXvecIAABAOYcxxtgu4mqKiorkdDpVWFiokJAQ2+UAqCPnLpaq29x3JUkZC4Yq2N/jz0cAGrCavn/z2zQAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAq2oVRpYvX64OHTooMDBQMTEx2rt3b5V9N2/erDvvvFOtWrVSSEiI+vbtq3fffbfWBQMAgOuLx2Fkw4YNmjFjhubMmaP09HTFxsYqISFBWVlZlfbfs2eP7rzzTiUnJ+vQoUMaOHCgRowYofT09B9dPAAA8H4OY4zxZEDv3r11++23a8WKFa62qKgojRw5UklJSTV6jVtuuUVjx47V3Llza9S/qKhITqdThYWFCgkJ8aRcAA3YuYul6jb3+yOlGQuGKtjf13JFAOpSTd+/PToycvHiRR06dEjx8fFu7fHx8UpNTa3Ra1y+fFnFxcVq0aJFlX1KSkpUVFTktgEAgOuTR2EkPz9fZWVlCgsLc2sPCwtTbm5ujV7jj3/8o7777juNGTOmyj5JSUlyOp2uLSIiwpMyAQCAF6nVBawOh8PtsTGmQltlXnvtNc2fP18bNmxQ69atq+w3e/ZsFRYWurbs7OzalAkAALyARydoQ0ND5ePjU+EoSF5eXoWjJVfasGGDpkyZoo0bN2rIkCHV9g0ICFBAQIAnpQEAAC/l0ZERf39/xcTEKCUlxa09JSVF/fr1q3Lca6+9pgceeECvvvqq7rrrrtpVCgAArkseX7o+a9YsjR8/Xj179lTfvn31l7/8RVlZWUpMTJT0/SmW06dP65VXXpH0fRCZMGGCnn/+efXp08d1VCUoKEhOp7MOpwIAALyRx2Fk7NixKigo0IIFC5STk6Po6GglJycrMjJSkpSTk+N2z5EXX3xRpaWl+s1vfqPf/OY3rvaJEydq3bp1P34GAADAq3l8nxEbuM8IcH3iPiPA9a1e7jMCAABQ1wgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKtqFUaWL1+uDh06KDAwUDExMdq7d2+1/Xfv3q2YmBgFBgaqY8eOWrlyZa2KBQAA1x+Pw8iGDRs0Y8YMzZkzR+np6YqNjVVCQoKysrIq7X/y5EkNHz5csbGxSk9P1+9+9ztNnz5dmzZt+tHFAwAA7+cwxhhPBvTu3Vu33367VqxY4WqLiorSyJEjlZSUVKH/f/zHf2jr1q3KzMx0tSUmJuof//iH9u/fX+k+SkpKVFJS4npcVFSkiIgIFRYWKiQkxJNyATRg5y6WqtvcdyVJGQuGKtjf13JFAOpSUVGRnE7nVd+/PToycvHiRR06dEjx8fFu7fHx8UpNTa10zP79+yv0Hzp0qNLS0nTp0qVKxyQlJcnpdLq2iIgIT8oEAABexKMwkp+fr7KyMoWFhbm1h4WFKTc3t9Ixubm5lfYvLS1Vfn5+pWNmz56twsJC15adne1JmQC8RJCfjzIWDFXGgqEK8vOxXQ4AS2p1TNThcLg9NsZUaLta/8raywUEBCggIKA2pQHwIg6Hg1MzADw7MhIaGiofH58KR0Hy8vIqHP0o16ZNm0r7+/r6qmXLlh6WCwAArjcehRF/f3/FxMQoJSXFrT0lJUX9+vWrdEzfvn0r9N++fbt69uwpPz8/D8sFAADXG4+/2jtr1iy99NJLWrNmjTIzMzVz5kxlZWUpMTFR0vfXe0yYMMHVPzExUZ9//rlmzZqlzMxMrVmzRqtXr9Zjjz1Wd7MAAABey+OTtWPHjlVBQYEWLFignJwcRUdHKzk5WZGRkZKknJwct3uOdOjQQcnJyZo5c6aWLVum8PBw/elPf9Lo0aPrbhYAAMBreXyfERtq+j1lAADQcNTLfUYAAADqGmEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFVe8XOZ5fdlKyoqslwJAACoqfL37avdX9UrwkhxcbEkKSIiwnIlAADAU8XFxXI6nVU+7xW3g798+bLOnDmjpk2byuFw2C7HqqKiIkVERCg7O5tb49cz1vraYJ2vDdb52mCd3RljVFxcrPDwcDVqVPWVIV5xZKRRo0Zq166d7TIalJCQEP7QrxHW+tpgna8N1vnaYJ3/X3VHRMpxASsAALCKMAIAAKwijHiZgIAAzZs3TwEBAbZLue6x1tcG63xtsM7XButcO15xASsAALh+cWQEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGGmAvv76a40fP15Op1NOp1Pjx4/XN998U+0YY4zmz5+v8PBwBQUFacCAATp27FiVfRMSEuRwOPTWW2/V/QS8RH2s81dffaVHHnlEXbt2VXBwsG688UZNnz5dhYWF9TybhmP58uXq0KGDAgMDFRMTo71791bbf/fu3YqJiVFgYKA6duyolStXVuizadMmdevWTQEBAerWrZu2bNlSX+V7jbpe51WrVik2NlbNmzdX8+bNNWTIEH344Yf1OQWvUR9/0+Vef/11ORwOjRw5so6r9jIGDc6wYcNMdHS0SU1NNampqSY6Otr8/Oc/r3bMwoULTdOmTc2mTZvM0aNHzdixY03btm1NUVFRhb5LliwxCQkJRpLZsmVLPc2i4auPdT569KgZNWqU2bp1qzl+/Lh57733zE033WRGjx59LaZk3euvv278/PzMqlWrTEZGhvntb39rGjdubD7//PNK+584ccIEBweb3/72tyYjI8OsWrXK+Pn5mTfffNPVJzU11fj4+JjnnnvOZGZmmueee874+vqaAwcOXKtpNTj1sc7jxo0zy5YtM+np6SYzM9NMmjTJOJ1O88UXX1yraTVI9bHW5U6dOmVuuOEGExsba+6+++56nknDRhhpYDIyMowkt39o9+/fbySZjz/+uNIxly9fNm3atDELFy50tV24cME4nU6zcuVKt76HDx827dq1Mzk5OT/pMFLf6/xDb7zxhvH39zeXLl2quwk0UL169TKJiYlubTfffLN58sknK+3/xBNPmJtvvtmtbdq0aaZPnz6ux2PGjDHDhg1z6zN06FBz77331lHV3qc+1vlKpaWlpmnTpubll1/+8QV7sfpa69LSUtO/f3/z0ksvmYkTJ/7kwwinaRqY/fv3y+l0qnfv3q62Pn36yOl0KjU1tdIxJ0+eVG5uruLj411tAQEBiouLcxtz7tw5/epXv9ILL7ygNm3a1N8kvEB9rvOVCgsLFRISIl9fr/hdylq7ePGiDh065LY+khQfH1/l+uzfv79C/6FDhyotLU2XLl2qtk91a349q691vtK5c+d06dIltWjRom4K90L1udYLFixQq1atNGXKlLov3AsRRhqY3NxctW7dukJ769atlZubW+UYSQoLC3NrDwsLcxszc+ZM9evXT3fffXcdVuyd6nOdf6igoEC///3vNW3atB9ZccOXn5+vsrIyj9YnNze30v6lpaXKz8+vtk9Vr3m9q691vtKTTz6pG264QUOGDKmbwr1Qfa31vn37tHr1aq1atap+CvdChJFrZP78+XI4HNVuaWlpkiSHw1FhvDGm0vYfuvL5H47ZunWrduzYoaVLl9bNhBoo2+v8Q0VFRbrrrrvUrVs3zZs370fMyrvUdH2q639lu6ev+VNQH+tcbvHixXrttde0efNmBQYG1kG13q0u17q4uFj333+/Vq1apdDQ0Lov1ktd38eNG5CHH35Y9957b7V92rdvryNHjujs2bMVnvvyyy8rpO1y5adccnNz1bZtW1d7Xl6ea8yOHTv02WefqVmzZm5jR48erdjYWO3atcuD2TRctte5XHFxsYYNG6YmTZpoy5Yt8vPz83QqXic0NFQ+Pj4VPjFWtj7l2rRpU2l/X19ftWzZsto+Vb3m9a6+1rncH/7wBz333HP6+9//rh49etRt8V6mPtb62LFjOnXqlEaMGOF6/vLly5IkX19fffLJJ+rUqVMdz8QLWLpWBVUov7Dygw8+cLUdOHCgRhdWLlq0yNVWUlLidmFlTk6OOXr0qNsmyTz//PPmxIkT9TupBqi+1tkYYwoLC02fPn1MXFyc+e677+pvEg1Qr169zEMPPeTWFhUVVe3FflFRUW5tiYmJFS5gTUhIcOszbNiwn/wFrHW9zsYYs3jxYhMSEmL2799ftwV7sbpe6/Pnz1f4t/juu+82gwYNMkePHjUlJSX1M5EGjjDSAA0bNsz06NHD7N+/3+zfv9907969wldOu3btajZv3ux6vHDhQuN0Os3mzZvN0aNHza9+9asqv9pbTj/hb9MYUz/rXFRUZHr37m26d+9ujh8/bnJyclxbaWnpNZ2fDeVfg1y9erXJyMgwM2bMMI0bNzanTp0yxhjz5JNPmvHjx7v6l38NcubMmSYjI8OsXr26wtcg9+3bZ3x8fMzChQtNZmamWbhwIV/trYd1XrRokfH39zdvvvmm299tcXHxNZ9fQ1Ifa30lvk1DGGmQCgoKzH333WeaNm1qmjZtau677z7z9ddfu/WRZNauXet6fPnyZTNv3jzTpk0bExAQYO644w5z9OjRavfzUw8j9bHOO3fuNJIq3U6ePHltJmbZsmXLTGRkpPH39ze333672b17t+u5iRMnmri4OLf+u3btMj/72c+Mv7+/ad++vVmxYkWF19y4caPp2rWr8fPzMzfffLPZtGlTfU+jwavrdY6MjKz073bevHnXYDYNW338Tf8QYcQYhzH/d2UNAACABXybBgAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFX/CxaZadVDRup7AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_iou 0.7009002659469843\n",
      "mIOU 0.0778778073274427\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ep 6: 100%|██████████| 3/3 [00:02<00:00,  1.14it/s]\n",
      "ep 7: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "ep 8: 100%|██████████| 3/3 [00:02<00:00,  1.23it/s]\n",
      "ep 9:  33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46732\\2298534051.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# ======= Train EPOCH =======\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mtrain_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# ======= Eval EPOCH =======\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_46732\\2590029330.py\u001b[0m in \u001b[0;36mtrain_loop\u001b[1;34m(dataloader)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mit_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\Layout\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mclip_coef_clamped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m         \u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_coef_clamped\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#BATCH_SIZE=6\n",
    "#TRAIN_NAME = \"hor-big-826-20-n256-1\"\n",
    "#TRAIN_NAME = \"n20_big20-r3\"\n",
    "\n",
    "#train_dataset = CustomDataset( \"./output/train_visiable_horizon_big_20.json\"   )  \n",
    "#eval_dataset = CustomDataset( \"./output/test_visiable_horizon_big_10.json\"   ) \n",
    "\n",
    "train_dataset = CustomDataset( f\"../../anno/train_visiable_20_no_cross.json\" , debug_doTrans= False  )  \n",
    "eval_dataset = CustomDataset( f\"../../anno/test_visiable_10_no_cross.json\"  ,debug_doTrans=False ) \n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE , shuffle=True, drop_last =True)\n",
    "eval_dataloader = DataLoader(eval_dataset, BATCH_SIZE , shuffle=False, drop_last =True)\n",
    "\n",
    "  \n",
    "ep_count = 1 if LOADED_EPOCH is None else LOADED_EPOCH+1\n",
    "#train_loop()\n",
    "\n",
    "#while True:\n",
    "for i in range(10):    \n",
    "    \n",
    "    # ======= Train EPOCH =======\n",
    "    net.train()\n",
    "    train_loop(train_dataloader)    \n",
    "    try:\n",
    "        # ======= Eval EPOCH =======    \n",
    "        if(ep_count % EVAL_GAP ==0):\n",
    "            print(\"=========== EVAL =========\")\n",
    "            net.eval()\n",
    "            with torch.no_grad():        \n",
    "                auc = eval_loop(eval_dataloader)\n",
    "                \n",
    "                if(auc > save_auc) :\n",
    "                    path = './output/'+ TRAIN_NAME  +'.pth'\n",
    "                    save_model(net , path , ep_count , auc)\n",
    "                    save_auc = auc\n",
    "                if(ep_count % 5 == 0):\n",
    "                    path = './output/'+ '1017_wAug_all_bk.pth'\n",
    "                    save_model(net , path , ep_count , auc)\n",
    "                '''\n",
    "                '''\n",
    "    except Exception as error:\n",
    "        print (\"Error! : \" , error)        \n",
    "        import datetime            \n",
    "        current_time = datetime.datetime.now()\n",
    "        current_time_str = current_time.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        log = {\n",
    "            'timestamp': current_time_str ,\n",
    "            'error': error.__dict__,            \n",
    "        }\n",
    "        print(log)            \n",
    "        json_object = json.dumps(log, indent=4)                        \n",
    "        with open(f\"./output/error_log-{TRAIN_NAME}.json\", \"w\") as outfile:\n",
    "            outfile.write(json_object)\n",
    "\n",
    "    ep_count+=1\n",
    "\n",
    "#save_model(net,f'./output/{TRAIN_NAME}-final.pth' , ep_count , save_auc )\n",
    "'''\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_model(net,f'./output/{TRAIN_NAME}-with_aug_ep166.pth' , 166 , 0.6612 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "with torch.no_grad():  \n",
    "    eval_loop(eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "#save_path = './output/horizonn256u20d20.pth'\n",
    "#save_model(net,save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "#state_dict = torch.load(save_path, map_location='cpu')\n",
    "#net.load_state_dict(state_dict['state_dict'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "'''\n",
    "target_imgs = [\n",
    "\"/0310/panos/floor_01_partial_room_11_pano_23.jpg\",\n",
    "\"1357/panos/floor_01_partial_room_08_pano_31.jpg\",\n",
    "\"0636/panos/floor_02_partial_room_03_pano_74.jpg\",\n",
    "\"0548/panos/floor_01_partial_room_12_pano_25.jpg\",\n",
    "\"1060/panos/floor_01_partial_room_03_pano_42.jpg\",\n",
    "\"0530/panos/floor_01_partial_room_15_pano_11.jpg\"\n",
    "]\n",
    "'''\n",
    "import torch\n",
    "import json\n",
    "from horizon_model_direct import HorizonNet\n",
    "'''\n",
    "train_dataset = CustomDataset( f\"./output/{TRAIN_DATASET_NAME}\"   )  \n",
    "train_dataloader = DataLoader(train_dataset, BATCH_SIZE , shuffle=True, drop_last =True)\n",
    "tr_data = next(iter(train_dataloader))\n",
    "\n",
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device= 'cpu'\n",
    "net = HorizonNet('resnet50', True , MAX_PREDICTION_COUNT).to(device)   # For server (small memory)\n",
    "\n",
    "'''\n",
    "fake_imgs = torch.rand((6,3,512,1024))\n",
    "f = open('./error_log-n90-c0.1-r10-0912-all-ep1.json') \n",
    "data = json.load(f)\n",
    "for k, v in data.items():    \n",
    "    data[k]=torch.tensor( data[k]).to(device) \n",
    "'''\n",
    "print(data.keys())\n",
    "out = net(fake_imgs)   #[b , max_count , 5 ]\n",
    "#out = predict(data)   #[b , max_count , 5 ]\n",
    "out = torch.transpose(out , 1 , 2) #[b , 5 , max_count ]\n",
    "'''\n",
    "\n",
    "#pack_gt = (data['u'] , data['v_top'] , data['v_btm'] , data['du'] , data['dv_top'] , data['dv_btm'] , data['u_grad'])    \n",
    "print(torch.rand_like(data['u']) .shape)\n",
    "print(data['v_top'].shape)\n",
    "print(out.shape)\n",
    "pack_gt = (data['u'] , data['v_top'] , data['v_btm'] , data['du'] , data['dv_top'] , data['dv_btm'] , torch.rand_like(data['u']) )    \n",
    "pack_gt = torch.cat(pack_gt , 1)\n",
    "b, _ = pack_gt.shape\n",
    "#pack_gt = pack_gt.reshape((b , 7 , -1 ))\n",
    "pack_gt = pack_gt.reshape((b ,  6 , -1 ))\n",
    "'''\n",
    "pack_gt = encode(pack_gt)\n",
    "print(pack_gt)\n",
    "'''\n",
    "\n",
    "(matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\\\n",
    "(matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,),gt_idxs  = match_gt(pack_gt , out )\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "(matched_gt_u , matched_gt_vtop , matched_gt_vbtm , matched_gt_du ,matched_gt_dvtop ,matched_gt_dvbtm) ,\\\n",
    "(matched_prd_u , matched_prd_vtop ,matched_prd_vbtm , matched_prd_du ,matched_prd_dvtop , matched_prd_dvbtm,),gt_idxs  = match_gt(pack_gt , out )\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "target_imgs = [\n",
    "\"0310/panos/floor_01_partial_room_11_pano_23.jpg\",\n",
    "\"1357/panos/floor_01_partial_room_08_pano_31.jpg\",\n",
    "\"0636/panos/floor_02_partial_room_03_pano_74.jpg\",\n",
    "\"0548/panos/floor_01_partial_room_12_pano_25.jpg\",\n",
    "\"1060/panos/floor_01_partial_room_03_pano_42.jpg\",\n",
    "\"0530/panos/floor_01_partial_room_15_pano_11.jpg\"\n",
    "]\n",
    "'''\n",
    "\n",
    "target_imgs = [\n",
    "    '0661/panos/floor_01_partial_room_01_pano_26.jpg',\n",
    "    '0544/panos/floor_01_partial_room_21_pano_48.jpg',\n",
    "    '1369/panos/floor_01_partial_room_04_pano_9.jpg',\n",
    "    '0883/panos/floor_01_partial_room_09_pano_28.jpg',\n",
    "    '0404/panos/floor_01_partial_room_13_pano_6.jpg',\n",
    "    '0142/panos/floor_01_partial_room_05_pano_30.jpg',\n",
    "    '0823/panos/floor_01_partial_room_05_pano_14.jpg',\n",
    "    '0313/panos/floor_01_partial_room_13_pano_33.jpg',\n",
    "    '0167/panos/floor_01_partial_room_17_pano_49.jpg',\n",
    "    '0831/panos/floor_01_partial_room_08_pano_10.jpg',\n",
    "    '1222/panos/floor_01_partial_room_04_pano_43.jpg',\n",
    "    '0868/panos/floor_02_partial_room_07_pano_58.jpg',\n",
    "    '0513/panos/floor_01_partial_room_09_pano_9.jpg',\n",
    "    '0672/panos/floor_01_partial_room_04_pano_4.jpg',\n",
    "    '0840/panos/floor_02_partial_room_09_pano_55.jpg',\n",
    "    '0467/panos/floor_01_partial_room_04_pano_32.jpg',\n",
    "    '0968/panos/floor_01_partial_room_03_pano_19.jpg', \n",
    "    '0350/panos/floor_02_partial_room_05_pano_70.jpg', \n",
    "    '0759/panos/floor_01_partial_room_03_pano_11.jpg', \n",
    "    '1345/panos/floor_01_partial_room_01_pano_8.jpg']\n",
    "f= open(\"./output/train_visiable_horizon_unique_w0.01_all_fixedbug.json\")\n",
    "all_json = json.load(f)\n",
    "target = [a for a in all_json if a['image'] in target_imgs]\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(target))\n",
    "json_object = json.dumps(target, indent=4)                        \n",
    "with open(f\"./output/testerr.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
