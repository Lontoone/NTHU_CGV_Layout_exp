{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\layout\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\Layout\\NTHU_CGV_Layout_exp\\ours\n",
      "d:\\Projects\\Layout\\NTHU_CGV_Layout_exp\\Horizon_and_SAM\\Horizon\n"
     ]
    }
   ],
   "source": [
    "# Data Loader\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from pytorch_lightning.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "import json\n",
    "from CustomDataset import * \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import *\n",
    "from file_helper import *\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "#=================================\n",
    "#             Augmentation\n",
    "#=================================\n",
    "\n",
    "def gauss_noise_tensor(img):\n",
    "    rand = torch.rand(1)[0]\n",
    "    if rand < 0.5 and Horizon_AUG:\n",
    "        sigma = rand *0.125\n",
    "        out = img + sigma * torch.randn_like(img)\n",
    "        return out\n",
    "    return img\n",
    "\n",
    "def blank(img):    \n",
    "    return img\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self ,\n",
    "                 train_dir ,\n",
    "                 test_dir , batch_size = 2, num_workers = 0 , img_size=[IMG_WIDTH, IMG_HEIGHT] , use_aug = True ,padding_count = 24 ,c =0.1\n",
    "                   ):\n",
    "        super().__init__()\n",
    "        self.train_dir = train_dir\n",
    "        self.test_dir = test_dir\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.img_size = img_size      \n",
    "        self.use_aug = use_aug\n",
    "        self.padding_count  = padding_count\n",
    "        self.c = c\n",
    "        \n",
    "\n",
    "        pass\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        # Download dataset\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage):\n",
    "        # Create dataset...          \n",
    "                \n",
    "        self.entire_dataset = CustomDataset(self.train_dir  , use_aug= self.use_aug , padding_count= self.padding_count , c=self.c)\n",
    "        self.train_ds , self.val_ds = random_split(self.entire_dataset , [0.9, 0.1])        \n",
    "        self.test_ds = CustomDataset(self.test_dir  , use_aug= False)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    # ToDo: Reture Dataloader...\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(self.train_ds , batch_size= self.batch_size , num_workers= self.num_workers , shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(self.val_ds , batch_size= self.batch_size , num_workers= self.num_workers , shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(self.test_ds , batch_size= self.batch_size , num_workers= self.num_workers , shuffle=False)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "# Test\n",
    "dm = CustomDataModule ( train_dir= f\"../anno/test_visiable_10_no_cross.json\" ,\n",
    "                       test_dir= f\"../anno/test_visiable_10_no_cross.json\" , padding_count=256\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "def unpad_data( x :[Tensor] ) :\n",
    "\tnon_zero_indices = torch.nonzero(x)\n",
    "\t#print(non_zero_indices)\n",
    "\t# Get the non-zero values\n",
    "\tnon_zero_values = x[non_zero_indices[:,0], non_zero_indices[:,1]]\n",
    "\n",
    "\tunique = torch.unique(non_zero_indices[:,0] ,return_counts=True)\t\n",
    "\tnon_zero_values = torch.split(non_zero_values , tuple(unique[1]))\n",
    "\t\n",
    "\treturn non_zero_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\layout\\lib\\site-packages\\torchvision\\models\\_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and may be removed in the future, \"\n",
      "d:\\conda\\envs\\layout\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                 | Type               | Params\n",
      "------------------------------------------------------------\n",
      "0 | backbone             | Resnet             | 23.5 M\n",
      "1 | fixed_pe             | PositionalEncoding | 0     \n",
      "2 | transformer          | TransformerModel   | 13.5 M\n",
      "3 | reduce_height_module | GlobalHeightStage  | 45.5 M\n",
      "------------------------------------------------------------\n",
      "82.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "82.5 M    Total params\n",
      "164.909   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity Checking: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0454/panos/floor_01_partial_room_19_pano_25.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_00_partial_room_08_pano_54.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0422/panos/floor_01_partial_room_02_pano_15.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0422/panos/floor_02_partial_room_04_pano_45.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\1308/panos/floor_02_partial_room_04_pano_24.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_01_partial_room_06_pano_86.jpg\n",
      "Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]val!!!!!\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "Sanity Checking DataLoader 0:  50%|█████     | 1/2 [00:01<00:01,  1.60s/it]img_path D:\\Projects\\Door_Detection\\data\\data\\0422/panos/floor_02_partial_room_05_pano_51.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0454/panos/floor_01_partial_room_13_pano_50.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0422/panos/floor_02_partial_room_01_pano_52.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\1308/panos/floor_01_partial_room_02_pano_6.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0422/panos/floor_01_partial_room_13_pano_58.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_01_partial_room_14_pano_28.jpg\n",
      "val!!!!!\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "u_id tensor([], device='cuda:0', size=(0, 1), dtype=torch.int64)\n",
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:229: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "d:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1613: PossibleUserWarning: The number of training batches (30) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/34 [00:00<?, ?it/s] img_path D:\\Projects\\Door_Detection\\data\\data\\0422/panos/floor_01_partial_room_10_pano_2.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0422/panos/floor_01_partial_room_10_pano_3.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\1308/panos/floor_01_partial_room_02_pano_9.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\1356/panos/floor_01_partial_room_09_pano_48.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0422/panos/floor_01_partial_room_13_pano_57.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_01_partial_room_05_pano_74.jpg\n",
      "batch_idx 0\n",
      "cls_sample_idx [8 5]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0291, 0.0351], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2506, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6948, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [18  1]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0042, 0.0257], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.3239, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6986, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [18  1]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([-0.0007,  0.0171], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6976, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [10 18 19  5]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0329, 0.0054, 0.0283, 0.0381], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6968, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [10 16  7  2]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0287, 0.0302, 0.0348, 0.0454], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2671, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6960, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  7 10 15 18 14  9 19 16 16]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0345, 0.0811, 0.0332, 0.0283, 0.0076, 0.0112, 0.0301, 0.0290, 0.0302,\n",
      "        0.0302], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([5, 6])\n",
      "L1 loss tensor(0.2820, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6906, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "batch_idx 0\n",
      "cls_sample_idx [8 9]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0336, 0.0324], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2420, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6930, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [18  5]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0338, 0.0345], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.3122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6935, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [18 19]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0451, 0.0295], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2714, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6894, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [10 18 15 17]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0315, 0.0317, 0.0305, 0.0651], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6974, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [10 16 14  5]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0290,  0.0302, -0.0027,  0.0285], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6891, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  7 10 15 18 13  3  3 17  3]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0499, 0.1016, 0.0332, 0.0408, 0.0323, 0.0912, 0.0994, 0.0994, 0.0787,\n",
      "        0.0994], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([5, 6])\n",
      "L1 loss tensor(0.2754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7044, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "batch_idx 0\n",
      "cls_sample_idx [ 8 10]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0826, 0.0324], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6811, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [18  3]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1422, 0.1180], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6892, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [18 19]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.1605, -0.0095], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2515, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6522, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [10 18 12 16]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0440,  0.0859, -0.0030,  0.0302], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2539, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6806, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [10 16 18  3]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0631, 0.0302, 0.0015, 0.0514], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2603, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6883, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  7 10 15 18 11  0 14 17  4]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0269,  0.1364,  0.0269,  0.0687,  0.0359,  0.0328,  0.0302,  0.0252,\n",
      "        -0.0452, -0.0436], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([5, 6])\n",
      "L1 loss tensor(0.2578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6788, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch 0:   3%|▎         | 1/34 [00:02<01:14,  2.25s/it, loss=0.957, v_num=264]img_path D:\\Projects\\Door_Detection\\data\\data\\1356/panos/floor_02_partial_room_11_pano_67.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_01_partial_room_10_pano_44.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\1356/panos/floor_01_partial_room_10_pano_32.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_01_partial_room_09_pano_34.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_00_partial_room_03_pano_71.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\1356/panos/floor_02_partial_room_07_pano_59.jpg\n",
      "batch_idx 1\n",
      "cls_sample_idx [ 8  9  2 10]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0789, 0.0285, 0.0760, 0.0610], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2129, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6974, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 8 13 18 17  9  0]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0543, 0.0498, 0.0995, 0.0797, 0.0298, 0.0300], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.3326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6883, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [12 18 13  6]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0187, 0.1257, 0.0790, 0.0696], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2825, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6945, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  9 10 12  1 16]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0425, 0.0245, 0.0229, 0.0103, 0.0309, 0.0297], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6917, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 6 14]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0770, 0.0291], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6816, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 7  8  6 19]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0097, 0.0431, 0.0780, 0.0348], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "batch_idx 1\n",
      "cls_sample_idx [ 8  9 19 16]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0836, 0.0236, 0.0244, 0.0300], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6868, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 8 13 18  5 14 14]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0895, 0.0645, 0.1309, 0.0322, 0.0245, 0.0245], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.3205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6768, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [12 18  3 14]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0225,  0.1456, -0.0784,  0.0172], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6654, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  9 10 17 12  7]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0803,  0.0273,  0.0508,  0.0379, -0.0265,  0.0543], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2030, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6857, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [6 5]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0970, 0.0322], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6776, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [7 8 9 1]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0713, 0.0801, 0.0234, 0.0279], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6810, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "batch_idx 1\n",
      "cls_sample_idx [ 8  9 11 17]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.1846,  0.0177, -0.0090,  0.0723], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.1939, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6770, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 8 13 18  4 12 12]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.1530,  0.1350,  0.1926, -0.0381,  0.0013,  0.0013], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6518, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [12 18  8  9]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1451, 0.1880, 0.0361, 0.0271], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2288, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6612, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  9 10  6 11  1]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1008, 0.0256, 0.0704, 0.0943, 0.0562, 0.0278], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.1915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6922, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [6 2]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1953, 0.0586], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6616, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 7  8 10 11]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.2212, 0.1613, 0.0579, 0.0498], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.1821, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6613, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch 0:   6%|▌         | 2/34 [00:04<01:04,  2.02s/it, loss=0.94, v_num=264] img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_00_partial_room_08_pano_51.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\1308/panos/floor_02_partial_room_05_pano_20.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\1356/panos/floor_02_partial_room_05_pano_65.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0919/panos/floor_02_partial_room_03_pano_70.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0454/panos/floor_01_partial_room_05_pano_62.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0454/panos/floor_01_partial_room_17_pano_42.jpg\n",
      "batch_idx 2\n",
      "cls_sample_idx [ 8 13 11  2]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0969,  0.1039, -0.0475,  0.0426], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6682, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 6  9 12 11  8  8]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.1383,  0.0297,  0.0333, -0.0629,  0.1154,  0.1154], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2738, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6914, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 6 12 15 17 18  9  3  1 19 14]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.1113,  0.0211,  0.0288,  0.0125,  0.2354,  0.0270, -0.1062,  0.0426,\n",
      "         0.0338,  0.0475], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([5, 6])\n",
      "L1 loss tensor(0.2950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6760, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 3 13 17  5]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([-0.1222,  0.0919,  0.0125,  0.0299], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7030, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 1  5 14 15 10  6]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0374, 0.0294, 0.0744, 0.0416, 0.0352, 0.1552], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7014, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  3 10  4 18  1]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0482, -0.1233,  0.0310, -0.0689,  0.2588,  0.0362], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.1980, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7176, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "batch_idx 2\n",
      "cls_sample_idx [ 8 13 15  9]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1805, 0.1509, 0.0606, 0.0259], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6644, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 6  9 12 16 17 19]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1583, 0.0292, 0.0526, 0.0299, 0.0029, 0.0517], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2654, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6808, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 6 12 15 17 18  7  7 16 16  8]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1429, 0.0579, 0.0470, 0.0098, 0.2566, 0.0740, 0.0740, 0.0302, 0.0302,\n",
      "        0.1055], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([5, 6])\n",
      "L1 loss tensor(0.2850, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6846, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 3 13  1 15]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([-0.0632,  0.1118,  0.0320,  0.0120], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2462, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6931, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 1  5 14  7  9 17]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0315,  0.0306,  0.0613,  0.0955,  0.0296, -0.0569], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6889, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  3 10  7 16 19]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0694, -0.0858,  0.0850,  0.0741,  0.0299,  0.0320], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.1861, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6993, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "batch_idx 2\n",
      "cls_sample_idx [ 8 13  9 16]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.2515, 0.2595, 0.0234, 0.0295], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.1638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6400, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 6  9 12 13 16  8]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1945, 0.0278, 0.1044, 0.1588, 0.0301, 0.0547], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2371, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6879, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 6 12 15 17 18  7  8 13  8  4]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.1566,  0.0779,  0.1052,  0.1423,  0.2935, -0.0754,  0.0466,  0.1188,\n",
      "         0.0466, -0.1138], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 1., 1., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([5, 6])\n",
      "L1 loss tensor(0.2546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6578, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 3 13 19 18]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0620, 0.2925, 0.0285, 0.2568], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.1785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6894, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 1  5 14  0  7 15]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0472,  0.0362,  0.1354,  0.0292, -0.0588,  0.0223], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6749, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  3 10  3 16 15]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1006, 0.0577, 0.0880, 0.0577, 0.0318, 0.0283], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.1507, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6734, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch 0:   9%|▉         | 3/34 [00:05<00:59,  1.92s/it, loss=0.935, v_num=264]img_path D:\\Projects\\Door_Detection\\data\\data\\1356/panos/floor_01_partial_room_11_pano_35.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0422/panos/floor_01_partial_room_12_pano_22.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0895/panos/floor_02_partial_room_05_pano_40.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0454/panos/floor_01_partial_room_04_pano_36.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_00_partial_room_05_pano_57.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0454/panos/floor_01_partial_room_04_pano_38.jpg\n",
      "batch_idx 3\n",
      "cls_sample_idx [ 7 17  2  6]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0121, 0.0509, 0.0575, 0.1237], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2410, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7086, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  9 11 12 14 18]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0374,  0.0292, -0.0912,  0.0870,  0.0657,  0.2759], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2349, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7330, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [11 14 17  3  5  2]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([-0.0702,  0.0890,  0.0199,  0.0170,  0.0304,  0.0693], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2644, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7000, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 3  4 15  1  0 17]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0025, -0.0348,  0.0473,  0.0337,  0.0300, -0.0205], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2142, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6956, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [14  9]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0945, 0.0273], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.3295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6769, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [12 12  0  9]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1039, 0.1039, 0.0306, 0.0279], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.1910, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6752, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "batch_idx 3\n",
      "cls_sample_idx [ 7 17 13 16]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0891, 0.0795, 0.1252, 0.0297], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6924, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  9 11 10  5 19]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0556,  0.0226, -0.0849,  0.0398,  0.0293,  0.0207], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7015, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [11 14 17 15 12 12]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([-0.0559,  0.0952,  0.0252,  0.0306,  0.1107,  0.1107], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2585, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7096, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 3  4 15  4 17 11]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0211, -0.0517,  0.0536, -0.0517,  0.0066, -0.0701], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.1988, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6905, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [14  0]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1294, 0.0287], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.3113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6691, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [12 12 15  8]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1333, 0.1333, 0.0249, 0.0828], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.1629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6746, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "batch_idx 3\n",
      "cls_sample_idx [ 7 17  2 19]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.1666, 0.1965, 0.0152, 0.0225], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.1783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6546, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 2  9 11  0  5  3]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.0591, 0.0235, 0.0076, 0.0318, 0.0254, 0.0118], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2101, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6915, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [11 14 17  7 18  2]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([-0.0071,  0.1232,  0.0958,  0.0468,  0.2903,  0.0635], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.2302, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7113, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 3  4 15  8 17  8]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.1422,  0.0425,  0.0546,  0.0750, -0.0895,  0.0750], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 1., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([3, 6])\n",
      "L1 loss tensor(0.1719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6792, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [14 10]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.2529, -0.0234], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([1, 6])\n",
      "L1 loss tensor(0.2405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6281, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [12 12  2  0]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([0.3225, 0.3225, 0.0079, 0.0292], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.1611, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6237, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "Epoch 0:  12%|█▏        | 4/34 [00:07<00:56,  1.89s/it, loss=0.928, v_num=264]img_path D:\\Projects\\Door_Detection\\data\\data\\1308/panos/floor_02_partial_room_06_pano_18.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0454/panos/floor_01_partial_room_15_pano_58.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_00_partial_room_02_pano_56.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0919/panos/floor_01_partial_room_09_pano_48.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0454/panos/floor_01_partial_room_04_pano_75.jpg\n",
      "img_path D:\\Projects\\Door_Detection\\data\\data\\0673/panos/floor_01_partial_room_16_pano_17.jpg\n",
      "batch_idx 4\n",
      "cls_sample_idx [ 3 10  8 14]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.0146, -0.0426, -0.0175,  0.1724], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.2155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.7170, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [13 18  7 11]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n",
      "cls_b.view(-1)[cls_sample_idx] tensor([ 0.1929,  0.2725,  0.0324, -0.0322], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt_cls.view(-1)[cls_sample_idx] tensor([1., 1., 0., 0.], device='cuda:0')\n",
      "torch.Size([20, 6])\n",
      "torch.Size([2, 6])\n",
      "L1 loss tensor(0.1466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.6385, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_sample_idx [ 4  9 13  0  1 11 10 15]\n",
      "torch.Size([20])\n",
      "torch.Size([20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    649\u001b[0m         )\n\u001b[1;32m--> 650\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1213\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_detect_anomaly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_detect_anomaly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1214\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"run_training_epoch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_fetcher\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\epoch\\training_epoch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"run_training_batch\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                 \u001b[0mbatch_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\batch\\training_batch_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m             )\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\loop.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_start\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_advance_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, optimizers, kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_optimization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim_progress\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_position\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py\u001b[0m in \u001b[0;36m_run_optimization\u001b[1;34m(self, kwargs, optimizer)\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[1;31m# the `batch_idx` is optional with inter-batch parallelism\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"batch_idx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py\u001b[0m in \u001b[0;36m_optimizer_step\u001b[1;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 379\u001b[1;33m             \u001b[0musing_lbfgs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    380\u001b[0m         )\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1355\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"[LightningModule]{pl_module.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\core\\module.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_lbfgs)\u001b[0m\n\u001b[0;32m   1753\u001b[0m         \"\"\"\n\u001b[1;32m-> 1754\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\core\\optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_strategy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m         \u001b[0mstep_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, optimizer, opt_idx, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    234\u001b[0m         return self.precision_plugin.optimizer_step(\n\u001b[1;32m--> 235\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m         )\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\plugins\\precision\\native_amp.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, optimizer, model, optimizer_idx, closure, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m             )\n\u001b[1;32m---> 75\u001b[1;33m         \u001b[0mclosure_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py\u001b[0m in \u001b[0;36mclosure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mClosureResult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mstep_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\loops\\optimization\\optimizer_loop.py\u001b[0m in \u001b[0;36m_training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[1;31m# manually capture logged metrics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[0mtraining_step_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_strategy_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training_step\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_call_strategy_hook\u001b[1;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1493\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"[Strategy]{self.strategy.__class__.__name__}.{hook_name}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1494\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrainingStep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21356\\3956303007.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, input_b, batch_idx, optimizer_idx)\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgt_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"cls_b.view(-1)[cls_sample_idx]\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mcls_b\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls_sample_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"gt_cls.view(-1)[cls_sample_idx]\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mgt_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcls_sample_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21356\\3956303007.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    420\u001b[0m '''\n\u001b[0;32m    421\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gpu'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mmin_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m51\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mfast_dev_run\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m         call._call_and_handle_interrupt(\n\u001b[1;32m--> 609\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    610\u001b[0m         )\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloggers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"failed\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_teardown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;31m# teardown might access the stage so we reset it after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_teardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1173\u001b[0m         \"\"\"This is the Trainer's internal teardown, unrelated to the `teardown` hooks in LightningModule and\n\u001b[0;32m   1174\u001b[0m         Callback; those are handled by :meth:`_call_teardown_hook`.\"\"\"\n\u001b[1;32m-> 1175\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m         \u001b[0mloop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_active_loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m         \u001b[1;31m# loop should never be `None` here but it can because we don't know the trainer stage with `ddp_spawn`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\pytorch_lightning\\strategies\\strategy.py\u001b[0m in \u001b[0;36mteardown\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[0mIt\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mright\u001b[0m \u001b[0mplace\u001b[0m \u001b[0mto\u001b[0m \u001b[0mrelease\u001b[0m \u001b[0mmemory\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfree\u001b[0m \u001b[0mother\u001b[0m \u001b[0mresources\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m         \u001b[0m_optimizers_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\lightning_fabric\\utilities\\optimizer.py\u001b[0m in \u001b[0;36m_optimizers_to_device\u001b[1;34m(optimizers, device)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;34m\"\"\"Moves optimizer states for a sequence of optimizers to the device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mopt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0m_optimizer_to_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\lightning_fabric\\utilities\\optimizer.py\u001b[0m in \u001b[0;36m_optimizer_to_device\u001b[1;34m(optimizer, device)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;34m\"\"\"Moves the state of a single optimizer to the device.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmove_data_to_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\lightning_utilities\\core\\apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 1d homogeneous dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;31m# slow path for everything else\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     return _apply_to_collection_slow(\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\lightning_utilities\\core\\apply_func.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 1d homogeneous dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m     \u001b[1;31m# slow path for everything else\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     return _apply_to_collection_slow(\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\lightning_fabric\\utilities\\apply_func.py\u001b[0m in \u001b[0;36mmove_data_to_device\u001b[1;34m(batch, device)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mapply_to_collection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_TransferableDataType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\lightning_utilities\\core\\apply_func.py\u001b[0m in \u001b[0;36mapply_to_collection\u001b[1;34m(data, dtype, function, wrong_dtype, include_none, allow_frozen, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# fast path for the most common cases:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# single element\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mlist\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# 1d homogeneous list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\conda\\envs\\layout\\lib\\site-packages\\lightning_fabric\\utilities\\apply_func.py\u001b[0m in \u001b[0;36mbatch_to\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_BLOCKING_DEVICE_TYPES\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"non_blocking\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[0mdata_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdata_output\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Any\n",
    "import pytorch_lightning as pl\n",
    "from config import *\n",
    "import torchvision.models as models\n",
    "from torchvision.ops import MLP\n",
    "import math\n",
    "from torch import Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from VerticalCompressionNet import * \n",
    "from CustomTransformer import *\n",
    "\n",
    "def encode_target(box_b):\n",
    "    box_b[:, 1] = torch.abs(0.5 -box_b[:, 1])  # v top\n",
    "    box_b[:, 2] = torch.abs(box_b[:, 2] -0.5) # v btm\n",
    "    box_b[:, 3] = torch.abs(box_b[:, 3] - box_b[:, 0]) # du\n",
    "\n",
    "    box_b[:, 4] = torch.abs(0.5 -box_b[:, 4])  # v top\n",
    "    box_b[:, 5] = torch.abs(box_b[:, 4] -0.5) # v btm\n",
    "\n",
    "    return box_b\n",
    "def decode_target(box_b):\n",
    "    box_b[:, 1] = 0.5 -box_b[:, 1]  # v top\n",
    "    box_b[:, 2] = box_b[:, 2] +0.5 # v btm\n",
    "    box_b[:, 3] = box_b[:, 3] + box_b[:, 0] # du\n",
    "\n",
    "    box_b[:, 4] = 0.5 -box_b[:, 4]  # v top\n",
    "\n",
    "    \n",
    "    box_b[:, 5] = box_b[:, 4] +0.5 # v btm\n",
    "\n",
    "    return box_b\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: 256, dropout: float = 0.1, max_len: int = 1024):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, d_model: int, nhead: int , d_hid: int, nlayers: int, dropout: float = 0.1 , activation=\"relu\" , normalize_before=False , out_dim=20):\n",
    "        super().__init__()\n",
    "        #self.ntoken = ntoken\n",
    "        self.model_type = 'Transformer'\n",
    "        self.d_model = d_model\n",
    "        self.out_dim =out_dim\n",
    "        \n",
    "        self.pe = PositionalEncoding(d_model,dropout)\n",
    "        self.query_embed = nn.Embedding(out_dim, d_model)\n",
    "\n",
    "        encoder_layer = TransformerEncoderLayer(d_model, nhead, d_hid,\n",
    "                                                dropout, activation, normalize_before)\n",
    "        encoder_norm = nn.LayerNorm(d_model) if normalize_before else None\n",
    "        self.encoder = TransformerEncoder(encoder_layer, nlayers, encoder_norm)\n",
    "        '''\n",
    "       \n",
    "        self.decoder = nn.Linear(out_dim, d_model)\n",
    "        '''\n",
    "        decoder_layer = nn.TransformerDecoderLayer(d_model=256, nhead=8  )\n",
    "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "\n",
    "        self.decoder1 = nn.Conv1d(1024 , 512 , kernel_size=3 , padding=1)\n",
    "        self.decoder2 = nn.Conv1d(512 , 128 , kernel_size=1)\n",
    "        self.decoder3 = nn.Conv1d(128 , self.out_dim , kernel_size=1)\n",
    "        \n",
    "        self.cls_head = nn.Linear(d_model, 1 )\n",
    "        self.box_head = nn.Linear(d_model, 6 )\n",
    "    \n",
    "        \n",
    "    def forward(self, src: Tensor ) -> Tensor:\n",
    "        # permute to (Sequence_length , Batches , Hidden layer)\n",
    "        '''\n",
    "        plt.imshow(src[0].detach().cpu().numpy())\n",
    "        plt.title(\"src\")\n",
    "        plt.show()\n",
    "        '''\n",
    "        src         = src.permute(1 , 0 , 2)# torch.Size([1024, b, 256])        \n",
    "        batch_size  = src.shape[1]        \n",
    "        src_pe         = self.pe(src)   # [ 1024 , 2 , hidden_dim]\n",
    "        src_pe         = self.encoder(src_pe)\n",
    "        src_pe         = src_pe.permute(1,0,2)\n",
    "\n",
    "        \n",
    "        #plt.imshow(src_pe[0].detach().cpu().numpy())\n",
    "        #plt.title(\"encoder output\")\n",
    "        #plt.show()\n",
    "\n",
    "        out = self.decoder1(src_pe)        \n",
    "        out = torch.relu(out)\n",
    "        out = self.decoder2(out)        \n",
    "        out = torch.relu(out)\n",
    "        out = self.decoder3(out)        \n",
    "        out = torch.relu(out)\n",
    "        #print(\"src_pe\",src_pe.shape)        \n",
    "       \n",
    "        box_logits = self.box_head(out)\n",
    "        cls_logits = self.cls_head(out)\n",
    "        \n",
    "\n",
    "        return box_logits ,cls_logits\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "class VerticalQueryTransformer(pl.LightningModule):    \n",
    "    def __init__(self  ,  max_predict_count = 24 ,\n",
    "                    hidden_out = 128 , class_num = 1 ,\n",
    "                    log_folder = \"__test\" , num_classes = 1 , backbone_trainable =False, load_weight =\"\" , top_k = 20 \n",
    "                    ):\n",
    "        #print(\" input_size\" ,  input_size)\n",
    "        super().__init__()\n",
    "        self.backbone = Resnet()\n",
    "        self.out_scale = 8\n",
    "        self.step_cols = 4        \n",
    "        self.hidden_size = hidden_out\n",
    "        self.max_predict_count = max_predict_count\n",
    "        self.num_classes  = num_classes \n",
    "        self.top_k_num = top_k        \n",
    "\n",
    "        self.fixed_pe = PositionalEncoding(hidden_out, 0.1 , 1024)\n",
    "\n",
    "        self.transformer = TransformerModel( d_model=hidden_out , nhead=8 , d_hid= 256,nlayers=6 ,out_dim=max_predict_count)\n",
    "        #self.transformer = nn.TransformerEncoderLayer(hidden_out ,  8 , 2048 , dropout= 0.1) \n",
    "\n",
    "        self.confidence_threshold = 0.9\n",
    "\n",
    "        # loss\n",
    "        self.box_cost = 1\n",
    "        self.cls_cost = 5\n",
    "\n",
    "        self.log_folder = create_folder(os.path.join(os.getcwd() , \"output\" , log_folder))\n",
    "        \n",
    "\n",
    "        # Inference channels number from each block of the encoder\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros(1, 3, 320, 190)\n",
    "            c1, c2, c3, c4 = [b.shape[1] for b in self.backbone(dummy)] # resnet feature channel數\n",
    "            #print(\"c1, c2, c3, c4\" , c1, c2, c3, c4)\n",
    "            c_last = (c1*8 + c2*4 + c3*2 + c4*1) // self.out_scale            \n",
    "        #self.v_reproj = nn.Conv2d(1024 , self.max_predict_count,kernel_size=1)\n",
    "            \n",
    "        self.reduce_height_module = GlobalHeightStage(c1, c2, c3, c4 , out_scale=self.out_scale , pretrain_weight= load_weight , freeze_model= not backbone_trainable)\n",
    "\n",
    "    def post_process(self ,box_coord , index , max_length = 1024):\n",
    "        '''\n",
    "        box_coord : contains left top v ,left btm v , du , right top v , right btm v\n",
    "        '''\n",
    "        origin_shape = box_coord.shape\n",
    "        box_coord = box_coord.view(-1 , 5)\n",
    "        \n",
    "        us = (index/max_length).view((box_coord.shape[0] , 1))\n",
    "        uvv_uvv_b = torch.zeros((box_coord.shape[0] , 6) , device=box_coord.device)\n",
    "        uvv_uvv_b[:,0] = us[:,0]\n",
    "        uvv_uvv_b[:,1] = box_coord[:,0] # left top v\n",
    "        uvv_uvv_b[:,2] = box_coord[:,1] # left btm v\n",
    "        uvv_uvv_b[:,3] = us[:,0] + box_coord[:,2] # right u\n",
    "        uvv_uvv_b[:,4] = box_coord[:,3] # right top v\n",
    "        uvv_uvv_b[:,5] = box_coord[:,4] # right btm v\n",
    "\n",
    "        #return uvv_uvv_b.view(origin_shape[0] , origin_shape[1] , 6)\n",
    "        return uvv_uvv_b.view(origin_shape[0] , -1 , 6)\n",
    "\n",
    "        pass\n",
    "\n",
    "    def forward(self ,x ):\n",
    "        features = self.backbone(x) # [4 , c , h, w]              \n",
    "        # vertical feature\n",
    "        reduced_feats  = self.reduce_height_module(features , x.shape[3]//self.step_cols ) # [b , 1024 ,  256] width = 1024 , 256d latent code each.\n",
    "        #plt.imshow(reduced_feats[0].detach().cpu().numpy())\n",
    "        #plt.title(\"reduced_feats\")\n",
    "        #plt.show()\n",
    "\n",
    "        out_box , out_cls = self.transformer(reduced_feats)  # (b , 1024 , 256 )               \n",
    "\n",
    "        return out_box , out_cls\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def inf(self , imgs ):\n",
    "        \n",
    "        out_box , out_cls   = self.forward(imgs)  # [ batch , top_k , 5]   , [ batch , top_k , 1]         \n",
    "        #print(\"val \" , out_cls)\n",
    "        #print(\"val sigmoid\" , torch.sigmoid(out_cls))\n",
    "        \n",
    "        batch_size = out_box.shape[0]\n",
    "        #sampled_u_idx = torch.argwhere( torch.sigmoid(out_cls.view(batch_size , -1)) > 0.01 )\n",
    "        #print(\"sampled_u_idx\" , sampled_u_idx)\n",
    "\n",
    "        sampled_box_b = []\n",
    "        #each batch\n",
    "        for img , pred , pcls in zip(imgs, out_box , out_cls.view(batch_size,-1)):  \n",
    "            u_id = torch.argwhere(torch.sigmoid(pcls) > self.confidence_threshold)\n",
    "            print(\"u_id\"  , u_id)\n",
    "            if(u_id.numel() ==0):\n",
    "                continue\n",
    "            u_id = u_id.view(-1)            \n",
    "            \n",
    "            #pred = self.post_process(pbox[u_id,:] , u_id ).view(-1,6)\n",
    "            pred = pred[u_id]\n",
    "            \n",
    "            save_folder = create_folder( os.path.join(self.log_folder ,\"val\"))\n",
    "            save_path = os.path.join(save_folder, f\"val_ep_{self.current_epoch}-{self.global_step}\" )\n",
    "\n",
    "            decode_pred = decode_target(pred.clone())\n",
    "            #pred_us , pred_tops , pred_btms = self.pack_visualize(pred[:,0], pred[:,1],pred[:,2],pred[:,3] -pred[:,0] ,pred[:,4],pred[:,5] )                    \n",
    "            pred_us , pred_tops , pred_btms = self.pack_visualize(decode_pred[:,0], decode_pred[:,1],decode_pred[:,2],decode_pred[:,3] ,decode_pred[:,4],decode_pred[:,5] )                    \n",
    "            vis_imgs = visualize_2d_single(pred_us , pred_tops , pred_btms , u_grad = F.sigmoid(pcls).view(1 , -1 ) , imgs=  img , title=\"Pred\" , save_path= save_path  )\n",
    "            #plt.imshow(vis_imgs)\n",
    "            #plt.show()\n",
    "\n",
    "            # ToDo: calculate loss          \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def pack_visualize(self, gt_u_b , gt_vtop_b , gt_vbtm_b , gt_du_b , gt_dvtop_b , dv_btm_b ):\n",
    "        \n",
    "        if isinstance(gt_u_b, torch.Tensor):\n",
    "            sizes = [t.numel() for t in gt_u_b]               \n",
    "            us = gt_u_b.flatten().unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            us[1::2]+=gt_du_b.flatten()\n",
    "            us = torch.split(us.view(-1,2) , sizes)\n",
    "\n",
    "            tops = gt_vtop_b.flatten().unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            tops[1::2]=gt_dvtop_b.flatten()\n",
    "            tops = torch.split(tops.view(-1,2) , sizes)\n",
    "\n",
    "            btms = gt_vbtm_b.flatten().unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            btms[1::2]=dv_btm_b.flatten()\n",
    "            btms = torch.split(btms.view(-1,2) , sizes)\n",
    "\n",
    "        elif isinstance(gt_u_b, tuple) and all(isinstance(t, torch.Tensor) for t in gt_u_b):        \n",
    "            sizes = [len(t) for t in gt_u_b]               \n",
    "            us = torch.cat(gt_u_b).view(-1).unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            us[1::2]+=torch.cat(gt_du_b).view(-1)\n",
    "            us = torch.split(us.view(-1,2) , sizes)\n",
    "\n",
    "            tops = torch.cat(gt_vtop_b).view(-1).unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            tops[1::2]=torch.cat(gt_dvtop_b).view(-1)\n",
    "            tops = torch.split(tops.view(-1,2) , sizes)\n",
    "\n",
    "            btms = torch.cat(gt_vbtm_b).view(-1).unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            btms[1::2]=torch.cat(dv_btm_b).view(-1)\n",
    "            btms = torch.split(btms.view(-1,2) , sizes)\n",
    "        else:\n",
    "            assert(\"Wrong Type.\")\n",
    "        \n",
    "        return us , tops ,btms\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def training_step(self , input_b ,batch_idx , optimizer_idx):\n",
    "        \n",
    "        img = input_b['image']\n",
    "        print(\"batch_idx\" , batch_idx)\n",
    "        out_box , out_cls   = self.forward(img)  # [ batch , top_k , 5]   , [ batch , top_k , 1] \n",
    "        #print(\"max out_cls\" , torch.max(out_cls) , \"min \" , torch.min(out_cls))\n",
    "        batch_size = out_box.shape[0]\n",
    "        \n",
    "        '''\n",
    "        if self.current_epoch % 5 == 0 :#and self.current_epoch > 0 :       \n",
    "            plt.imshow(out_cls[0].repeat(1,100).detach().cpu().numpy())\n",
    "            plt.title(\"encoder cls output\")\n",
    "            plt.show()      \n",
    "        '''\n",
    "\n",
    "        # Select top k        \n",
    "        #top_k = torch.topk(out_cls ,self.top_k_num , dim= 1 )\n",
    "        #top_k_idx = top_k[1].view(batch_size  , self.top_k_num)  # [b , top_k ]        \n",
    "        #print(\"top_k_idx\" , top_k_idx.shape , top_k_idx)\n",
    "\n",
    "        #topk_box = out_box.gather(1 , top_k_idx.unsqueeze(-1).repeat(1,1,5))\n",
    "        #topk_cls = out_cls.gather(1 , top_k_idx.unsqueeze(-1).repeat(1,1,1))\n",
    "        #print(\"topk_cls\" , topk_cls.shape)\n",
    "        \n",
    "        #pred_uvvboxes_b = self.post_process(topk_box , top_k_idx )\n",
    "        #pred_uvvboxes_b = self.post_process(out_box , out_box )\n",
    "        #print(\"pred_uvvboxes_b\" , pred_uvvboxes_b.shape ,pred_uvvboxes_b)\n",
    "\n",
    "        # remove padding , each batch have different length\n",
    "        gt_u_b = unpad_data( input_b['u'])          \n",
    "        gt_vtop_b =unpad_data(input_b['v_top'])\n",
    "        gt_vbtm_b = unpad_data (input_b['v_btm'])\n",
    "        gt_du_b = unpad_data(input_b['du'])\n",
    "        gt_dvtop_b = unpad_data(input_b['dv_top'])\n",
    "        gt_dv_btm_b = unpad_data(input_b['dv_btm'])\n",
    "\n",
    "        #selected_gt_u_grad =  input_b['u_grad'].view(batch_size , 1024 , 1).gather(1 , top_k_idx.unsqueeze(-1).repeat(1,1,1)).view(batch_size , self.top_k_num)        \n",
    "\n",
    "        total_loss = 0\n",
    "        b_cnt = 0\n",
    "        \n",
    "        #for u,vtop,vbtm,du,dvtop, dvbtm , pred ,cls_b,gt_cls in zip(gt_u_b , gt_vtop_b , gt_vbtm_b , gt_du_b , gt_dvtop_b , gt_dv_btm_b , pred_uvvboxes_b , topk_cls , input_b['u_grad']):\n",
    "        for u,vtop,vbtm,du,dvtop, dvbtm , pred ,cls_b  in zip(gt_u_b , gt_vtop_b , gt_vbtm_b , gt_du_b , gt_dvtop_b , gt_dv_btm_b , out_box , out_cls  ):\n",
    "            \n",
    "            # match                        \n",
    "            gt_box =  torch.vstack([ u, vtop,vbtm, u + du ,dvtop , dvbtm]).permute(1,0)   # [n , 6]\n",
    "            #print(\"gt_box\" , gt_box)\n",
    "\n",
    "            gt_l1_target = encode_target(gt_box.clone())\n",
    "            #print(\"gt_l1_target\" , gt_l1_target)\n",
    "            \n",
    "\n",
    "            \n",
    "            row_idx = torch.round(u*self.max_predict_count).to(torch.long).detach().cpu().numpy()\n",
    "            col_idx = torch.argsort(u).detach().cpu().numpy().astype(np.int32) \n",
    "            '''\n",
    "            print(\"row_idx  \" , row_idx  )\n",
    "            print(\"col_idx  \" , col_idx  )\n",
    "            print(\"matched pred\" , pred[row_idx] )\n",
    "            print(\"matched gt \" , gt_box[col_idx] )\n",
    "            print(\"pred cls\" , cls_b)            \n",
    "            '''\n",
    "            \n",
    "            gt_cls = torch.zeros(self.max_predict_count,device= cls_b.device )            \n",
    "            gt_cls[row_idx] = 1            \n",
    "\n",
    "            neg_sample = (np.random.rand(row_idx.shape[0]) * self.max_predict_count).astype(np.int32)\n",
    "            neg_sample = [(val + 1) % self.max_predict_count if val in row_idx else val for val in neg_sample]\n",
    "            cls_sample_idx =  np.concatenate((row_idx , neg_sample)).astype(np.int32)% self.max_predict_count\n",
    "            print (\"cls_sample_idx\" , cls_sample_idx)\n",
    "            print(cls_b.view(-1).shape)\n",
    "            print(gt_cls.view(-1).shape)\n",
    "            print (\"cls_b.view(-1)[cls_sample_idx]\" ,cls_b.view(-1)[cls_sample_idx])\n",
    "            print (\"gt_cls.view(-1)[cls_sample_idx]\" ,gt_cls.view(-1)[cls_sample_idx])\n",
    "            print(pred.shape)\n",
    "            print(gt_l1_target.shape)\n",
    "\n",
    "            \n",
    "            l1_loss = F.l1_loss(pred[row_idx] ,  gt_l1_target[col_idx]) \n",
    "            cls_loss = F.binary_cross_entropy_with_logits(cls_b.view(-1)[cls_sample_idx], gt_cls.view(-1)[cls_sample_idx]) \n",
    "            \n",
    "            print(\"L1 loss\"  , l1_loss)\n",
    "            print(\"cls_loss\"  , cls_loss)\n",
    "            \n",
    "            total_loss += l1_loss+ cls_loss\n",
    "            #total_loss += cls_loss\n",
    "                        \n",
    "            with torch.no_grad():\n",
    "                #if self.current_epoch % 5 == 0  :                \n",
    "                if self.current_epoch % 5 == 0 and self.current_epoch > 0 and b_cnt<10 :                \n",
    "                    save_path =  os.path.join(self.log_folder , f\"gt_ep_{self.current_epoch}-{self.global_step}-{b_cnt}\" )\n",
    "                    gt_us , gt_tops , gt_btms = self.pack_visualize(u.view(1 , -1 ) , vtop , vbtm , du , dvtop , dvbtm )\n",
    "                    #print(\"gt_us , gt_tops , gt_btms\" , gt_us , gt_tops , gt_btms)\n",
    "                    vis_imgs = visualize_2d_single(gt_us , gt_tops , gt_btms , u_grad =  gt_cls.view(1 , -1 ), imgs= img[b_cnt] , title=\"GT\",save_path=save_path )                \n",
    "                    \n",
    "                    save_path =  os.path.join(self.log_folder , f\"pred_ep_{self.current_epoch}-{self.global_step}-{b_cnt}\" )\n",
    "                    decode_pred = decode_target(pred.clone())\n",
    "                    #pred_us , pred_tops , pred_btms = self.pack_visualize(pred[row_idx,0], pred[row_idx,1],pred[row_idx,2],pred[row_idx,3] ,pred[row_idx,4],pred[row_idx,5] )                    \n",
    "                    pred_us , pred_tops , pred_btms = self.pack_visualize(decode_pred[row_idx,0], decode_pred[row_idx,1],decode_pred[row_idx,2],decode_pred[row_idx,3] ,decode_pred[row_idx,4],decode_pred[row_idx,5] )                    \n",
    "                    vis_imgs = visualize_2d_single(pred_us , pred_tops , pred_btms , u_grad = F.sigmoid(cls_b).view(1 , -1 ) , imgs=  img[b_cnt] , title=\"Pred\" , save_path= save_path  )\n",
    "                    \n",
    "           \n",
    "            b_cnt+=1\n",
    "            pass        \n",
    "        return total_loss / batch_size\n",
    "        pass    \n",
    "\n",
    "    def validation_step(self, input_b, batch_idx):\n",
    "        print(\"val!!!!!\")\n",
    "        img = input_b['image']\n",
    "        \n",
    "        #out_box , out_cls   = self.forward(img)  # [ batch , top_k , 5]   , [ batch , top_k , 1]         \n",
    "        self.inf(img)\n",
    "        return\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        backbone_opt = optim.Adam(self.backbone.parameters() , lr=0.00035)\n",
    "        comp_opt = optim.Adam(self.reduce_height_module.parameters() , lr=0.00035)\n",
    "        transforms_opt = optim.Adam(self.transformer.parameters() , lr=0.00015)\n",
    "\n",
    "        return [backbone_opt ,comp_opt, transforms_opt] , []\n",
    "\n",
    "\n",
    "    pass\n",
    "\n",
    "# Unit testing...\n",
    "save_path = create_folder( os.path.join(os.getcwd() , \"output\" , \"checkpoints\"))\n",
    "save_file = os.path.join(save_path , \"detr_v1_d20_e50.pth\")\n",
    "\n",
    "# Test\n",
    "dm = CustomDataModule ( train_dir= f\"../anno/train_visiable_200_no_cross.json\" ,\n",
    "                        test_dir= f\"../anno/test_visiable_10_no_cross.json\" , padding_count=20 , use_aug=False , c= 0.95,batch_size=6\n",
    "                       )\n",
    "m = VerticalQueryTransformer(max_predict_count = 20 , hidden_out=256 , load_weight=\"D:/OneDrive/OneDrive - NTHU/Layout/Horizon/0912_all_bk.pth\"  , backbone_trainable=True)\n",
    "\n",
    "'''\n",
    "save_path = create_folder( os.path.join(os.getcwd() , \"output\" , \"checkpoints\"))\n",
    "save_file = os.path.join(save_path , \"detr_v1_d20_e50.pth\")\n",
    "m = torch.load(save_file)\n",
    "    \n",
    "        \n",
    "\n",
    "#print(o)\n",
    "'''\n",
    "trainer = pl.Trainer(accelerator='gpu' , devices=1 ,min_epochs=1, max_epochs=51 , precision=16 , fast_dev_run=False )\n",
    "trainer.fit(m , dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.2000, 0.4000, 0.6000, 0.8000])\n",
      "torch.Size([5])\n",
      "tensor([0.0000, 0.2878, 0.6753, 0.0745, 1.0726])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "mean = torch.arange(5)/5\n",
    "std = torch.arange(5)/5\n",
    "print(mean)\n",
    "a = torch.normal(mean, std)\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = create_folder( os.path.join(os.getcwd() , \"output\" , \"checkpoints\"))\n",
    "save_file = os.path.join(save_path , \"detr_v1_d20_e50.pth\")\n",
    "torch.save(m , save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.rand(2,20,2)\n",
    "b = torch.rand(20,2)\n",
    "c = b.repeat(2,1,1)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.rand(20,2)\n",
    "b = torch.rand(20)*2\n",
    "b = b.to(torch.long).view(-1,1)\n",
    "#c = a[b]\n",
    "c= torch.gather(a,1,b)\n",
    "print(c.shape)\n",
    "print(a)\n",
    "print(b)\n",
    "print()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "memory = torch.rand(10, 32, 512)\n",
    "tgt = torch.rand(20, 32, 512)\n",
    "out = transformer_decoder(tgt, memory)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "horizon_path =r\"D:/OneDrive/OneDrive - NTHU/Layout/Horizon/0912_all_bk.pth\"\n",
    "#models_dict = torch.load_s\n",
    "checkpoint = torch.load(horizon_path ,  map_location=\"cpu\")\n",
    "print(checkpoint['state_dict'].keys())\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "pretrained_dict = {k: v for k, v in checkpoint['state_dict'].items() if k in m.state_dict()}\n",
    "m.load_state_dict(pretrained_dict , strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.rand(2,256 ,1024)\n",
    "b = nn.Conv1d(256 , 64 , kernel_size=3 ,padding=1)\n",
    "c = b(a)\n",
    "print(c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,5,2)\n",
    "print(a)\n",
    "b=  nn.MaxPool2d((5,1))\n",
    "c = b(a)\n",
    "print(c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(200).view(2,100,1)\n",
    "#aa = a[:,:,0].unsqueeze(0)\n",
    "#print(aa.shape)\n",
    "b = F.interpolate(a.view(2,-1).unsqueeze(0), 10 )[0]\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,10,1)\n",
    "b = torch.cat([a,a] , dim=1)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = torch.rand(2,100,1)\n",
    "a = torch.arange(400).view(2,100,2)\n",
    "b = torch.arange(20).view(2,10)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "b= b.unsqueeze(-1).repeat(1,1,2)\n",
    "print(b)\n",
    "#print(\"b unsqueeze\",b.unsqueeze(-1))\n",
    "\n",
    "c = a.gather(1, b)\n",
    "print(c.shape)\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.arange(5)\n",
    "b=torch.arange(5)\n",
    "c=torch.arange(5)\n",
    "\n",
    "d = torch.vstack([a,b,c]).permute(1,0)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "a = torch.tensor([ [0,1,2]  ,  [0,3,5] , [1,0,5] ]).to(torch.float32)\n",
    "b = torch.tensor([ [0,1,2] , [1,0,5] ]).to(torch.float32)\n",
    "\n",
    "cost = torch.cdist(b,a)\n",
    "print(cost)\n",
    "row , col = linear_sum_assignment(cost,)\n",
    "print(row)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.7605, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.7730, 0.5752, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.7057, 0.5861, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.8386, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.8304, 0.7823, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.7034, 0.5994, 0.5691, 0.5652, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.6996, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.8305, 0.7819, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.8238, 0.7839, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
    "# Get the indices of non-zero elements\n",
    "non_zero_indices = torch.nonzero(x)\n",
    "print(non_zero_indices)\n",
    "# Get the non-zero values\n",
    "non_zero_values = x[non_zero_indices[:,0], non_zero_indices[:,1]]\n",
    "\n",
    "unique = torch.unique(non_zero_indices[:,0] ,return_counts=True)\n",
    "print(\"unique\" , unique)\n",
    "# Print the result\n",
    "print(non_zero_values)\n",
    "non_zero_values = torch.split(non_zero_values , tuple(unique[1]))\n",
    "print(\"split non_zero_values\" , non_zero_values)\n",
    "\n",
    "def unpad_data( x :[Tensor] ) :\n",
    "\tnon_zero_indices = torch.nonzero(x)\n",
    "\tprint(non_zero_indices)\n",
    "\t# Get the non-zero values\n",
    "\tnon_zero_values = x[non_zero_indices[:,0], non_zero_indices[:,1]]\n",
    "\n",
    "\tunique = torch.unique(non_zero_indices[:,0] ,return_counts=True)\n",
    "\tprint(\"unique\" , unique)\n",
    "\t# Print the result\n",
    "\tprint(non_zero_values)\n",
    "\tnon_zero_values = torch.split(non_zero_values , tuple(unique[1]))\n",
    "\tprint(\"split non_zero_values\" , non_zero_values)\n",
    "\treturn non_zero_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0.58 , 0.6] , [0.4] ] , )\n",
    "b = torch.tensor([0.1 , 0.2] , )\n",
    "\n",
    "c = a.repeat(2)\n",
    "print(a.repeat(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, tgt)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.rand(1)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Layout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
