{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "from pytorch_lightning.utilities.types import EVAL_DATALOADERS, TRAIN_DATALOADERS\n",
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "import json\n",
    "from CustomDataset import * \n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import *\n",
    "from file_helper import *\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "#=================================\n",
    "#             Augmentation\n",
    "#=================================\n",
    "\n",
    "def gauss_noise_tensor(img):\n",
    "    rand = torch.rand(1)[0]\n",
    "    if rand < 0.5 and Horizon_AUG:\n",
    "        sigma = rand *0.125\n",
    "        out = img + sigma * torch.randn_like(img)\n",
    "        return out\n",
    "    return img\n",
    "\n",
    "def blank(img):    \n",
    "    return img\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self ,\n",
    "                 train_dir ,\n",
    "                 test_dir , batch_size = 2, num_workers = 0 , img_size=[IMG_WIDTH, IMG_HEIGHT] , use_aug = True ,padding_count = 24 ,c =0.1\n",
    "                   ):\n",
    "        super().__init__()\n",
    "        self.train_dir = train_dir\n",
    "        self.test_dir = test_dir\n",
    "        \n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.img_size = img_size      \n",
    "        self.use_aug = use_aug\n",
    "        self.padding_count  = padding_count\n",
    "        self.c = c\n",
    "        \n",
    "\n",
    "        pass\n",
    "\n",
    "    def prepare_data(self) -> None:\n",
    "        # Download dataset\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage):\n",
    "        # Create dataset...          \n",
    "                \n",
    "        self.entire_dataset = CustomDataset(self.train_dir  , use_aug= self.use_aug , padding_count= self.padding_count , c=self.c)\n",
    "        self.train_ds , self.val_ds = random_split(self.entire_dataset , [0.9, 0.1])        \n",
    "        self.test_ds = CustomDataset(self.test_dir  , use_aug= False)\n",
    "        \n",
    "        pass\n",
    "\n",
    "    # ToDo: Reture Dataloader...\n",
    "    def train_dataloader(self) -> TRAIN_DATALOADERS:\n",
    "        return DataLoader(self.train_ds , batch_size= self.batch_size , num_workers= self.num_workers , shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(self.val_ds , batch_size= self.batch_size , num_workers= self.num_workers , shuffle=False)\n",
    "    \n",
    "    def test_dataloader(self) -> EVAL_DATALOADERS:\n",
    "        return DataLoader(self.test_ds , batch_size= self.batch_size , num_workers= self.num_workers , shuffle=False)\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "# Test\n",
    "dm = CustomDataModule ( train_dir= f\"../anno/test_visiable_10_no_cross.json\" ,\n",
    "                       test_dir= f\"../anno/test_visiable_10_no_cross.json\" , padding_count=256\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "def unpad_data( x :[Tensor] ) :\n",
    "\tnon_zero_indices = torch.nonzero(x)\n",
    "\t#print(non_zero_indices)\n",
    "\t# Get the non-zero values\n",
    "\tnon_zero_values = x[non_zero_indices[:,0], non_zero_indices[:,1]]\n",
    "\n",
    "\tunique = torch.unique(non_zero_indices[:,0] ,return_counts=True)\t\n",
    "\tnon_zero_values = torch.split(non_zero_values , tuple(unique[1]))\n",
    "\t\n",
    "\treturn non_zero_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3655, 0.8320, 0.5488, 0.5542, 0.1095, 0.8735],\n",
      "        [1.1914, 1.6289, 0.7690, 0.4539, 0.1058, 0.8794]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.3406, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1212, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3684, 0.8438, 0.5503, 0.5566, 0.1157, 0.8726]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.2034, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0720, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3411, 0.8218, 0.5635, 0.5581, 0.0944, 0.8931]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.2037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0721, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.9087,  1.3643,  0.3721,  0.1082, -0.0666,  0.9082],\n",
      "        [ 0.3320,  0.8257,  0.5703,  0.5576,  0.0991,  0.9023],\n",
      "        [ 1.1641,  1.6143,  0.7881,  0.4675,  0.0964,  0.9180]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782]], device='cuda:0')\n",
      "L1 loss tensor(0.3612, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2167, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3389, 0.8257, 0.5664, 0.5547, 0.0999, 0.8979]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.2719, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0718, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.0452, 0.8540, 0.5356, 0.7656, 0.1372, 0.7109]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.2884, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0717, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0281, 0.8428, 0.5522, 0.7651, 0.1298, 0.7305]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.2953, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0717, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0397, 0.8467, 0.5449, 0.7637, 0.1356, 0.7188],\n",
      "        [0.9624, 1.5996, 0.8657, 0.7188, 0.1554, 0.7837]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.2914, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1183, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0845, 0.8467, 0.5205, 0.7563, 0.1465, 0.6860]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.2801, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0734, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0416, 0.8525, 0.5420, 0.7646, 0.1393, 0.7163]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.2891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0718, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.0891, 0.6069, 0.7676, 0.6992, 0.3572, 0.8770],\n",
      "        [0.9526, 1.3799, 1.0566, 0.8135, 0.3596, 0.8960]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046],\n",
      "        [0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915]], device='cuda:0')\n",
      "L1 loss tensor(0.2429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1177, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0907, 0.6060, 0.7632, 0.6973, 0.3574, 0.8721],\n",
      "        [0.9546, 1.3809, 1.0537, 0.8101, 0.3596, 0.8911]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.2615, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1176, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1086, 0.6152, 0.7520, 0.6978, 0.3650, 0.8564],\n",
      "        [0.9697, 1.3945, 1.0410, 0.8042, 0.3645, 0.8691]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.2645, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1179, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[  0.8120,   1.2109,   0.6299,   0.2544,   0.1438,   0.8828],\n",
      "        [  0.0719,   0.6094,   0.7754,   0.6997,   0.3574,   0.8911],\n",
      "        [  0.9375,   1.3779,   1.0635,   0.8193,   0.3606,   0.9141],\n",
      "        [-12.7500,   9.9609,   7.4023,  -3.9199,   1.1787,  41.5312]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657],\n",
      "        [0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647],\n",
      "        [0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569]], device='cuda:0')\n",
      "L1 loss tensor(3.3913, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(1.2155, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1211, 0.6162, 0.7441, 0.6948, 0.3684, 0.8477]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0699, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[0.2542, 0.1899, 0.9590, 0.5127, 0.5454, 0.9941]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.1081, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0713, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2461, 0.1870, 0.9673, 0.5122, 0.5439, 1.0059]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.1428, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0711, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2402, 0.1880, 0.9717, 0.5142, 0.5425, 1.0117]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.1357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1059, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.8457, 0.7461, 0.7231, 0.1552, 0.3684, 0.7461],\n",
      "        [0.2073, 0.0584, 0.9014, 0.4753, 0.4993, 0.8408],\n",
      "        [0.7178, 0.7324, 1.0059, 0.8726, 0.7388, 0.6992]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298]], device='cuda:0')\n",
      "L1 loss tensor(0.2450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2953, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.8589, 0.7500, 0.7153, 0.1494, 0.3745, 0.7314],\n",
      "        [0.2189, 0.0620, 0.8940, 0.4736, 0.5029, 0.8296]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.1755, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1906, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2281, 0.0645, 0.8857, 0.4741, 0.5034, 0.8208]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.1358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0673, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2162, 0.0550, 0.8936, 0.4763, 0.4949, 0.8311]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.1532, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0674, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2229, 0.0702, 0.8872, 0.4771, 0.5049, 0.8242]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.1132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0668, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.2852, 0.0861, 0.7280, 0.5894, 0.2898, 0.6392]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.1201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0649, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[  0.7876,   0.6929,   0.6338,   0.2822,   0.2634,   0.6128],\n",
      "        [  0.2223,   0.0865,   0.7642,   0.6006,   0.2788,   0.6875],\n",
      "        [  0.5571,   0.6030,   0.8428,   1.0322,   0.6943,   0.5474],\n",
      "        [ -4.6992,  -7.9688,  -2.0859,  12.3047, -12.7031,  39.2500]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647],\n",
      "        [0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569]], device='cuda:0')\n",
      "L1 loss tensor(3.4652, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(1.7995, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2386, 0.0841, 0.7554, 0.5972, 0.2793, 0.6719],\n",
      "        [0.5723, 0.6060, 0.8359, 1.0254, 0.6938, 0.5288]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.1766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1159, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2266, 0.0800, 0.7637, 0.5996, 0.2739, 0.6841]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.1133, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0670, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2389, 0.0853, 0.7563, 0.5986, 0.2795, 0.6729],\n",
      "        [0.5723, 0.6064, 0.8364, 1.0273, 0.6938, 0.5308]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046],\n",
      "        [0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915]], device='cuda:0')\n",
      "L1 loss tensor(0.1617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1160, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.5264, 0.1980, 0.7339, 0.5205, 0.0637, 0.7041]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.1570, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0619, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5181, 0.1913, 0.7349, 0.5200, 0.0579, 0.7061],\n",
      "        [0.6616, 0.4568, 0.6992, 0.9546, 0.5806, 0.5737]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.1343, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1170, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5234, 0.1879, 0.7324, 0.5190, 0.0580, 0.7036],\n",
      "        [0.6660, 0.4541, 0.6963, 0.9521, 0.5811, 0.5708]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1167, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4934, 0.1851, 0.7524, 0.5225, 0.0483, 0.7275]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.1110, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0616, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4998, 0.1882, 0.7471, 0.5215, 0.0537, 0.7212]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.1571, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0617, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[0.5347, 0.4683, 0.7588, 0.4202, 0.0137, 0.7788]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1478, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0602, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.4990,  0.4575,  0.7822,  0.4229, -0.0027,  0.8101]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.1963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0598, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 5.0244e-01,  4.5947e-01,  7.7881e-01,  4.2236e-01, -3.6621e-04,\n",
      "          8.0420e-01]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.1856, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0598, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.3091, 0.5005, 1.0088, 0.2144, 0.1616, 1.1045],\n",
      "        [0.3840, 0.2325, 0.6816, 0.6040, 0.5654, 1.0127]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660],\n",
      "        [0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253]], device='cuda:0')\n",
      "L1 loss tensor(0.2323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1222, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3159, 0.5078, 0.9976, 0.2169, 0.1644, 1.0967]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.1862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0554, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4214, 0.2480, 0.6597, 0.5884, 0.5752, 0.9697]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.1177, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.3736, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3206, 0.5020, 0.9961, 0.2151, 0.1628, 1.0938]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.1686, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0557, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4089, 0.2576, 0.6670, 0.5981, 0.5781, 0.9849]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.1618, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.3722, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.2352, 0.5161, 1.0791, 0.1838, 0.2793, 1.1631],\n",
      "        [0.4124, 0.2137, 0.6812, 0.5508, 0.4858, 0.9800]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.2450, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1275, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2139, 0.5000, 1.0918, 0.1864, 0.2622, 1.1787]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.2553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0519, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2173, 0.5122, 1.0908, 0.1840, 0.2751, 1.1777]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.1777, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0516, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2122, 0.5034, 1.0957, 0.1821, 0.2683, 1.1846]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.1630, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0517, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.6699,  0.6123,  0.8701, -0.0442,  0.2219,  0.9937],\n",
      "        [ 0.1974,  0.5103,  1.1045,  0.1868,  0.2686,  1.1963],\n",
      "        [ 0.3792,  0.1937,  0.7036,  0.5605,  0.4797,  1.0225],\n",
      "        [22.6406, -1.8164, 15.1875,  9.5391, -8.7891, 20.8125]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657],\n",
      "        [0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569],\n",
      "        [0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647]], device='cuda:0')\n",
      "L1 loss tensor(3.3877, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(3.4969, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0577, 0.3735, 0.9150, 0.3684, 0.3777, 1.0303]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.1701, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0496, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1047, 0.3882, 0.8853, 0.3645, 0.3965, 0.9937]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0499, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5977, 0.5005, 0.7114, 0.0787, 0.2502, 0.8271],\n",
      "        [0.0611, 0.3748, 0.9111, 0.3682, 0.3801, 1.0264],\n",
      "        [0.3848, 0.1064, 0.4832, 0.6743, 0.3838, 0.8081]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782]], device='cuda:0')\n",
      "L1 loss tensor(0.1734, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.3130, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0728, 0.3784, 0.9048, 0.3665, 0.3843, 1.0176]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.0932, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0497, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0735, 0.3782, 0.9043, 0.3667, 0.3833, 1.0156],\n",
      "        [0.3955, 0.1148, 0.4778, 0.6704, 0.3865, 0.7935]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.1222, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1297, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[0.1550, 0.1724, 0.5752, 0.5508, 0.3489, 0.7026],\n",
      "        [0.5703, 0.0289, 0.2258, 0.7466, 0.1869, 0.4839]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1858, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1309, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6577, 0.3530, 0.4729, 0.1987, 0.1879, 0.5596],\n",
      "        [0.1287, 0.1685, 0.5928, 0.5532, 0.3403, 0.7241]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915],\n",
      "        [0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046]], device='cuda:0')\n",
      "L1 loss tensor(0.2443, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2371, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1248, 0.1694, 0.5933, 0.5537, 0.3394, 0.7261]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.1501, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0485, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.3455, 0.1272, 0.5210, 0.7993, 0.2686, 0.5474]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.1915, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0500, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2949, 0.1271, 0.5449, 0.8066, 0.2559, 0.5796]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.1838, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0492, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.7593,  0.3032,  0.4846,  0.4260,  0.1471,  0.4712],\n",
      "        [ 0.2810,  0.1271,  0.5508,  0.8086,  0.2542,  0.5894],\n",
      "        [ 0.7891,  0.0496,  0.2539,  0.9478,  0.0311,  0.4016],\n",
      "        [ 7.7539, 24.7969, 17.2500,  0.7778,  7.8320, -4.5938]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647],\n",
      "        [0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657]], device='cuda:0')\n",
      "L1 loss tensor(2.7326, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(2.7311, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.7671, 0.2969, 0.4797, 0.4229, 0.1454, 0.4651],\n",
      "        [0.2893, 0.1207, 0.5469, 0.8076, 0.2520, 0.5835],\n",
      "        [0.7964, 0.0468, 0.2496, 0.9453, 0.0278, 0.3936]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298],\n",
      "        [0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782]], device='cuda:0')\n",
      "L1 loss tensor(0.2739, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.3186, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3098, 0.1274, 0.5337, 0.8062, 0.2576, 0.5649]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.2205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0495, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.5229, 0.2578, 0.7295, 0.8062, 0.1588, 0.6641]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.1498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0518, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.9077, 0.4026, 0.6626, 0.4280, 0.1439, 0.5200],\n",
      "        [0.5439, 0.2551, 0.7222, 0.8018, 0.1650, 0.6523]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1842, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2336, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.8799, 0.3967, 0.6826, 0.4373, 0.1323, 0.5488],\n",
      "        [0.5171, 0.2510, 0.7388, 0.8052, 0.1555, 0.6729]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915],\n",
      "        [0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046]], device='cuda:0')\n",
      "L1 loss tensor(0.1854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2353, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5195, 0.2498, 0.7358, 0.8027, 0.1569, 0.6699]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.2202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0521, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.9023, 0.4072, 0.6641, 0.4302, 0.1439, 0.5220],\n",
      "        [0.5376, 0.2595, 0.7246, 0.8032, 0.1647, 0.6553]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.1667, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2343, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.6553, 0.3977, 0.9937, 0.6606, 0.2507, 0.9141]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.2214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0551, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6914, 0.4133, 0.9746, 0.6587, 0.2661, 0.8857]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0554, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6572, 0.3936, 0.9897, 0.6646, 0.2443, 0.9092]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.1633, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0553, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6460, 0.3955, 1.0000, 0.6641, 0.2450, 0.9214]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.1094, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0551, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.8706, 0.4836, 0.9395, 0.3354, 0.3032, 0.7856],\n",
      "        [0.6606, 0.4004, 0.9907, 0.6611, 0.2520, 0.9077]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.1661, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2280, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[0.4951, 0.3511, 0.9385, 0.4531, 0.4934, 0.9238]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.1421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0564, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5220, 0.3628, 0.9277, 0.4531, 0.5029, 0.9082]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.1471, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0565, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4917, 0.3452, 0.9429, 0.4526, 0.4893, 0.9277],\n",
      "        [1.0732, 0.4355, 0.7402, 0.6064, 0.0862, 0.6992]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.1491, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1209, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.0572, 0.3313, 0.7051, 0.3567, 0.5664, 0.7373],\n",
      "        [0.7676, 0.4438, 0.6763, 0.5376, 0.1587, 0.6582]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046],\n",
      "        [0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915]], device='cuda:0')\n",
      "L1 loss tensor(0.1730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1202, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0595, 0.3369, 0.7017, 0.3562, 0.5713, 0.7339]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.1565, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0576, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0593, 0.3303, 0.7026, 0.3560, 0.5674, 0.7349]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.1511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0577, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0547, 0.3274, 0.7046, 0.3542, 0.5645, 0.7393]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.1308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0577, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0872, 0.3481, 0.6909, 0.3567, 0.5811, 0.7192]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.1789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0576, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[-0.0317,  0.1832,  0.6401,  0.2600,  0.4390,  0.7153],\n",
      "        [ 0.6636,  0.3513,  0.7412,  0.4832,  0.1249,  0.7251]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1212, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[-0.0601,  0.1749,  0.6548,  0.2610,  0.4314,  0.7344],\n",
      "        [ 0.6396,  0.3362,  0.7529,  0.4893,  0.1199,  0.7520]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.1639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1211, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[-1.7258e-02,  1.9897e-01,  9.0186e-01, -1.5640e-02,  7.5000e-01,\n",
      "          9.7607e-01],\n",
      "        [-7.7454e-02,  1.7603e-01,  6.6016e-01,  2.6392e-01,  4.2896e-01,\n",
      "          7.4658e-01],\n",
      "        [ 6.2402e-01,  3.3057e-01,  7.5684e-01,  4.9390e-01,  1.1969e-01,\n",
      "          7.7002e-01],\n",
      "        [-8.9141e+00,  2.3750e+01, -1.5633e+01, -3.6594e+01,  7.0703e+00,\n",
      "         -6.8594e+00]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647],\n",
      "        [0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569]], device='cuda:0')\n",
      "L1 loss tensor(4.3421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(2.3577, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[-0.0724,  0.1692,  0.6606,  0.2625,  0.4248,  0.7437]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.2312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0576, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[-0.0383,  0.1868,  0.6416,  0.2615,  0.4390,  0.7183],\n",
      "        [ 0.6582,  0.3542,  0.7427,  0.4854,  0.1248,  0.7285]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.1751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1216, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[-0.0559,  0.1390,  0.9839,  0.0768,  0.7744,  1.0625],\n",
      "        [-0.0066,  0.1392,  0.7031,  0.3516,  0.2778,  0.7544],\n",
      "        [ 0.6528,  0.2949,  0.8857,  0.6665,  0.1603,  0.8613]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782]], device='cuda:0')\n",
      "L1 loss tensor(0.1823, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2639, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0510, 0.1494, 0.6807, 0.3435, 0.2957, 0.7183]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.1832, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0628, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0021, 0.1365, 0.6968, 0.3525, 0.2737, 0.7446]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0621, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0095, 0.1521, 0.6929, 0.3530, 0.2847, 0.7402]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.1568, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0616, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0381, 0.1578, 0.6841, 0.3477, 0.2964, 0.7236]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1699, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0622, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[0.3130, 0.2847, 0.9072, 0.5571, 0.1484, 0.9023]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.0439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0653, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2981, 0.2817, 0.9185, 0.5581, 0.1454, 0.9160]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.0554, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0649, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.0967, 0.2173, 1.1504, 0.2598, 0.7949, 1.2256],\n",
      "        [0.3047, 0.2808, 0.9141, 0.5557, 0.1462, 0.9102]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.1839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2050, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6016, 0.3059, 0.8901, 0.8457, 0.0522, 1.0059]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.1452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0670, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6128, 0.3052, 0.8804, 0.8467, 0.0504, 0.9937]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.1723, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0667, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6240, 0.3167, 0.8750, 0.8438, 0.0607, 0.9854]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.1435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0666, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6157, 0.3186, 0.8813, 0.8438, 0.0630, 0.9932]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.2068, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0663, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "pred box tensor([[0.6104, 0.3142, 0.8857, 0.8452, 0.0575, 0.9990]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.1447, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0688, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.6416, 0.1753, 0.6494, 0.9282, 0.2273, 0.8345]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1632, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0640, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2441, 0.1561, 0.9619, 0.5215, 0.9492, 1.2451],\n",
      "        [0.6084, 0.1598, 0.6675, 0.9336, 0.2123, 0.8589]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046],\n",
      "        [0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915]], device='cuda:0')\n",
      "L1 loss tensor(0.1971, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1990, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6357, 0.1798, 0.6533, 0.9321, 0.2280, 0.8398]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.2247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0636, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2439, 0.1560, 0.9600, 0.5195, 0.9502, 1.2451],\n",
      "        [0.6069, 0.1587, 0.6665, 0.9326, 0.2133, 0.8574]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.1897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1986, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2474, 0.1564, 0.9575, 0.5176, 0.9502, 1.2402],\n",
      "        [0.6108, 0.1591, 0.6646, 0.9321, 0.2135, 0.8550]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.2488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1985, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.1976, 0.2720, 0.7554, 0.4856, 1.1133, 1.0312],\n",
      "        [0.5420, 0.2322, 0.4824, 0.9126, 0.4683, 0.6406]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1961, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1930, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5186, 0.2227, 0.4954, 0.9146, 0.4590, 0.6562]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.3092, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0652, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1581, 0.2544, 0.7744, 0.4988, 1.0938, 1.0645],\n",
      "        [0.5063, 0.2163, 0.4988, 0.9155, 0.4541, 0.6650],\n",
      "        [0.9507, 0.3525, 0.8975, 1.3164, 0.6660, 1.0508]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782]], device='cuda:0')\n",
      "L1 loss tensor(0.2791, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(1.3380, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1912, 0.2769, 0.7568, 0.4902, 1.1133, 1.0342],\n",
      "        [0.5371, 0.2360, 0.4849, 0.9141, 0.4678, 0.6431]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.1993, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1935, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[  0.1486,   0.2603,   0.7788,   0.5024,   1.0967,   1.0703],\n",
      "        [  0.4978,   0.2223,   0.5029,   0.9175,   0.4565,   0.6699],\n",
      "        [  0.9424,   0.3550,   0.9009,   1.3193,   0.6699,   1.0596],\n",
      "        [ -1.4746,   0.4778, -15.2188, -36.7500, -13.0547,   6.7422]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647],\n",
      "        [0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569]], device='cuda:0')\n",
      "L1 loss tensor(3.3281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(3.2309, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[0.4331, 0.4038, 0.4607, 0.7334, 0.4941, 0.4253]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.3362, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0593, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4822, 0.4155, 0.4412, 0.7275, 0.5112, 0.3999]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.1876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0603, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4424, 0.4175, 0.4524, 0.7373, 0.4993, 0.4155]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.2400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0590, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.3962, 0.3748, 0.6597, 0.3145, 0.3018, 0.4597]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.1316, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0555, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3672, 0.3523, 0.6729, 0.3127, 0.2849, 0.4739],\n",
      "        [0.7837, 0.5527, 0.9712, 0.9189, 0.5298, 0.8154]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.1175, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1396, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3735, 0.3633, 0.6650, 0.3162, 0.2883, 0.4680]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.1433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0553, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3694, 0.3596, 0.6699, 0.3140, 0.2900, 0.4717]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.1757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0554, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3948, 0.3635, 0.6592, 0.3120, 0.2957, 0.4592],\n",
      "        [0.8076, 0.5693, 0.9619, 0.9131, 0.5381, 0.7905]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1444, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1397, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.2563, 0.2321, 0.9028, 0.0319, 0.1473, 0.6963]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.1679, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0526, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2715, 0.2352, 0.8926, 0.0325, 0.1511, 0.6865]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.1545, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0529, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3091, 0.2408, 0.8804, 0.0263, 0.1639, 0.6714]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.1968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0537, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[-0.0797,  0.5127,  0.7817, -0.3269,  0.6323,  0.7266],\n",
      "        [ 0.2507,  0.2249,  0.9043,  0.0312,  0.1434,  0.6987],\n",
      "        [ 0.6152,  0.4492,  1.0479,  0.7173,  0.3611,  0.9722]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782]], device='cuda:0')\n",
      "L1 loss tensor(0.1900, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2752, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2478, 0.2219, 0.9072, 0.0317, 0.1405, 0.7007]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.1689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0527, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[ 0.2751,  0.1785,  0.9785, -0.0518,  0.1177,  1.0000]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.1433, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0505, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.2739,  0.1781,  0.9814, -0.0509,  0.1170,  1.0020],\n",
      "        [ 0.5405,  0.3862,  1.0020,  0.6309,  0.2551,  1.1426]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046],\n",
      "        [0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915]], device='cuda:0')\n",
      "L1 loss tensor(0.1968, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1541, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ -0.1009,   0.5151,   0.7329,  -0.4351,   0.5093,   0.8374],\n",
      "        [  0.2549,   0.1776,   0.9873,  -0.0508,   0.1140,   1.0098],\n",
      "        [  0.5229,   0.3821,   1.0049,   0.6323,   0.2542,   1.1562],\n",
      "        [ 21.7188, -25.7500,  11.7031, -19.7969, -10.4453,   5.9414]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569],\n",
      "        [0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647]], device='cuda:0')\n",
      "L1 loss tensor(4.1470, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(8.8186, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.2705,  0.1746,  0.9810, -0.0533,  0.1149,  1.0039]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.1637, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0505, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.3081,  0.1971,  0.9624, -0.0520,  0.1335,  0.9849]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.2017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0507, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[0.2065, 0.3276, 0.8110, 0.1057, 0.3091, 1.0391],\n",
      "        [0.4299, 0.4924, 0.7441, 0.7402, 0.3435, 1.0918]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.1139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1584, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2036, 0.3188, 0.8096, 0.1089, 0.2998, 1.0391]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.1756, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0498, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2256, 0.3423, 0.8018, 0.1074, 0.3191, 1.0312],\n",
      "        [0.4453, 0.5103, 0.7383, 0.7388, 0.3538, 1.0762]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.2035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1590, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.2649, 0.4294, 0.4941, 0.4089, 0.5518, 0.8838],\n",
      "        [0.5249, 0.4810, 0.3965, 0.9492, 0.5698, 0.8511]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1775, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1579, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2328, 0.4192, 0.5103, 0.4106, 0.5386, 0.8994]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.1969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0504, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2666, 0.4412, 0.4951, 0.4111, 0.5581, 0.8848]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.1463, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0505, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2389, 0.4185, 0.5073, 0.4087, 0.5410, 0.8960]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.1822, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0506, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2488, 0.4236, 0.5000, 0.4114, 0.5435, 0.8906]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.2158, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0506, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.3389, 0.4070, 0.4304, 0.7026, 0.5479, 0.7261]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.1595, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0515, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2896, 0.4033, 0.4487, 0.7090, 0.5361, 0.7466]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.2424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0505, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.0194,  0.6982,  0.0316, -0.0160,  0.6177,  0.3049],\n",
      "        [ 0.2764,  0.3901,  0.4548,  0.7080,  0.5264,  0.7529],\n",
      "        [ 0.6045,  0.3413,  0.2754,  1.1279,  0.5791,  0.6548]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782]], device='cuda:0')\n",
      "L1 loss tensor(0.2414, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2801, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2859, 0.3958, 0.4524, 0.7080, 0.5322, 0.7476],\n",
      "        [0.6138, 0.3486, 0.2749, 1.1250, 0.5835, 0.6470]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.1876, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1574, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2859, 0.3884, 0.4478, 0.7109, 0.5229, 0.7451]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.1418, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0509, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4392, 0.2260, 0.5991, 0.8491, 0.3267, 0.7510]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0522, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4241, 0.2217, 0.6045, 0.8511, 0.3210, 0.7568],\n",
      "        [0.8057, 0.0889, 0.3503, 1.1436, 0.4231, 0.5913]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.1703, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1556, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3862, 0.2000, 0.6235, 0.8496, 0.3054, 0.7749]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.1218, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0518, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1799, 0.5415, 0.0903, 0.0431, 0.4099, 0.2476],\n",
      "        [0.4038, 0.2084, 0.6143, 0.8491, 0.3113, 0.7656]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.2019, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1710, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4011, 0.2084, 0.6182, 0.8506, 0.3113, 0.7681],\n",
      "        [0.7866, 0.0716, 0.3594, 1.1465, 0.4133, 0.6113]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046],\n",
      "        [0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915]], device='cuda:0')\n",
      "L1 loss tensor(0.1617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1550, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[ 2.0789e-01,  4.7607e-01,  3.4253e-01,  2.4414e-04,  1.2231e-01,\n",
      "          2.8784e-01],\n",
      "        [ 4.3628e-01,  1.5771e-01,  9.8340e-01,  8.0908e-01,  2.0752e-02,\n",
      "          8.7695e-01],\n",
      "        [ 8.0811e-01, -4.9072e-02,  6.5039e-01,  1.0186e+00,  1.8567e-01,\n",
      "          6.4551e-01],\n",
      "        [ 1.4984e+01, -2.4688e+01,  1.2836e+01,  1.5578e+01,  1.0328e+01,\n",
      "         -1.8672e+01]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569],\n",
      "        [0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647]], device='cuda:0')\n",
      "L1 loss tensor(4.1750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(15.0640, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4534, 0.1538, 0.9766, 0.8071, 0.0210, 0.8691]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.2366, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0541, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4614, 0.1685, 0.9697, 0.8120, 0.0260, 0.8633]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.1513, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0538, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[ 0.3132,  0.3113,  1.0996,  0.6567, -0.0468,  0.7998]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1389, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0577, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.2891,  0.2988,  1.1064,  0.6587, -0.0597,  0.8086]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.1229, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0575, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.1232,  0.5176,  0.4355, -0.1154, -0.0026,  0.2394],\n",
      "        [ 0.2666,  0.2883,  1.1172,  0.6567, -0.0663,  0.8203],\n",
      "        [ 0.6870, -0.0339,  0.7622,  0.8101,  0.1091,  0.5972]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298]], device='cuda:0')\n",
      "L1 loss tensor(0.2419, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2553, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.2744,  0.2900,  1.1143,  0.6553, -0.0632,  0.8174]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.2075, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0574, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.3066,  0.3164,  1.1035,  0.6587, -0.0461,  0.8032]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.2866, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0573, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[ 0.1450,  0.3208,  1.0645,  0.3521,  0.0598,  0.8760],\n",
      "        [ 0.5864, -0.0619,  0.7803,  0.5044,  0.1898,  0.6411]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.2199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1423, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1324, 0.3130, 1.0693, 0.3528, 0.0512, 0.8823]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.1628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0600, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1411, 0.3228, 1.0654, 0.3528, 0.0578, 0.8789]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.1555, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0598, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.1487,  0.3215,  1.0615,  0.3518,  0.0594,  0.8735],\n",
      "        [ 0.5898, -0.0609,  0.7783,  0.5029,  0.1896,  0.6382]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.1415, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1423, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1514, 0.3323, 1.0576, 0.3545, 0.0617, 0.8706]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.1509, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0597, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.1924, 0.2893, 0.8618, 0.2415, 0.3701, 0.7944]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.0752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0618, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2427, 0.2910, 0.8481, 0.2343, 0.3811, 0.7783]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.1155, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0629, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1924, 0.2827, 0.8628, 0.2406, 0.3657, 0.7949]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.0819, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0621, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.1887, 0.2744, 0.8604, 0.2437, 0.3572, 0.7930]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.1292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0623, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.2197,  0.2930,  0.8525,  0.2391,  0.3755,  0.7837],\n",
      "        [ 0.6196, -0.0567,  0.7451,  0.3792,  0.4524,  0.6279]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1390, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[  0.2390,   0.3950,   0.2668,  -0.3347,   0.2457,   0.3298],\n",
      "        [  0.3145,   0.1860,   0.6875,   0.3057,   0.4443,   0.8379],\n",
      "        [  0.6787,  -0.0911,   0.7559,   0.4026,   0.5215,   0.7559],\n",
      "        [-11.2656,  -0.3345, -19.3438,   4.9062,  -6.4453,   0.2439]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569],\n",
      "        [0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647],\n",
      "        [0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657]], device='cuda:0')\n",
      "L1 loss tensor(1.9845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(17.7765, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.3354,  0.1870,  0.6836,  0.3054,  0.4468,  0.8320],\n",
      "        [ 0.6978, -0.0880,  0.7559,  0.3994,  0.5239,  0.7451]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046],\n",
      "        [0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915]], device='cuda:0')\n",
      "L1 loss tensor(0.1743, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1369, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.3579,  0.2007,  0.6738,  0.3042,  0.4565,  0.8203],\n",
      "        [ 0.7168, -0.0708,  0.7500,  0.3940,  0.5312,  0.7256]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.1648, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1376, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.5864, 0.2710, 0.4951, 0.4966, 0.4238, 0.7891],\n",
      "        [0.8936, 0.1335, 0.6533, 0.6299, 0.4722, 0.6582]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1289, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.6113, 0.2693, 0.4902, 0.4922, 0.4290, 0.7837]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.1139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0690, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5513, 0.2607, 0.5068, 0.4995, 0.4131, 0.8032]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.1405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0679, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5791, 0.2747, 0.4968, 0.4978, 0.4236, 0.7910],\n",
      "        [0.8887, 0.1367, 0.6543, 0.6323, 0.4714, 0.6606]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.1312, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1292, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5547, 0.2507, 0.5010, 0.5005, 0.4062, 0.7988]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.1692, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0685, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.5649, 0.4849, 0.4946, 0.7700, 0.2512, 0.7129]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0732, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5288, 0.4653, 0.5039, 0.7710, 0.2361, 0.7256],\n",
      "        [0.8071, 0.4612, 0.6733, 0.9609, 0.2590, 0.5703]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605],\n",
      "        [0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947]], device='cuda:0')\n",
      "L1 loss tensor(0.2413, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1216, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5312, 0.4758, 0.5005, 0.7734, 0.2378, 0.7222]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.1873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0725, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5103, 0.4561, 0.5098, 0.7729, 0.2290, 0.7339]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.1770, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0729, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5220, 0.4602, 0.5059, 0.7700, 0.2340, 0.7295]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.2785, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0730, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[0.3384, 0.4629, 0.6831, 0.8013, 0.2524, 0.8647],\n",
      "        [0.6309, 0.6201, 0.8247, 1.0830, 0.1986, 0.6362]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1171, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3389, 0.4631, 0.6831, 0.8022, 0.2512, 0.8652],\n",
      "        [0.6313, 0.6206, 0.8252, 1.0840, 0.1978, 0.6372]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046],\n",
      "        [0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915]], device='cuda:0')\n",
      "L1 loss tensor(0.1519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1171, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3401, 0.4705, 0.6812, 0.8022, 0.2568, 0.8643]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.1726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0746, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 2.6465e-01,  8.1885e-01,  3.6475e-01,  2.0288e-01, -6.2752e-03,\n",
      "          3.6670e-01],\n",
      "        [ 3.1641e-01,  4.6191e-01,  6.8750e-01,  8.0127e-01,  2.4915e-01,\n",
      "          8.7354e-01],\n",
      "        [ 6.1133e-01,  6.1572e-01,  8.2568e-01,  1.0859e+00,  1.9617e-01,\n",
      "          6.5137e-01],\n",
      "        [-1.8906e+00,  3.9406e+01, -1.0578e+01, -2.9016e+01,  9.7500e+00,\n",
      "          3.3094e+01]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647],\n",
      "        [0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569]], device='cuda:0')\n",
      "L1 loss tensor(5.3295, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(15.6793, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3708, 0.4880, 0.6748, 0.8032, 0.2664, 0.8540]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.1649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0745, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[0.2489, 0.7109, 0.5068, 0.1696, 0.0174, 0.5391],\n",
      "        [0.2766, 0.2651, 0.8657, 0.6748, 0.2954, 1.0625],\n",
      "        [0.6006, 0.5347, 0.9131, 1.0391, 0.2268, 0.8408]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782]], device='cuda:0')\n",
      "L1 loss tensor(0.1824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2036, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.3000, 0.2769, 0.8574, 0.6768, 0.3015, 1.0518]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.0933, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0794, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.2900, 0.2720, 0.8633, 0.6743, 0.3010, 1.0557]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.1377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0795, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n",
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.1001, -0.0092,  1.1260,  0.4233,  0.2512,  1.1084]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2281, 0.2236, 0.9058, 0.5764, 0.1084, 0.9589]], device='cuda:0')\n",
      "L1 loss tensor(0.1711, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0844, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.0909, -0.0145,  1.1309,  0.4199,  0.2499,  1.1143]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1301, 0.2241, 0.8883, 0.3297, 0.2114, 0.8963]], device='cuda:0')\n",
      "L1 loss tensor(0.1445, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0844, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4902, 0.3896, 1.0391, 0.8872, 0.2465, 0.9575]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.5182, 0.4623, 0.5875, 0.5325, 0.4611, 0.5903]], device='cuda:0')\n",
      "L1 loss tensor(0.2481, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.4309, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.0756, -0.0241,  1.1367,  0.4199,  0.2423,  1.1211]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4044, 0.2272, 0.8878, 0.5827, 0.2491, 0.8729]], device='cuda:0')\n",
      "L1 loss tensor(0.2078, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0844, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.0867, -0.0230,  1.1289,  0.4226,  0.2405,  1.1123]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.2245, 0.2741, 0.7487, 0.7194, 0.2171, 0.8048]], device='cuda:0')\n",
      "L1 loss tensor(0.2404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0848, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[ 0.0718, -0.0912,  1.2051,  0.2759,  0.1615,  0.9814],\n",
      "        [ 0.4778,  0.3564,  1.0020,  0.7690,  0.2710,  0.9561]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4204, 0.3814, 0.7442, 0.4958, 0.3936, 0.7253],\n",
      "        [0.7810, 0.3339, 0.8079, 0.9365, 0.2692, 0.8660]], device='cuda:0')\n",
      "L1 loss tensor(0.2308, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1038, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.5146, 0.3855, 0.9980, 0.7646, 0.2832, 0.9248]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4027, 0.2897, 0.8449, 0.5696, 0.2832, 0.8504]], device='cuda:0')\n",
      "L1 loss tensor(0.1051, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.4300, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.0729, -0.0911,  1.2061,  0.2759,  0.1595,  0.9824],\n",
      "        [ 0.4780,  0.3562,  1.0020,  0.7700,  0.2708,  0.9580]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3826, 0.1989, 0.8989, 0.6217, 0.1895, 0.9046],\n",
      "        [0.7501, 0.4075, 0.6955, 0.7948, 0.4097, 0.6915]], device='cuda:0')\n",
      "L1 loss tensor(0.2017, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1038, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[0.4822, 0.3696, 0.9971, 0.7695, 0.2708, 0.9458]], device='cuda:0',\n",
      "       dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3680, 0.2880, 0.8495, 0.5285, 0.2962, 0.8426]], device='cuda:0')\n",
      "L1 loss tensor(0.1188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.4289, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.0695, -0.0950,  1.2041,  0.2739,  0.1591,  0.9839]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.0992, 0.2652, 0.8614, 0.2375, 0.2747, 0.8539]], device='cuda:0')\n",
      "L1 loss tensor(0.1691, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0829, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([5, 3, 256])\n",
      "patcher torch.Size([5, 8, 256])\n",
      "patcher + token torch.Size([5, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([5, 11, 256])\n",
      "encoder torch.Size([5, 11, 256])\n",
      "pred box tensor([[ 0.0340,  0.4280,  0.6704, -0.0746,  0.0524,  0.4551],\n",
      "        [ 0.0691, -0.1298,  1.1055,  0.1533,  0.1670,  0.7246],\n",
      "        [ 0.4282,  0.2649,  0.6929,  0.6387,  0.3589,  0.7114]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1683, 0.4644, 0.5880, 0.1853, 0.4603, 0.5979],\n",
      "        [0.2933, 0.4422, 0.6301, 0.3231, 0.4424, 0.6298],\n",
      "        [0.4349, 0.2799, 0.8403, 0.5767, 0.2306, 0.8782]], device='cuda:0')\n",
      "L1 loss tensor(0.1890, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.2051, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.0823, -0.1224,  1.1025,  0.1542,  0.1726,  0.7178],\n",
      "        [ 0.4417,  0.2749,  0.6914,  0.6362,  0.3633,  0.6987]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1490, 0.3818, 0.7947, 0.1808, 0.3270, 0.7947],\n",
      "        [0.4750, 0.2943, 0.8376, 0.5285, 0.3651, 0.7605]], device='cuda:0')\n",
      "L1 loss tensor(0.1256, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1009, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 1.9547e-02,  4.3457e-01,  6.7432e-01, -7.4097e-02,  5.2948e-02,\n",
      "          4.5752e-01],\n",
      "        [ 5.7037e-02, -1.2433e-01,  1.1094e+00,  1.5332e-01,  1.6907e-01,\n",
      "          7.2900e-01],\n",
      "        [ 4.1602e-01,  2.6807e-01,  6.9482e-01,  6.3965e-01,  3.6157e-01,\n",
      "          7.1875e-01],\n",
      "        [ 1.5859e+01,  5.5094e+01,  1.1750e+01, -4.0031e+01,  6.8555e+00,\n",
      "          3.3531e+01]], device='cuda:0', dtype=torch.float16,\n",
      "       grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4439, 0.4301, 0.6548, 0.4709, 0.4383, 0.6383],\n",
      "        [0.2345, 0.4434, 0.6372, 0.2667, 0.4343, 0.6569],\n",
      "        [0.6360, 0.4125, 0.6761, 0.6746, 0.4190, 0.6647],\n",
      "        [0.5016, 0.4353, 0.6492, 0.5340, 0.4272, 0.6657]], device='cuda:0')\n",
      "L1 loss tensor(6.8653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(10.2238, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.0805, -0.1155,  1.1035,  0.1549,  0.1768,  0.7188]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1958, 0.2334, 0.8761, 0.3895, 0.2266, 0.8808]], device='cuda:0')\n",
      "L1 loss tensor(0.1897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0812, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.1057, -0.1088,  1.0967,  0.1559,  0.1816,  0.7080],\n",
      "        [ 0.4658,  0.2932,  0.6880,  0.6338,  0.3706,  0.6792]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.1493, 0.3349, 0.7973, 0.2632, 0.3426, 0.7886],\n",
      "        [0.6557, 0.3235, 0.8131, 0.7732, 0.3373, 0.7983]], device='cuda:0')\n",
      "L1 loss tensor(0.1477, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.1012, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([3, 3, 256])\n",
      "patcher torch.Size([3, 8, 256])\n",
      "patcher + token torch.Size([3, 11, 256])\n",
      "position_embeddings  torch.Size([1, 11, 256])\n",
      "embeddings_block torch.Size([3, 11, 256])\n",
      "encoder torch.Size([3, 11, 256])\n",
      "pred box tensor([[ 0.2424, -0.0259,  0.9248,  0.1556,  0.3015,  0.5762]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4022, 0.2485, 0.8723, 0.5710, 0.2421, 0.8768]], device='cuda:0')\n",
      "L1 loss tensor(0.2104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0843, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.2666, -0.0112,  0.9199,  0.1567,  0.3110,  0.5645],\n",
      "        [ 0.6328,  0.3682,  0.4031,  0.5645,  0.5381,  0.5752]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.3734, 0.4525, 0.6094, 0.3908, 0.4459, 0.6241],\n",
      "        [0.7547, 0.4627, 0.5916, 0.8132, 0.4636, 0.5896]], device='cuda:0')\n",
      "L1 loss tensor(0.1710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0965, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred box tensor([[ 0.2976, -0.0161,  0.9146,  0.1525,  0.3152,  0.5547]],\n",
      "       device='cuda:0', dtype=torch.float16, grad_fn=<IndexBackward0>)\n",
      "gt box tensor([[0.4840, 0.3223, 0.8129, 0.5891, 0.3601, 0.7693]], device='cuda:0')\n",
      "L1 loss tensor(0.2204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "cls_loss tensor(0.0855, device='cuda:0',\n",
      "       grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=51` reached.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from typing import Any\n",
    "import pytorch_lightning as pl\n",
    "from config import *\n",
    "import torchvision.models as models\n",
    "from torchvision.ops import MLP\n",
    "import math\n",
    "from torch import Tensor\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from VerticalCompressionNet import * \n",
    "from CustomTransformer import *\n",
    "\n",
    "def encode_target(box_b , base_u):\n",
    "    box_b[:, 1] = (0.5 -box_b[:, 1])  # v top\n",
    "    box_b[:, 2] = (box_b[:, 2] -0.5) # v btm\n",
    "    box_b[:, 3] = ( torch.abs(box_b[:, 3] - base_u) ) # du\n",
    "\n",
    "    box_b[:, 4] = (0.5 -box_b[:, 4])  # v top\n",
    "    box_b[:, 5] = (box_b[:, 4] -0.5) # v btm\n",
    "    box_b[:, 0] = (base_u - box_b[:, 0])  # u\n",
    "    '''\n",
    "    box_b[:, 1] = torch.exp(torch.abs(0.5 -box_b[:, 1]))  # v top\n",
    "    box_b[:, 2] = torch.exp(torch.abs(box_b[:, 2] -0.5)) # v btm\n",
    "    box_b[:, 3] = torch.exp(torch.abs(box_b[:, 3])) # du\n",
    "\n",
    "    box_b[:, 4] = torch.exp(torch.abs(0.5 -box_b[:, 4]))  # v top\n",
    "    box_b[:, 5] = torch.exp(torch.abs(box_b[:, 4] -0.5)) # v btm\n",
    "    box_b[:, 0] = torch.exp( box_b[:, 0] )  # u\n",
    "    '''\n",
    "\n",
    "    return box_b\n",
    "def decode_target(box_b , base_u):\n",
    "    box_b[:, 0] = base_u -( box_b[:, 0])  # u\n",
    "    box_b[:, 1] = 0.5 - box_b[:, 1]  # v top\n",
    "    box_b[:, 2] = box_b[:, 2] +0.5 # v btm\n",
    "    box_b[:, 3] = base_u + (box_b[:, 3])  # du\n",
    "\n",
    "    box_b[:, 4] = 0.5 -box_b[:, 4]  # v top    \n",
    "    box_b[:, 5] = box_b[:, 4] +0.5 # v btm\n",
    "    '''\n",
    "    box_b[:, 0] = torch.log( box_b[:, 0] )  # u\n",
    "    box_b[:, 1] = 0.5 - torch.log(box_b[:, 1])  # v top\n",
    "    box_b[:, 2] = torch.log(box_b[:, 2]) +0.5 # v btm\n",
    "    box_b[:, 3] = torch.log(box_b[:, 3]) + box_b[:, 0] # du\n",
    "\n",
    "    box_b[:, 4] = 0.5 - torch.log(box_b[:, 4])  # v top    \n",
    "    box_b[:, 5] = torch.log(box_b[:, 4]) +0.5 # v btm\n",
    "    '''\n",
    "    return box_b\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: 256, dropout: float = 0.1, max_len: int = 1024):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, embed_dim, patch_size, num_patches, dropout, in_channels):\n",
    "        super().__init__()\n",
    "        self.patcher = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=embed_dim,\n",
    "                kernel_size=patch_size,\n",
    "                stride=patch_size,\n",
    "            ),                  \n",
    "            nn.Flatten(2))\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(size=(1, in_channels, embed_dim)), requires_grad=True)\n",
    "        self.position_embeddings = nn.Parameter(torch.randn(size=(1, num_patches+1, embed_dim)), requires_grad=True)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cls_token = self.cls_token.expand(x.shape[0], -1, -1)\n",
    "        print(\"cls_token\" ,cls_token.shape)  # [batch , channel , hidden]  , example [5, 3, 256]\n",
    "        x = self.patcher(x).permute(0, 2, 1)\n",
    "        print(\"patcher\" ,x.shape)  # [batch , patches , hidden]  , example [5, 11, 256]\n",
    "        x = torch.cat([cls_token, x], dim=1)\n",
    "        print(\"patcher + token\" ,x.shape)  # [batch , patches +1 , hidden]  , example [5, 32771, 256]\n",
    "        print(\"position_embeddings \" ,self.position_embeddings.shape)  # [batch , patches +1 , hidden]  , example [5, 32771, 256]\n",
    "        x = self.position_embeddings + x \n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, num_patches, img_size, num_classes, patch_size, embed_dim, num_encoders, num_heads, hidden_dim, dropout, activation, in_channels):\n",
    "        super().__init__()\n",
    "        self.embeddings_block = PatchEmbedding(embed_dim, patch_size, num_patches, dropout, in_channels)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dropout=dropout, activation=activation, batch_first=True, norm_first=True)\n",
    "        self.encoder_blocks = nn.TransformerEncoder(encoder_layer, num_layers=num_encoders)\n",
    "\n",
    "        self.mlp_head = nn.Sequential(\n",
    "            nn.LayerNorm(normalized_shape=embed_dim),\n",
    "            nn.Linear(in_features=embed_dim, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embeddings_block(x)            # [batch , patches , hidden] \n",
    "        print(\"embeddings_block\" , x.shape)\n",
    "        x = self.encoder_blocks(x)              # [batch , patches , hidden] \n",
    "        print(\"encoder\" , x.shape)\n",
    "        #x = self.mlp_head(x[:, 0, :])  # Apply MLP on the CLS token only         # [batch , classes_number] \n",
    "        return x\n",
    "\n",
    "#model = ViT(NUM_PATCHES, IMG_SIZE, NUM_CLASSES, PATCH_SIZE, EMBED_DIM, NUM_ENCODERS, NUM_HEADS, HIDDEN_DIM, DROPOUT, ACTIVATION, IN_CHANNELS).to(device)\n",
    "#x = torch.randn(512, 1, 28, 28).to(device)\n",
    "#print(model(x).shape) # BATCH_SIZE X NUM_CLASSES\n",
    "    \n",
    "\n",
    "class VerticalQueryTransformer(pl.LightningModule):    \n",
    "    def __init__(self  ,  max_predict_count = 24 ,\n",
    "                    hidden_out = 128 , class_num = 1 ,\n",
    "                    log_folder = \"__test\" , num_classes = 1 , backbone_trainable =False, load_weight =\"\"  , dropout = 0.001 , normalize_before=False\n",
    "                    ):\n",
    "        #print(\" input_size\" ,  input_size)\n",
    "        super().__init__()\n",
    "        self.confidence_threshold = 0.75\n",
    "        self.log_folder = create_folder(os.path.join(os.getcwd() , \"output\" , log_folder))\n",
    "        self.automatic_optimization = False\n",
    "        self.hidden_size = hidden_out\n",
    "        self.max_predict_count = max_predict_count\n",
    "        self.num_classes  = num_classes \n",
    "\n",
    "        self.input_width = 1024\n",
    "        self.input_height = 512\n",
    "        '''\n",
    "        self.pixel_value_proj = nn.Linear( 3*self.input_height , self.hidden_size )\n",
    "\n",
    "        self.pe = PositionalEncoding(self.hidden_size ,dropout , max_len=  self.input_width)\n",
    "        \n",
    "        encoder_norm = nn.LayerNorm(1024) if normalize_before else None\n",
    "        encoder_layer = TransformerEncoderLayer(self.hidden_size, 8, 2048,\n",
    "                                                dropout, 'relu', normalize_before)\n",
    "        self.encoder = TransformerEncoder(encoder_layer, 8, encoder_norm )\n",
    "        \n",
    "        #decoder_layer = nn.TransformerDecoderLayer(d_model=self.hidden_size, nhead=8  )\n",
    "        #self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "\n",
    "        self.cls_head = nn.Linear(self.hidden_size, 1 )\n",
    "        self.u_head = nn.Linear(self.hidden_size, 2 )\n",
    "        self.v_head = nn.Linear(self.hidden_size, 4 )\n",
    "\n",
    "        self.u_head.bias.data.fill_(self.max_predict_count /100*0.5)\n",
    "        self.v_head.bias.data.fill_(0.15)\n",
    "\n",
    "        #self.backbone = Resnet()\n",
    "\n",
    "        #self.pos_emb = nn.Embedding(self.max_predict_count , self.hidden_size)\n",
    "        #nn.init.constant_(self.pos_emb.weight , 0)\n",
    "        #self.pixel_query = nn.Linear(self.input_width , self.hidden_size , kernel_size=3 , padding=1)\n",
    "        self.pixel_query = nn.Linear(self.hidden_size , self.hidden_size )\n",
    "        '''\n",
    "        self.vit= ViT(10, IMG_SIZE, 2, 256, hidden_out, 6, 16, 256, dropout, 'relu', 3)\n",
    "\n",
    "        self.cls_head = nn.Linear(self.hidden_size, 1 )\n",
    "        self.u_head = nn.Linear(self.hidden_size, 2 )\n",
    "        self.v_head = nn.Linear(self.hidden_size, 4 )\n",
    "\n",
    "        self.u_head.bias.data.fill_(self.max_predict_count /100*0.5)\n",
    "        self.v_head.bias.data.fill_(0.15)\n",
    "    def forward(self ,x ):\n",
    "        '''\n",
    "        x = x.permute(0,3,1,2)  # [ batch , width , channel , height]\n",
    "        x = x.view(x.shape[0] , x.shape[1] , -1)  # [ batch , width , channel * height]\n",
    "        \n",
    "        pixel_feat = self.pixel_value_proj(x)  # [ batch , width , hidden ]\n",
    "        print(\"x\" , x.shape)\n",
    "        '''\n",
    "        feat = self.vit(x)\n",
    "\n",
    "        box_u_logits = self.u_head(feat)\n",
    "        box_v_logits = self.v_head(feat)\n",
    "        cls_logits = self.cls_head(feat)\n",
    "\n",
    "        if(self.global_step %10==0):\n",
    "            plt.imshow(feat[0].detach().cpu().numpy())\n",
    "            plt.title(\"feat\")\n",
    "            plt.show()\n",
    "        \n",
    "      \n",
    "        box_logits = torch.cat([ box_u_logits[:,:,0].unsqueeze(2) ,\n",
    "                                 box_v_logits[:,:,0].unsqueeze(2) ,\n",
    "                                 box_v_logits[:,:,1].unsqueeze(2) , \n",
    "                                 box_u_logits[:,:,1].unsqueeze(2) ,\n",
    "                                 box_v_logits[:,:,2].unsqueeze(2) ,\n",
    "                                 box_v_logits[:,:,3].unsqueeze(2)] , dim=-1 )\n",
    "        \n",
    "        return box_logits ,cls_logits            \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def inf(self , imgs ):\n",
    "        \n",
    "        out_box , out_cls   = self.forward(imgs)  # [ batch , top_k , 5]   , [ batch , top_k , 1]         \n",
    "        #print(\"val \" , out_cls)\n",
    "        #print(\"val sigmoid\" , torch.sigmoid(out_cls))\n",
    "        \n",
    "        batch_size = out_box.shape[0]\n",
    "        #sampled_u_idx = torch.argwhere( torch.sigmoid(out_cls.view(batch_size , -1)) > 0.01 )\n",
    "        #print(\"sampled_u_idx\" , sampled_u_idx)\n",
    "\n",
    "        sampled_box_b = []\n",
    "        #each batch\n",
    "        for img , pred , pcls in zip(imgs, out_box , out_cls.view(batch_size,-1)):  \n",
    "            u_id = torch.argwhere(torch.sigmoid(pcls) > self.confidence_threshold)\n",
    "            print(\"u_id\"  , u_id)\n",
    "            if(u_id.numel() ==0):\n",
    "                continue\n",
    "            u_id = u_id.view(-1)            \n",
    "            \n",
    "            #pred = self.post_process(pbox[u_id,:] , u_id ).view(-1,6)\n",
    "            pred = pred[u_id]\n",
    "            \n",
    "            save_folder = create_folder( os.path.join(self.log_folder ,\"val\"))\n",
    "            save_path = os.path.join(save_folder, f\"val_ep_{self.current_epoch}-{self.global_step}\" )\n",
    "\n",
    "            decode_pred = decode_target(pred.clone())\n",
    "            #pred_us , pred_tops , pred_btms = self.pack_visualize(pred[:,0], pred[:,1],pred[:,2],pred[:,3] -pred[:,0] ,pred[:,4],pred[:,5] )                    \n",
    "            pred_us , pred_tops , pred_btms = self.pack_visualize(decode_pred[:,0], decode_pred[:,1],decode_pred[:,2],decode_pred[:,3] ,decode_pred[:,4],decode_pred[:,5] )                    \n",
    "            vis_imgs = visualize_2d_single(pred_us , pred_tops , pred_btms , u_grad = F.sigmoid(pcls).view(1 , -1 ) , imgs=  img , title=\"Pred\" , save_path= save_path  )\n",
    "            #plt.imshow(vis_imgs)\n",
    "            #plt.show()\n",
    "\n",
    "            # ToDo: calculate loss          \n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def pack_visualize(self, gt_u_b , gt_vtop_b , gt_vbtm_b , gt_du_b , gt_dvtop_b , dv_btm_b ):\n",
    "        \n",
    "        if isinstance(gt_u_b, torch.Tensor):\n",
    "            sizes = [t.numel() for t in gt_u_b]               \n",
    "            us = gt_u_b.flatten().unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            us[1::2]+=gt_du_b.flatten()\n",
    "            us = torch.split(us.view(-1,2) , sizes)\n",
    "\n",
    "            tops = gt_vtop_b.flatten().unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            tops[1::2]=gt_dvtop_b.flatten()\n",
    "            tops = torch.split(tops.view(-1,2) , sizes)\n",
    "\n",
    "            btms = gt_vbtm_b.flatten().unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            btms[1::2]=dv_btm_b.flatten()\n",
    "            btms = torch.split(btms.view(-1,2) , sizes)\n",
    "\n",
    "        elif isinstance(gt_u_b, tuple) and all(isinstance(t, torch.Tensor) for t in gt_u_b):        \n",
    "            sizes = [len(t) for t in gt_u_b]               \n",
    "            us = torch.cat(gt_u_b).view(-1).unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            us[1::2]+=torch.cat(gt_du_b).view(-1)\n",
    "            us = torch.split(us.view(-1,2) , sizes)\n",
    "\n",
    "            tops = torch.cat(gt_vtop_b).view(-1).unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            tops[1::2]=torch.cat(gt_dvtop_b).view(-1)\n",
    "            tops = torch.split(tops.view(-1,2) , sizes)\n",
    "\n",
    "            btms = torch.cat(gt_vbtm_b).view(-1).unsqueeze(0).repeat(2, 1).permute(1,0).reshape(-1)\n",
    "            btms[1::2]=torch.cat(dv_btm_b).view(-1)\n",
    "            btms = torch.split(btms.view(-1,2) , sizes)\n",
    "        else:\n",
    "            assert(\"Wrong Type.\")\n",
    "        \n",
    "        return us , tops ,btms\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def training_step(self , input_b ,batch_idx ):\n",
    "        \n",
    "        img = input_b['image']        \n",
    "        out_box , out_cls   = self.forward(img)  # [ batch , top_k , 5]   , [ batch , top_k , 1] \n",
    "        #print(\"max out_cls\" , torch.max(out_cls) , \"min \" , torch.min(out_cls))\n",
    "        batch_size = out_box.shape[0]\n",
    "        \n",
    "        '''\n",
    "        if self.current_epoch % 5 == 0 :#and self.current_epoch > 0 :       \n",
    "            plt.imshow(out_cls[0].repeat(1,100).detach().cpu().numpy())\n",
    "            plt.title(\"encoder cls output\")\n",
    "            plt.show()      \n",
    "        '''\n",
    "\n",
    "        # remove padding , each batch have different length\n",
    "        gt_u_b = unpad_data( input_b['u'])          \n",
    "        gt_vtop_b =unpad_data(input_b['v_top'])\n",
    "        gt_vbtm_b = unpad_data (input_b['v_btm'])\n",
    "        gt_du_b = unpad_data(input_b['du'])\n",
    "        gt_dvtop_b = unpad_data(input_b['dv_top'])\n",
    "        gt_dv_btm_b = unpad_data(input_b['dv_btm'])\n",
    "        \n",
    "        total_loss = 0\n",
    "        b_cnt = 0        \n",
    "        \n",
    "        for u,vtop,vbtm,du,dvtop, dvbtm , pred ,cls_b  in zip(gt_u_b , gt_vtop_b , gt_vbtm_b , gt_du_b , gt_dvtop_b , gt_dv_btm_b , out_box , out_cls  ):\n",
    "            \n",
    "            # match                        \n",
    "            gt_box =  torch.vstack([ u, vtop,vbtm, u + du ,dvtop , dvbtm]).permute(1,0)   # [n , 6]\n",
    "            \n",
    "                        \n",
    "            #u_cost = torch.cdist( (torch.arange(self.max_predict_count,device=u.device).unsqueeze(-1) /self.max_predict_count ) , u.unsqueeze(-1) )            \n",
    "            \n",
    "            box_loss = torch.cdist( pred , gt_box , p=1)\n",
    "            cls_cost = -torch.sigmoid(cls_b)\n",
    "            \n",
    "            cost_matrix = box_loss  + cls_cost \n",
    "            #cost_matrix =  u_cost * 2            \n",
    "            #cost_matrix = u_cost\n",
    "            \n",
    "            \n",
    "            cost_matrix = cost_matrix.detach().cpu().numpy()            \n",
    "            row_idx  , col_idx = linear_sum_assignment(cost_matrix)    \n",
    "            \n",
    "            #matched_u = torch.tensor( np.float32(row_idx)/self.max_predict_count,device=u.device)\n",
    "            \n",
    "            gt_cls = torch.zeros(self.max_predict_count,device= cls_b.device )            \n",
    "            gt_cls[row_idx] = 1            \n",
    "            \n",
    "            #gt_l1_target = encode_target(gt_box.clone() , matched_u)           \n",
    "            gt_cls = torch.zeros_like(cls_b,device= cls_b.device)\n",
    "            gt_cls[row_idx ] = 1\n",
    "\n",
    "            #decode_pred = decode_target(pred.clone()[row_idx].view(-1,6) , matched_u)\n",
    "            decode_pred = pred[row_idx]\n",
    "            #l1_loss = F.l1_loss(decode_pred ,  gt_l1_target[col_idx]) \n",
    "            l1_loss = F.l1_loss(decode_pred ,  gt_box) \n",
    "            cls_loss = F.binary_cross_entropy_with_logits(cls_b.view(-1), gt_cls.view(-1)) \n",
    "            #cls_loss = F.binary_cross_entropy_with_logits(cls_b.view(-1)[cls_sample_idx], gt_cls.view(-1)[cls_sample_idx]) \n",
    "            #print(\"cls_b\" , cls_b.view(-1))\n",
    "            #print(\"gt_cls\" , gt_cls.view(-1))\n",
    "            print(\"pred box\" , decode_pred)\n",
    "            print(\"gt box\" , gt_box[col_idx])\n",
    "\n",
    "            print(\"L1 loss\"  , l1_loss)\n",
    "            print(\"cls_loss\"  , cls_loss)\n",
    "            \n",
    "            total_loss += l1_loss + cls_loss\n",
    "            #total_loss += cls_loss\n",
    "                        \n",
    "            with torch.no_grad():\n",
    "                #if self.current_epoch % 5 == 0  :                \n",
    "                #if self.current_epoch % 5 == 0 and self.current_epoch > 0 and batch_idx<2 :                \n",
    "                if self.current_epoch > 0 and batch_idx <5 :                \n",
    "                    save_path =  os.path.join(self.log_folder , f\"gt_ep_{self.current_epoch}-{self.global_step}-{batch_idx}\" )\n",
    "                    gt_us , gt_tops , gt_btms = self.pack_visualize(u.view(1 , -1 ) , vtop , vbtm , du , dvtop , dvbtm )\n",
    "                    #print(\"gt_us , gt_tops , gt_btms\" , gt_us , gt_tops , gt_btms)\n",
    "                    vis_imgs = visualize_2d_single(gt_us , gt_tops , gt_btms , u_grad =  gt_cls.view(1 , -1 ), imgs= img[b_cnt] , title=\"GT\",save_path=save_path )                \n",
    "                    \n",
    "                    save_path =  os.path.join(self.log_folder , f\"pred_ep_{self.current_epoch}-{self.global_step}-{batch_idx}\" )\n",
    "                    #decode_pred = decode_target(pred.clone()[row_idx].view(-1,6) , matched_u)\n",
    "                    #pred_us , pred_tops , pred_btms = self.pack_visualize(pred[row_idx,0], pred[row_idx,1],pred[row_idx,2],pred[row_idx,3] ,pred[row_idx,4],pred[row_idx,5] )                    \n",
    "                    pred_us , pred_tops , pred_btms = self.pack_visualize(decode_pred[:,0], decode_pred[:,1],decode_pred[:,2],\n",
    "                                                                          decode_pred[:,3]-decode_pred[:,0] ,\n",
    "                                                                          decode_pred[:,4],decode_pred[:,5] )                    \n",
    "                    vis_imgs = visualize_2d_single(pred_us , pred_tops , pred_btms , u_grad = F.sigmoid(cls_b).view(1 , -1 ) , imgs=  img[b_cnt] ,\n",
    "                                                    title=f\"Pred_row{row_idx}-\\n u:{pred_us}\" , save_path= save_path  )\n",
    "                    \n",
    "           \n",
    "           \n",
    "            b_cnt+=1\n",
    "            pass        \n",
    "\n",
    "        op1  = self.optimizers()\n",
    "        op1.zero_grad()        \n",
    "        self.manual_backward(total_loss / batch_size)\n",
    "        op1.step()\n",
    "\n",
    "        return total_loss / batch_size\n",
    "        pass    \n",
    "\n",
    "    def __validation_step(self, input_b, batch_idx):\n",
    "        print(\"val!!!!!\")\n",
    "        img = input_b['image']\n",
    "        \n",
    "        #out_box , out_cls   = self.forward(img)  # [ batch , top_k , 5]   , [ batch , top_k , 1]         \n",
    "        if(batch_idx %2==0 and self.current_epoch>0 ):\n",
    "            self.inf(img)\n",
    "        return\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        '''\n",
    "        backbone_opt = optim.Adam(self.backbone.parameters() , lr=0.00035)\n",
    "        comp_opt = optim.Adam(self.reduce_height_module.parameters() , lr=0.00035)\n",
    "        transforms_opt = optim.Adam(self.transformer.parameters() , lr=0.00035)\n",
    "        '''\n",
    "        opt = optim.Adam(self.parameters() , lr=0.00035)\n",
    "\n",
    "        return [opt] , []\n",
    "\n",
    "\n",
    "    pass\n",
    "\n",
    "# Unit testing...\n",
    "save_path = create_folder( os.path.join(os.getcwd() , \"output\" , \"checkpoints\"))\n",
    "save_file = os.path.join(save_path , \"detr_v1_d20_e50.pth\")\n",
    "\n",
    "# Test\n",
    "dm = CustomDataModule ( train_dir= f\"../anno/train_visiable_20_no_cross.json\" ,\n",
    "                        test_dir= f\"../anno/test_visiable_10_no_cross.json\" , padding_count=20 , use_aug=False , c= 0.95,batch_size=5\n",
    "                       )\n",
    "#m = VerticalQueryTransformer(max_predict_count = 20 , hidden_out=256 , load_weight=\"D:/OneDrive/OneDrive - NTHU/Layout/Horizon/0912_all_bk.pth\"  , backbone_trainable=True)\n",
    "m = VerticalQueryTransformer(max_predict_count = 100 , hidden_out=256  , backbone_trainable=True ,dropout=0)\n",
    "\n",
    "'''\n",
    "save_path = create_folder( os.path.join(os.getcwd() , \"output\" , \"checkpoints\"))\n",
    "save_file = os.path.join(save_path , \"detr_v1_d20_e50.pth\")\n",
    "m = torch.load(save_file)\n",
    "    \n",
    "        \n",
    "\n",
    "#print(o)\n",
    "'''\n",
    "trainer = pl.Trainer(accelerator='gpu' , devices=1 ,\n",
    "                     min_epochs=1, max_epochs=51 , precision=16 , fast_dev_run=False )\n",
    "trainer.fit(m , dm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 11, 256])\n",
      "Parameter containing:\n",
      "tensor([[[-1.0832,  0.7621, -0.5626,  ...,  0.3670,  0.6487,  0.3955],\n",
      "         [ 0.8461,  0.4983, -0.7445,  ...,  0.9953, -1.7925, -1.1348],\n",
      "         [-0.2226,  0.3130, -1.2659,  ..., -0.4433, -0.2110, -0.1009],\n",
      "         ...,\n",
      "         [-0.4160, -0.1730, -0.2618,  ..., -1.1232,  0.2023,  0.9864],\n",
      "         [-0.0963, -1.1124, -0.8947,  ...,  0.2545, -1.7994, -0.3637],\n",
      "         [-0.3984, -2.0231,  1.5254,  ..., -0.6741, -0.8480,  0.0689]]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(m.vit.embeddings_block.position_embeddings.shape)\n",
    "print(m.vit.embeddings_block.position_embeddings)\n",
    "plt.imshow(m.vit.embeddings_block.position_embeddings[0].detach().cpu().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(1,5,8)\n",
    "self_attn = nn.MultiheadAttention(8, 8, dropout=0.1)\n",
    "atten , src = self_attn(a  , a, a)\n",
    "\n",
    "print(atten.shape) \t# ([20, 5, 256])\n",
    "print(src.shape) \t# ([5, 20, 20])\n",
    "plt.imshow(src[0].detach().cpu().numpy())\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(atten.permute(1,0,2)[0].detach().cpu().numpy())\n",
    "plt.show()\n",
    "\n",
    "print(atten)\n",
    "print(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = create_folder( os.path.join(os.getcwd() , \"output\" , \"checkpoints\"))\n",
    "save_file = os.path.join(save_path , \"detr_v1_d20_e50.pth\")\n",
    "torch.save(m , save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = torch.rand(1,5,8)\n",
    "a = torch.arange(80.0).view(2,5,8)\n",
    "n = nn.Linear(8,2)\n",
    "n.bias.data.fill_(1)\n",
    "n.weight.data.fill_(1)\n",
    "\n",
    "print(n.weight.shape)\n",
    "print(n.bias)\n",
    "b =n(a)\n",
    "print(a)\n",
    "print(b.shape)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.rand(20,2)\n",
    "b = torch.rand(20)*2\n",
    "b = b.to(torch.long).view(-1,1)\n",
    "#c = a[b]\n",
    "c= torch.gather(a,1,b)\n",
    "print(c.shape)\n",
    "print(a)\n",
    "print(b)\n",
    "print()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "transformer_decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "memory = torch.rand(10, 32, 512)\n",
    "tgt = torch.rand(20, 32, 512)\n",
    "out = transformer_decoder(tgt, memory)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "horizon_path =r\"D:/OneDrive/OneDrive - NTHU/Layout/Horizon/0912_all_bk.pth\"\n",
    "#models_dict = torch.load_s\n",
    "checkpoint = torch.load(horizon_path ,  map_location=\"cpu\")\n",
    "print(checkpoint['state_dict'].keys())\n",
    "#model.load_state_dict(checkpoint['model_state_dict'])\n",
    "pretrained_dict = {k: v for k, v in checkpoint['state_dict'].items() if k in m.state_dict()}\n",
    "m.load_state_dict(pretrained_dict , strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.rand(2,256 ,1024)\n",
    "b = nn.Conv1d(256 , 64 , kernel_size=3 ,padding=1)\n",
    "c = b(a)\n",
    "print(c.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,5,2)\n",
    "print(a)\n",
    "b=  nn.MaxPool2d((5,1))\n",
    "c = b(a)\n",
    "print(c.shape)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(200).view(2,100,1)\n",
    "#aa = a[:,:,0].unsqueeze(0)\n",
    "#print(aa.shape)\n",
    "b = F.interpolate(a.view(2,-1).unsqueeze(0), 10 )[0]\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(2,10,1)\n",
    "b = torch.cat([a,a] , dim=1)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = torch.rand(2,100,1)\n",
    "a = torch.arange(400).view(2,100,2)\n",
    "b = torch.arange(20).view(2,10)\n",
    "\n",
    "print(a)\n",
    "print(b)\n",
    "b= b.unsqueeze(-1).repeat(1,1,2)\n",
    "print(b)\n",
    "#print(\"b unsqueeze\",b.unsqueeze(-1))\n",
    "\n",
    "c = a.gather(1, b)\n",
    "print(c.shape)\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.arange(5)\n",
    "b=torch.arange(5)\n",
    "c=torch.arange(5)\n",
    "\n",
    "d = torch.vstack([a,b,c]).permute(1,0)\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment\n",
    "a = torch.tensor([ [0,1,2]  ,  [0,3,5] , [1,0,5] ]).to(torch.float32)\n",
    "b = torch.tensor([ [0,1,2] , [1,0,5] ]).to(torch.float32)\n",
    "\n",
    "cost = torch.cdist(b,a)\n",
    "print(cost)\n",
    "row , col = linear_sum_assignment(cost,)\n",
    "print(row)\n",
    "print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[0.7605, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.7730, 0.5752, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.7057, 0.5861, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.8386, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.8304, 0.7823, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.7034, 0.5994, 0.5691, 0.5652, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.6996, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.8305, 0.7819, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
    "        [0.8238, 0.7839, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
    "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]])\n",
    "# Get the indices of non-zero elements\n",
    "non_zero_indices = torch.nonzero(x)\n",
    "print(non_zero_indices)\n",
    "# Get the non-zero values\n",
    "non_zero_values = x[non_zero_indices[:,0], non_zero_indices[:,1]]\n",
    "\n",
    "unique = torch.unique(non_zero_indices[:,0] ,return_counts=True)\n",
    "print(\"unique\" , unique)\n",
    "# Print the result\n",
    "print(non_zero_values)\n",
    "non_zero_values = torch.split(non_zero_values , tuple(unique[1]))\n",
    "print(\"split non_zero_values\" , non_zero_values)\n",
    "\n",
    "def unpad_data( x :[Tensor] ) :\n",
    "\tnon_zero_indices = torch.nonzero(x)\n",
    "\tprint(non_zero_indices)\n",
    "\t# Get the non-zero values\n",
    "\tnon_zero_values = x[non_zero_indices[:,0], non_zero_indices[:,1]]\n",
    "\n",
    "\tunique = torch.unique(non_zero_indices[:,0] ,return_counts=True)\n",
    "\tprint(\"unique\" , unique)\n",
    "\t# Print the result\n",
    "\tprint(non_zero_values)\n",
    "\tnon_zero_values = torch.split(non_zero_values , tuple(unique[1]))\n",
    "\tprint(\"split non_zero_values\" , non_zero_values)\n",
    "\treturn non_zero_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[0.58 , 0.6] , [0.4] ] , )\n",
    "b = torch.tensor([0.1 , 0.2] , )\n",
    "\n",
    "c = a.repeat(2)\n",
    "print(a.repeat(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model = nn.Transformer(nhead=16, num_encoder_layers=12)\n",
    "src = torch.rand((10, 32, 512))\n",
    "tgt = torch.rand((20, 32, 512))\n",
    "out = transformer_model(src, tgt)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.rand(1)[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Layout",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
