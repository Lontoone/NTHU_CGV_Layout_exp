[01/07 23:12:09] detectron2 INFO: Rank of current process: 0. World size: 1
[01/07 23:12:10] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.7.7 (default, Mar 23 2020, 23:19:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.21.6
detectron2              0.6 @e:\projects\layout\detrex\detectron2\detectron2
Compiler                MSVC 193632537
CUDA compiler           CUDA 11.7
detectron2 arch flags   e:\projects\layout\detrex\detectron2\detectron2\_C.cp37-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          537.13
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7
Pillow                  9.3.0
torchvision             0.14.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision
torchvision arch flags  C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[01/07 23:12:10] detectron2 INFO: Command line arguments: Namespace(config_file='projects/deformable_detr/configs/deformable_detr_r50_50ep.py', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/07 23:12:10] detectron2 INFO: Contents of args.config_file=projects/deformable_detr/configs/deformable_detr_r50_50ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdeformable_detr_r50[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;15mdataloader[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/coco_detr.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mdataloader[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mlr_multiplier_50ep[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mAdamW[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mtrain[39m

[38;5;242m# modify training config[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/deformable_detr_r50_50ep[39m[38;5;186m"[39m

[38;5;242m# max training iterations[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m375000[39m

[38;5;242m# run evaluation every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# log training infomation every 20 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20[39m

[38;5;242m# save checkpoint every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;242m# set training devices[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m

[38;5;242m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;242m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;242m# please notice that this is total batch size.[39m
[38;5;242m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;242m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;242m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m

[01/07 23:12:10] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/deformable_detr_r50_50ep\config.yaml is human-readable but cannot be loaded.
[01/07 23:12:10] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/deformable_detr_r50_50ep\config.yaml.pkl.
[01/07 23:12:10] detectron2 INFO: Full config saved to ./output/deformable_detr_r50_50ep\config.yaml
[01/07 23:12:10] d2.utils.env INFO: Using a generated random seed 10434245
[01/07 23:12:10] detectron2 INFO: Model:
DeformableDETR(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (position_embedding): PositionEmbeddingSine()
  (neck): ChannelMapper(
    (convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): ConvNormAct(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (2): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (extra_convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
  )
  (query_embedding): Embedding(300, 512)
  (transformer): DeformableDetrTransformer(
    (encoder): DeformableDetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (decoder): DeformableDetrTransformerDecoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
  )
  (bbox_embed): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (3): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (4): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (5): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): Criterion DeformableCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_bbox: 5.0
          cost_giou: 2.0
          cost_class_type: focal_loss_cost
          focal cost alpha: 0.25
          focal cost gamma: 2.0
      losses: ['class', 'boxes']
      loss_class_type: focal_loss
      weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0}
      num_classes: 80
      eos_coef: 0.1
      focal loss alpha: 0.25
      focal loss gamma: 2.0
)
[01/07 23:19:07] detectron2 INFO: Rank of current process: 0. World size: 1
[01/07 23:19:07] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.7.7 (default, Mar 23 2020, 23:19:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.21.6
detectron2              0.6 @e:\projects\layout\detrex\detectron2\detectron2
Compiler                MSVC 193632537
CUDA compiler           CUDA 11.7
detectron2 arch flags   e:\projects\layout\detrex\detectron2\detectron2\_C.cp37-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          537.13
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7
Pillow                  9.3.0
torchvision             0.14.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision
torchvision arch flags  C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[01/07 23:19:07] detectron2 INFO: Command line arguments: Namespace(config_file='projects/deformable_detr/configs/deformable_detr_r50_50ep.py', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/07 23:19:07] detectron2 INFO: Contents of args.config_file=projects/deformable_detr/configs/deformable_detr_r50_50ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdeformable_detr_r50[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;242m#dataloader = get_config("common/data/coco_detr.py").dataloader[39m
[38;5;15mdataloader[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/custom_zillow.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mdataloader[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mlr_multiplier_50ep[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mAdamW[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mtrain[39m

[38;5;242m# modify training config[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/deformable_detr_r50_50ep[39m[38;5;186m"[39m

[38;5;242m# max training iterations[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m375000[39m

[38;5;242m# run evaluation every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# log training infomation every 20 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20[39m

[38;5;242m# save checkpoint every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;242m# set training devices[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m

[38;5;242m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;242m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;242m# please notice that this is total batch size.[39m
[38;5;242m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;242m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;242m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m

[01/07 23:19:07] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/deformable_detr_r50_50ep\config.yaml is human-readable but cannot be loaded.
[01/07 23:19:07] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/deformable_detr_r50_50ep\config.yaml.pkl.
[01/07 23:19:07] detectron2 INFO: Full config saved to ./output/deformable_detr_r50_50ep\config.yaml
[01/07 23:19:07] d2.utils.env INFO: Using a generated random seed 7795247
[01/07 23:19:08] detectron2 INFO: Model:
DeformableDETR(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (position_embedding): PositionEmbeddingSine()
  (neck): ChannelMapper(
    (convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): ConvNormAct(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (2): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (extra_convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
  )
  (query_embedding): Embedding(300, 512)
  (transformer): DeformableDetrTransformer(
    (encoder): DeformableDetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (decoder): DeformableDetrTransformerDecoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
  )
  (bbox_embed): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (3): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (4): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (5): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): Criterion DeformableCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_bbox: 5.0
          cost_giou: 2.0
          cost_class_type: focal_loss_cost
          focal cost alpha: 0.25
          focal cost gamma: 2.0
      losses: ['class', 'boxes']
      loss_class_type: focal_loss
      weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0}
      num_classes: 80
      eos_coef: 0.1
      focal loss alpha: 0.25
      focal loss gamma: 2.0
)
[01/08 04:21:03] detectron2 INFO: Rank of current process: 0. World size: 1
[01/08 04:21:04] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.7.7 (default, Mar 23 2020, 23:19:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.21.6
detectron2              0.6 @e:\projects\layout\detrex\detectron2\detectron2
Compiler                MSVC 193632537
CUDA compiler           CUDA 11.7
detectron2 arch flags   e:\projects\layout\detrex\detectron2\detectron2\_C.cp37-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          537.13
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7
Pillow                  9.3.0
torchvision             0.14.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision
torchvision arch flags  C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[01/08 04:21:04] detectron2 INFO: Command line arguments: Namespace(config_file='projects/deformable_detr/configs/deformable_detr_r50_50ep.py', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/08 04:21:04] detectron2 INFO: Contents of args.config_file=projects/deformable_detr/configs/deformable_detr_r50_50ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdeformable_detr_r50[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;242m#dataloader = get_config("common/data/coco_detr.py").dataloader[39m
[38;5;15mdataloader[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/custom_zillow.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mdataloader[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mlr_multiplier_50ep[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mAdamW[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mtrain[39m

[38;5;242m# modify training config[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/deformable_detr_r50_50ep[39m[38;5;186m"[39m

[38;5;242m# max training iterations[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m375000[39m

[38;5;242m# run evaluation every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# log training infomation every 20 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20[39m

[38;5;242m# save checkpoint every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;242m# set training devices[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m

[38;5;242m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;242m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;242m# please notice that this is total batch size.[39m
[38;5;242m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;242m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;242m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m

[01/08 04:21:04] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/deformable_detr_r50_50ep\config.yaml is human-readable but cannot be loaded.
[01/08 04:21:04] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/deformable_detr_r50_50ep\config.yaml.pkl.
[01/08 04:21:04] detectron2 INFO: Full config saved to ./output/deformable_detr_r50_50ep\config.yaml
[01/08 04:21:04] d2.utils.env INFO: Using a generated random seed 4442612
[01/08 04:21:04] detectron2 INFO: Model:
DeformableDETR(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (position_embedding): PositionEmbeddingSine()
  (neck): ChannelMapper(
    (convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): ConvNormAct(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (2): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (extra_convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
  )
  (query_embedding): Embedding(300, 512)
  (transformer): DeformableDetrTransformer(
    (encoder): DeformableDetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (decoder): DeformableDetrTransformerDecoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
  )
  (bbox_embed): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (3): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (4): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (5): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): Criterion DeformableCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_bbox: 5.0
          cost_giou: 2.0
          cost_class_type: focal_loss_cost
          focal cost alpha: 0.25
          focal cost gamma: 2.0
      losses: ['class', 'boxes']
      loss_class_type: focal_loss
      weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0}
      num_classes: 80
      eos_coef: 0.1
      focal loss alpha: 0.25
      focal loss gamma: 2.0
)
[01/08 04:21:04] d2.data.datasets.coco INFO: Loaded 200 images in COCO format from ../anno/instances_train2017.json
[01/08 04:21:04] d2.data.build INFO: Removed 0 images with no usable annotations. 200 images left.
[01/08 04:21:04] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    door    | 428          |
|            |              |[0m
[01/08 04:21:04] d2.data.common INFO: Serializing 200 elements to byte tensors and concatenating them all ...
[01/08 04:21:04] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[01/08 04:21:04] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/08 04:21:16] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/08 04:21:16] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/08 04:21:16] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbbox_embed.0.layers.0.{bias, weight}[0m
[34mbbox_embed.0.layers.1.{bias, weight}[0m
[34mbbox_embed.0.layers.2.{bias, weight}[0m
[34mbbox_embed.1.layers.0.{bias, weight}[0m
[34mbbox_embed.1.layers.1.{bias, weight}[0m
[34mbbox_embed.1.layers.2.{bias, weight}[0m
[34mbbox_embed.2.layers.0.{bias, weight}[0m
[34mbbox_embed.2.layers.1.{bias, weight}[0m
[34mbbox_embed.2.layers.2.{bias, weight}[0m
[34mbbox_embed.3.layers.0.{bias, weight}[0m
[34mbbox_embed.3.layers.1.{bias, weight}[0m
[34mbbox_embed.3.layers.2.{bias, weight}[0m
[34mbbox_embed.4.layers.0.{bias, weight}[0m
[34mbbox_embed.4.layers.1.{bias, weight}[0m
[34mbbox_embed.4.layers.2.{bias, weight}[0m
[34mbbox_embed.5.layers.0.{bias, weight}[0m
[34mbbox_embed.5.layers.1.{bias, weight}[0m
[34mbbox_embed.5.layers.2.{bias, weight}[0m
[34mclass_embed.0.{bias, weight}[0m
[34mclass_embed.1.{bias, weight}[0m
[34mclass_embed.2.{bias, weight}[0m
[34mclass_embed.3.{bias, weight}[0m
[34mclass_embed.4.{bias, weight}[0m
[34mclass_embed.5.{bias, weight}[0m
[34mneck.convs.0.conv.{bias, weight}[0m
[34mneck.convs.0.norm.{bias, weight}[0m
[34mneck.convs.1.conv.{bias, weight}[0m
[34mneck.convs.1.norm.{bias, weight}[0m
[34mneck.convs.2.conv.{bias, weight}[0m
[34mneck.convs.2.norm.{bias, weight}[0m
[34mneck.extra_convs.0.conv.{bias, weight}[0m
[34mneck.extra_convs.0.norm.{bias, weight}[0m
[34mquery_embedding.weight[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.2.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.level_embeds[0m
[34mtransformer.reference_points.{bias, weight}[0m
[01/08 04:21:16] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/08 04:21:16] d2.engine.train_loop INFO: Starting training from iteration 0
[01/08 04:22:20] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "e:\projects\layout\detrex\detectron2\detectron2\engine\train_loop.py", line 149, in train
    self.run_step()
  File "tools/train_net.py", line 101, in run_step
    loss_dict = self.model(data)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_detr.py", line 193, in forward
    multi_level_feats, multi_level_masks, multi_level_position_embeddings, query_embeds
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 423, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 93, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\transformer.py", line 189, in forward
    query = self.ffns[ffn_index](query, identity if self.pre_norm else None)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\mlp.py", line 127, in forward
    out = self.layers(x)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\container.py", line 204, in forward
    input = module(input)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\container.py", line 204, in forward
    input = module(input)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\dropout.py", line 59, in forward
    return F.dropout(input, self.p, self.training, self.inplace)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\functional.py", line 1252, in dropout
    return _VF.dropout_(input, p, training) if inplace else _VF.dropout(input, p, training)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.14 GiB (GPU 0; 12.00 GiB total capacity; 40.45 GiB already allocated; 0 bytes free; 40.90 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/08 04:22:20] d2.engine.hooks INFO: Total training time: 0:01:03 (0:00:00 on hooks)
[01/08 04:22:20] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 41422M
[01/08 04:24:26] detectron2 INFO: Rank of current process: 0. World size: 1
[01/08 04:24:27] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.7.7 (default, Mar 23 2020, 23:19:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.21.6
detectron2              0.6 @e:\projects\layout\detrex\detectron2\detectron2
Compiler                MSVC 193632537
CUDA compiler           CUDA 11.7
detectron2 arch flags   e:\projects\layout\detrex\detectron2\detectron2\_C.cp37-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          537.13
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7
Pillow                  9.3.0
torchvision             0.14.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision
torchvision arch flags  C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[01/08 04:24:27] detectron2 INFO: Command line arguments: Namespace(config_file='projects/deformable_detr/configs/deformable_detr_r50_50ep.py', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/08 04:24:27] detectron2 INFO: Contents of args.config_file=projects/deformable_detr/configs/deformable_detr_r50_50ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdeformable_detr_r50[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;242m#dataloader = get_config("common/data/coco_detr.py").dataloader[39m
[38;5;15mdataloader[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/custom_zillow.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mdataloader[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mlr_multiplier_50ep[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mAdamW[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mtrain[39m

[38;5;242m# modify training config[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/deformable_detr_r50_50ep[39m[38;5;186m"[39m

[38;5;242m# max training iterations[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m375000[39m

[38;5;242m# run evaluation every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# log training infomation every 20 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20[39m

[38;5;242m# save checkpoint every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;242m# set training devices[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m

[38;5;242m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;242m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0[39m

[38;5;242m# please notice that this is total batch size.[39m
[38;5;242m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;242m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m16[39m

[38;5;242m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m

[01/08 04:24:27] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/deformable_detr_r50_50ep\config.yaml is human-readable but cannot be loaded.
[01/08 04:24:27] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/deformable_detr_r50_50ep\config.yaml.pkl.
[01/08 04:24:27] detectron2 INFO: Full config saved to ./output/deformable_detr_r50_50ep\config.yaml
[01/08 04:24:27] d2.utils.env INFO: Using a generated random seed 27444907
[01/08 04:24:27] detectron2 INFO: Model:
DeformableDETR(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (position_embedding): PositionEmbeddingSine()
  (neck): ChannelMapper(
    (convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): ConvNormAct(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (2): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (extra_convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
  )
  (query_embedding): Embedding(300, 512)
  (transformer): DeformableDetrTransformer(
    (encoder): DeformableDetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (decoder): DeformableDetrTransformerDecoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
  )
  (bbox_embed): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (3): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (4): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (5): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): Criterion DeformableCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_bbox: 5.0
          cost_giou: 2.0
          cost_class_type: focal_loss_cost
          focal cost alpha: 0.25
          focal cost gamma: 2.0
      losses: ['class', 'boxes']
      loss_class_type: focal_loss
      weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0}
      num_classes: 80
      eos_coef: 0.1
      focal loss alpha: 0.25
      focal loss gamma: 2.0
)
[01/08 04:24:27] d2.data.datasets.coco INFO: Loaded 200 images in COCO format from ../anno/instances_train2017.json
[01/08 04:24:27] d2.data.build INFO: Removed 0 images with no usable annotations. 200 images left.
[01/08 04:24:27] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    door    | 428          |
|            |              |[0m
[01/08 04:24:27] d2.data.common INFO: Serializing 200 elements to byte tensors and concatenating them all ...
[01/08 04:24:27] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[01/08 04:24:27] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/08 04:24:27] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/08 04:24:27] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/08 04:24:28] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbbox_embed.0.layers.0.{bias, weight}[0m
[34mbbox_embed.0.layers.1.{bias, weight}[0m
[34mbbox_embed.0.layers.2.{bias, weight}[0m
[34mbbox_embed.1.layers.0.{bias, weight}[0m
[34mbbox_embed.1.layers.1.{bias, weight}[0m
[34mbbox_embed.1.layers.2.{bias, weight}[0m
[34mbbox_embed.2.layers.0.{bias, weight}[0m
[34mbbox_embed.2.layers.1.{bias, weight}[0m
[34mbbox_embed.2.layers.2.{bias, weight}[0m
[34mbbox_embed.3.layers.0.{bias, weight}[0m
[34mbbox_embed.3.layers.1.{bias, weight}[0m
[34mbbox_embed.3.layers.2.{bias, weight}[0m
[34mbbox_embed.4.layers.0.{bias, weight}[0m
[34mbbox_embed.4.layers.1.{bias, weight}[0m
[34mbbox_embed.4.layers.2.{bias, weight}[0m
[34mbbox_embed.5.layers.0.{bias, weight}[0m
[34mbbox_embed.5.layers.1.{bias, weight}[0m
[34mbbox_embed.5.layers.2.{bias, weight}[0m
[34mclass_embed.0.{bias, weight}[0m
[34mclass_embed.1.{bias, weight}[0m
[34mclass_embed.2.{bias, weight}[0m
[34mclass_embed.3.{bias, weight}[0m
[34mclass_embed.4.{bias, weight}[0m
[34mclass_embed.5.{bias, weight}[0m
[34mneck.convs.0.conv.{bias, weight}[0m
[34mneck.convs.0.norm.{bias, weight}[0m
[34mneck.convs.1.conv.{bias, weight}[0m
[34mneck.convs.1.norm.{bias, weight}[0m
[34mneck.convs.2.conv.{bias, weight}[0m
[34mneck.convs.2.norm.{bias, weight}[0m
[34mneck.extra_convs.0.conv.{bias, weight}[0m
[34mneck.extra_convs.0.norm.{bias, weight}[0m
[34mquery_embedding.weight[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.2.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.level_embeds[0m
[34mtransformer.reference_points.{bias, weight}[0m
[01/08 04:24:28] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/08 04:24:28] d2.engine.train_loop INFO: Starting training from iteration 0
[01/08 04:24:40] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "e:\projects\layout\detrex\detectron2\detectron2\engine\train_loop.py", line 149, in train
    self.run_step()
  File "tools/train_net.py", line 101, in run_step
    loss_dict = self.model(data)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_detr.py", line 193, in forward
    multi_level_feats, multi_level_masks, multi_level_position_embeddings, query_embeds
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 423, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 93, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\transformer.py", line 189, in forward
    query = self.ffns[ffn_index](query, identity if self.pre_norm else None)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\mlp.py", line 127, in forward
    out = self.layers(x)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\container.py", line 204, in forward
    input = module(input)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\container.py", line 204, in forward
    input = module(input)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\linear.py", line 114, in forward
    return F.linear(input, self.weight, self.bias)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.36 GiB (GPU 0; 12.00 GiB total capacity; 40.34 GiB already allocated; 0 bytes free; 40.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/08 04:24:40] d2.engine.hooks INFO: Total training time: 0:00:12 (0:00:00 on hooks)
[01/08 04:24:40] d2.utils.events INFO:  iter: 0    lr: N/A  max_mem: 41999M
[01/08 04:26:21] detectron2 INFO: Rank of current process: 0. World size: 1
[01/08 04:26:21] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.7.7 (default, Mar 23 2020, 23:19:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.21.6
detectron2              0.6 @e:\projects\layout\detrex\detectron2\detectron2
Compiler                MSVC 193632537
CUDA compiler           CUDA 11.7
detectron2 arch flags   e:\projects\layout\detrex\detectron2\detectron2\_C.cp37-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          537.13
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7
Pillow                  9.3.0
torchvision             0.14.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision
torchvision arch flags  C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[01/08 04:26:21] detectron2 INFO: Command line arguments: Namespace(config_file='projects/deformable_detr/configs/deformable_detr_r50_50ep.py', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/08 04:26:21] detectron2 INFO: Contents of args.config_file=projects/deformable_detr/configs/deformable_detr_r50_50ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdeformable_detr_r50[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;242m#dataloader = get_config("common/data/coco_detr.py").dataloader[39m
[38;5;15mdataloader[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/custom_zillow.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mdataloader[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mlr_multiplier_50ep[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mAdamW[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mtrain[39m

[38;5;242m# modify training config[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/deformable_detr_r50_50ep[39m[38;5;186m"[39m

[38;5;242m# max training iterations[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m375000[39m

[38;5;242m# run evaluation every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# log training infomation every 20 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20[39m

[38;5;242m# save checkpoint every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;242m# set training devices[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m

[38;5;242m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;242m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0[39m

[38;5;242m# please notice that this is total batch size.[39m
[38;5;242m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;242m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m10[39m

[38;5;242m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m

[01/08 04:26:21] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/deformable_detr_r50_50ep\config.yaml is human-readable but cannot be loaded.
[01/08 04:26:21] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/deformable_detr_r50_50ep\config.yaml.pkl.
[01/08 04:26:21] detectron2 INFO: Full config saved to ./output/deformable_detr_r50_50ep\config.yaml
[01/08 04:26:21] d2.utils.env INFO: Using a generated random seed 21868720
[01/08 04:26:22] detectron2 INFO: Model:
DeformableDETR(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (position_embedding): PositionEmbeddingSine()
  (neck): ChannelMapper(
    (convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): ConvNormAct(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (2): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (extra_convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
  )
  (query_embedding): Embedding(300, 512)
  (transformer): DeformableDetrTransformer(
    (encoder): DeformableDetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (decoder): DeformableDetrTransformerDecoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
  )
  (bbox_embed): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (3): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (4): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (5): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): Criterion DeformableCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_bbox: 5.0
          cost_giou: 2.0
          cost_class_type: focal_loss_cost
          focal cost alpha: 0.25
          focal cost gamma: 2.0
      losses: ['class', 'boxes']
      loss_class_type: focal_loss
      weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0}
      num_classes: 80
      eos_coef: 0.1
      focal loss alpha: 0.25
      focal loss gamma: 2.0
)
[01/08 04:26:22] d2.data.datasets.coco INFO: Loaded 200 images in COCO format from ../anno/instances_train2017.json
[01/08 04:26:22] d2.data.build INFO: Removed 0 images with no usable annotations. 200 images left.
[01/08 04:26:22] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    door    | 428          |
|            |              |[0m
[01/08 04:26:22] d2.data.common INFO: Serializing 200 elements to byte tensors and concatenating them all ...
[01/08 04:26:22] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[01/08 04:26:22] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/08 04:26:22] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/08 04:26:22] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/08 04:26:22] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbbox_embed.0.layers.0.{bias, weight}[0m
[34mbbox_embed.0.layers.1.{bias, weight}[0m
[34mbbox_embed.0.layers.2.{bias, weight}[0m
[34mbbox_embed.1.layers.0.{bias, weight}[0m
[34mbbox_embed.1.layers.1.{bias, weight}[0m
[34mbbox_embed.1.layers.2.{bias, weight}[0m
[34mbbox_embed.2.layers.0.{bias, weight}[0m
[34mbbox_embed.2.layers.1.{bias, weight}[0m
[34mbbox_embed.2.layers.2.{bias, weight}[0m
[34mbbox_embed.3.layers.0.{bias, weight}[0m
[34mbbox_embed.3.layers.1.{bias, weight}[0m
[34mbbox_embed.3.layers.2.{bias, weight}[0m
[34mbbox_embed.4.layers.0.{bias, weight}[0m
[34mbbox_embed.4.layers.1.{bias, weight}[0m
[34mbbox_embed.4.layers.2.{bias, weight}[0m
[34mbbox_embed.5.layers.0.{bias, weight}[0m
[34mbbox_embed.5.layers.1.{bias, weight}[0m
[34mbbox_embed.5.layers.2.{bias, weight}[0m
[34mclass_embed.0.{bias, weight}[0m
[34mclass_embed.1.{bias, weight}[0m
[34mclass_embed.2.{bias, weight}[0m
[34mclass_embed.3.{bias, weight}[0m
[34mclass_embed.4.{bias, weight}[0m
[34mclass_embed.5.{bias, weight}[0m
[34mneck.convs.0.conv.{bias, weight}[0m
[34mneck.convs.0.norm.{bias, weight}[0m
[34mneck.convs.1.conv.{bias, weight}[0m
[34mneck.convs.1.norm.{bias, weight}[0m
[34mneck.convs.2.conv.{bias, weight}[0m
[34mneck.convs.2.norm.{bias, weight}[0m
[34mneck.extra_convs.0.conv.{bias, weight}[0m
[34mneck.extra_convs.0.norm.{bias, weight}[0m
[34mquery_embedding.weight[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.2.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.level_embeds[0m
[34mtransformer.reference_points.{bias, weight}[0m
[01/08 04:26:22] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/08 04:26:22] d2.engine.train_loop INFO: Starting training from iteration 0
[01/08 04:27:46] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "e:\projects\layout\detrex\detectron2\detectron2\engine\train_loop.py", line 149, in train
    self.run_step()
  File "tools/train_net.py", line 101, in run_step
    loss_dict = self.model(data)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_detr.py", line 193, in forward
    multi_level_feats, multi_level_masks, multi_level_position_embeddings, query_embeds
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 467, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 184, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\transformer.py", line 183, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\multi_scale_deform_attn.py", line 292, in forward
    value = value.masked_fill(key_padding_mask[..., None], float(0))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 268.00 MiB (GPU 0; 12.00 GiB total capacity; 40.71 GiB already allocated; 0 bytes free; 41.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/08 04:27:46] d2.engine.hooks INFO: Overall training speed: 1 iterations in 0:00:33 (33.9662 s / it)
[01/08 04:27:46] d2.engine.hooks INFO: Total training time: 0:00:33 (0:00:00 on hooks)
[01/08 04:27:46] d2.utils.events INFO:  eta: 94 days, 22:38:07  iter: 3  total_loss: 24.83  loss_class: 0.7892  loss_bbox: 1.385  loss_giou: 2  loss_class_0: 0.7549  loss_bbox_0: 1.43  loss_giou_0: 2  loss_class_1: 0.6627  loss_bbox_1: 1.433  loss_giou_1: 2  loss_class_2: 0.6549  loss_bbox_2: 1.409  loss_giou_2: 2.005  loss_class_3: 0.6813  loss_bbox_3: 1.363  loss_giou_3: 2  loss_class_4: 0.8274  loss_bbox_4: 1.395  loss_giou_4: 2  time: 21.8751  data_time: 0.5500  lr: 0.0001  max_mem: 41691M
[01/08 04:28:24] detectron2 INFO: Rank of current process: 0. World size: 1
[01/08 04:28:25] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.7.7 (default, Mar 23 2020, 23:19:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.21.6
detectron2              0.6 @e:\projects\layout\detrex\detectron2\detectron2
Compiler                MSVC 193632537
CUDA compiler           CUDA 11.7
detectron2 arch flags   e:\projects\layout\detrex\detectron2\detectron2\_C.cp37-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          537.13
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7
Pillow                  9.3.0
torchvision             0.14.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision
torchvision arch flags  C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[01/08 04:28:25] detectron2 INFO: Command line arguments: Namespace(config_file='projects/deformable_detr/configs/deformable_detr_r50_50ep.py', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/08 04:28:25] detectron2 INFO: Contents of args.config_file=projects/deformable_detr/configs/deformable_detr_r50_50ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdeformable_detr_r50[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;242m#dataloader = get_config("common/data/coco_detr.py").dataloader[39m
[38;5;15mdataloader[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/custom_zillow.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mdataloader[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mlr_multiplier_50ep[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mAdamW[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mtrain[39m

[38;5;242m# modify training config[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/deformable_detr_r50_50ep[39m[38;5;186m"[39m

[38;5;242m# max training iterations[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m375000[39m

[38;5;242m# run evaluation every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# log training infomation every 20 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20[39m

[38;5;242m# save checkpoint every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;242m# set training devices[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m

[38;5;242m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;242m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0[39m

[38;5;242m# please notice that this is total batch size.[39m
[38;5;242m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;242m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m10[39m

[38;5;242m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m

[01/08 04:28:25] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/deformable_detr_r50_50ep\config.yaml is human-readable but cannot be loaded.
[01/08 04:28:25] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/deformable_detr_r50_50ep\config.yaml.pkl.
[01/08 04:28:25] detectron2 INFO: Full config saved to ./output/deformable_detr_r50_50ep\config.yaml
[01/08 04:28:25] d2.utils.env INFO: Using a generated random seed 25243290
[01/08 04:28:25] detectron2 INFO: Model:
DeformableDETR(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (position_embedding): PositionEmbeddingSine()
  (neck): ChannelMapper(
    (convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): ConvNormAct(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (2): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (extra_convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
  )
  (query_embedding): Embedding(300, 512)
  (transformer): DeformableDetrTransformer(
    (encoder): DeformableDetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (decoder): DeformableDetrTransformerDecoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
  )
  (bbox_embed): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (3): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (4): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (5): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): Criterion DeformableCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_bbox: 5.0
          cost_giou: 2.0
          cost_class_type: focal_loss_cost
          focal cost alpha: 0.25
          focal cost gamma: 2.0
      losses: ['class', 'boxes']
      loss_class_type: focal_loss
      weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0}
      num_classes: 80
      eos_coef: 0.1
      focal loss alpha: 0.25
      focal loss gamma: 2.0
)
[01/08 04:28:25] d2.data.datasets.coco INFO: Loaded 200 images in COCO format from ../anno/instances_train2017.json
[01/08 04:28:25] d2.data.build INFO: Removed 0 images with no usable annotations. 200 images left.
[01/08 04:28:25] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    door    | 428          |
|            |              |[0m
[01/08 04:28:25] d2.data.common INFO: Serializing 200 elements to byte tensors and concatenating them all ...
[01/08 04:28:25] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[01/08 04:28:25] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/08 04:28:25] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/08 04:28:25] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/08 04:28:25] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbbox_embed.0.layers.0.{bias, weight}[0m
[34mbbox_embed.0.layers.1.{bias, weight}[0m
[34mbbox_embed.0.layers.2.{bias, weight}[0m
[34mbbox_embed.1.layers.0.{bias, weight}[0m
[34mbbox_embed.1.layers.1.{bias, weight}[0m
[34mbbox_embed.1.layers.2.{bias, weight}[0m
[34mbbox_embed.2.layers.0.{bias, weight}[0m
[34mbbox_embed.2.layers.1.{bias, weight}[0m
[34mbbox_embed.2.layers.2.{bias, weight}[0m
[34mbbox_embed.3.layers.0.{bias, weight}[0m
[34mbbox_embed.3.layers.1.{bias, weight}[0m
[34mbbox_embed.3.layers.2.{bias, weight}[0m
[34mbbox_embed.4.layers.0.{bias, weight}[0m
[34mbbox_embed.4.layers.1.{bias, weight}[0m
[34mbbox_embed.4.layers.2.{bias, weight}[0m
[34mbbox_embed.5.layers.0.{bias, weight}[0m
[34mbbox_embed.5.layers.1.{bias, weight}[0m
[34mbbox_embed.5.layers.2.{bias, weight}[0m
[34mclass_embed.0.{bias, weight}[0m
[34mclass_embed.1.{bias, weight}[0m
[34mclass_embed.2.{bias, weight}[0m
[34mclass_embed.3.{bias, weight}[0m
[34mclass_embed.4.{bias, weight}[0m
[34mclass_embed.5.{bias, weight}[0m
[34mneck.convs.0.conv.{bias, weight}[0m
[34mneck.convs.0.norm.{bias, weight}[0m
[34mneck.convs.1.conv.{bias, weight}[0m
[34mneck.convs.1.norm.{bias, weight}[0m
[34mneck.convs.2.conv.{bias, weight}[0m
[34mneck.convs.2.norm.{bias, weight}[0m
[34mneck.extra_convs.0.conv.{bias, weight}[0m
[34mneck.extra_convs.0.norm.{bias, weight}[0m
[34mquery_embedding.weight[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.2.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.level_embeds[0m
[34mtransformer.reference_points.{bias, weight}[0m
[01/08 04:28:25] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/08 04:28:25] d2.engine.train_loop INFO: Starting training from iteration 0
[01/08 04:32:48] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "e:\projects\layout\detrex\detectron2\detectron2\engine\train_loop.py", line 149, in train
    self.run_step()
  File "tools/train_net.py", line 101, in run_step
    loss_dict = self.model(data)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_detr.py", line 193, in forward
    multi_level_feats, multi_level_masks, multi_level_position_embeddings, query_embeds
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 467, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 184, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\transformer.py", line 183, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\multi_scale_deform_attn.py", line 292, in forward
    value = value.masked_fill(key_padding_mask[..., None], float(0))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 278.00 MiB (GPU 0; 12.00 GiB total capacity; 40.77 GiB already allocated; 0 bytes free; 41.41 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/08 04:32:48] d2.engine.hooks INFO: Overall training speed: 7 iterations in 0:03:31 (30.1705 s / it)
[01/08 04:32:48] d2.engine.hooks INFO: Total training time: 0:03:31 (0:00:00 on hooks)
[01/08 04:32:48] d2.utils.events INFO:  eta: 129 days, 11:36:11  iter: 9  total_loss: 23.92  loss_class: 0.6129  loss_bbox: 1.39  loss_giou: 2.003  loss_class_0: 0.5774  loss_bbox_0: 1.409  loss_giou_0: 2.005  loss_class_1: 0.6011  loss_bbox_1: 1.393  loss_giou_1: 2.005  loss_class_2: 0.5759  loss_bbox_2: 1.379  loss_giou_2: 2  loss_class_3: 0.6004  loss_bbox_3: 1.378  loss_giou_3: 2  loss_class_4: 0.6471  loss_bbox_4: 1.372  loss_giou_4: 2.004  time: 28.3611  data_time: 0.5098  lr: 0.0001  max_mem: 41752M
[01/08 22:32:25] detectron2 INFO: Rank of current process: 0. World size: 1
[01/08 22:32:25] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.7.7 (default, Mar 23 2020, 23:19:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.21.6
detectron2              0.6 @e:\projects\layout\detrex\detectron2\detectron2
Compiler                MSVC 193632537
CUDA compiler           CUDA 11.7
detectron2 arch flags   e:\projects\layout\detrex\detectron2\detectron2\_C.cp37-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          537.13
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7
Pillow                  9.3.0
torchvision             0.14.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision
torchvision arch flags  C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[01/08 22:32:25] detectron2 INFO: Command line arguments: Namespace(config_file='projects/deformable_detr/configs/deformable_detr_r50_50ep.py', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/08 22:32:25] detectron2 INFO: Contents of args.config_file=projects/deformable_detr/configs/deformable_detr_r50_50ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdeformable_detr_r50[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;242m#dataloader = get_config("common/data/coco_detr.py").dataloader[39m
[38;5;15mdataloader[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/custom_zillow.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mdataloader[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mlr_multiplier_50ep[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mAdamW[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mtrain[39m

[38;5;242m# modify training config[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/deformable_detr_r50_50ep[39m[38;5;186m"[39m

[38;5;242m# max training iterations[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m375000[39m

[38;5;242m# run evaluation every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# log training infomation every 20 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20[39m

[38;5;242m# save checkpoint every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;242m# set training devices[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m

[38;5;242m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;242m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0[39m

[38;5;242m# please notice that this is total batch size.[39m
[38;5;242m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;242m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m10[39m

[38;5;242m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m

[01/08 22:32:25] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/deformable_detr_r50_50ep\config.yaml is human-readable but cannot be loaded.
[01/08 22:32:25] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/deformable_detr_r50_50ep\config.yaml.pkl.
[01/08 22:32:25] detectron2 INFO: Full config saved to ./output/deformable_detr_r50_50ep\config.yaml
[01/08 22:32:25] d2.utils.env INFO: Using a generated random seed 25749031
[01/08 22:32:25] detectron2 INFO: Model:
DeformableDETR(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (position_embedding): PositionEmbeddingSine()
  (neck): ChannelMapper(
    (convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): ConvNormAct(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (2): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (extra_convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
  )
  (query_embedding): Embedding(300, 512)
  (transformer): DeformableDetrTransformer(
    (encoder): DeformableDetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (decoder): DeformableDetrTransformerDecoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
  )
  (bbox_embed): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (3): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (4): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (5): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): Criterion DeformableCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_bbox: 5.0
          cost_giou: 2.0
          cost_class_type: focal_loss_cost
          focal cost alpha: 0.25
          focal cost gamma: 2.0
      losses: ['class', 'boxes']
      loss_class_type: focal_loss
      weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0}
      num_classes: 80
      eos_coef: 0.1
      focal loss alpha: 0.25
      focal loss gamma: 2.0
)
[01/08 22:32:26] d2.data.datasets.coco INFO: Loaded 200 images in COCO format from ../anno/instances_train2017.json
[01/08 22:32:26] d2.data.build INFO: Removed 0 images with no usable annotations. 200 images left.
[01/08 22:32:26] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    door    | 428          |
|            |              |[0m
[01/08 22:32:26] d2.data.common INFO: Serializing 200 elements to byte tensors and concatenating them all ...
[01/08 22:32:26] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[01/08 22:32:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/08 22:32:26] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/08 22:32:26] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/08 22:32:26] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbbox_embed.0.layers.0.{bias, weight}[0m
[34mbbox_embed.0.layers.1.{bias, weight}[0m
[34mbbox_embed.0.layers.2.{bias, weight}[0m
[34mbbox_embed.1.layers.0.{bias, weight}[0m
[34mbbox_embed.1.layers.1.{bias, weight}[0m
[34mbbox_embed.1.layers.2.{bias, weight}[0m
[34mbbox_embed.2.layers.0.{bias, weight}[0m
[34mbbox_embed.2.layers.1.{bias, weight}[0m
[34mbbox_embed.2.layers.2.{bias, weight}[0m
[34mbbox_embed.3.layers.0.{bias, weight}[0m
[34mbbox_embed.3.layers.1.{bias, weight}[0m
[34mbbox_embed.3.layers.2.{bias, weight}[0m
[34mbbox_embed.4.layers.0.{bias, weight}[0m
[34mbbox_embed.4.layers.1.{bias, weight}[0m
[34mbbox_embed.4.layers.2.{bias, weight}[0m
[34mbbox_embed.5.layers.0.{bias, weight}[0m
[34mbbox_embed.5.layers.1.{bias, weight}[0m
[34mbbox_embed.5.layers.2.{bias, weight}[0m
[34mclass_embed.0.{bias, weight}[0m
[34mclass_embed.1.{bias, weight}[0m
[34mclass_embed.2.{bias, weight}[0m
[34mclass_embed.3.{bias, weight}[0m
[34mclass_embed.4.{bias, weight}[0m
[34mclass_embed.5.{bias, weight}[0m
[34mneck.convs.0.conv.{bias, weight}[0m
[34mneck.convs.0.norm.{bias, weight}[0m
[34mneck.convs.1.conv.{bias, weight}[0m
[34mneck.convs.1.norm.{bias, weight}[0m
[34mneck.convs.2.conv.{bias, weight}[0m
[34mneck.convs.2.norm.{bias, weight}[0m
[34mneck.extra_convs.0.conv.{bias, weight}[0m
[34mneck.extra_convs.0.norm.{bias, weight}[0m
[34mquery_embedding.weight[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.2.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.level_embeds[0m
[34mtransformer.reference_points.{bias, weight}[0m
[01/08 22:32:26] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/08 22:32:26] d2.engine.train_loop INFO: Starting training from iteration 0
[01/08 22:32:59] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "e:\projects\layout\detrex\detectron2\detectron2\engine\train_loop.py", line 149, in train
    self.run_step()
  File "tools/train_net.py", line 101, in run_step
    loss_dict = self.model(data)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_detr.py", line 193, in forward
    multi_level_feats, multi_level_masks, multi_level_position_embeddings, query_embeds
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 467, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 184, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\transformer.py", line 183, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\multi_scale_deform_attn.py", line 292, in forward
    value = value.masked_fill(key_padding_mask[..., None], float(0))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 256.00 MiB (GPU 0; 12.00 GiB total capacity; 38.80 GiB already allocated; 0 bytes free; 41.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/08 22:32:59] d2.engine.hooks INFO: Total training time: 0:00:11 (0:00:00 on hooks)
[01/08 22:32:59] d2.utils.events INFO:  iter: 1  total_loss: 27.79  loss_class: 1.417  loss_bbox: 1.405  loss_giou: 2  loss_class_0: 0.9045  loss_bbox_0: 1.471  loss_giou_0: 2.043  loss_class_1: 0.9952  loss_bbox_1: 1.413  loss_giou_1: 2.002  loss_class_2: 1.215  loss_bbox_2: 1.383  loss_giou_2: 2  loss_class_3: 1.33  loss_bbox_3: 1.385  loss_giou_3: 2  loss_class_4: 1.43  loss_bbox_4: 1.395  loss_giou_4: 2  data_time: 0.4484  lr: 0.0001  max_mem: 39729M
[01/08 22:34:04] detectron2 INFO: Rank of current process: 0. World size: 1
[01/08 22:34:04] detectron2 INFO: Environment info:
----------------------  -----------------------------------------------------------------------------------------------
sys.platform            win32
Python                  3.7.7 (default, Mar 23 2020, 23:19:08) [MSC v.1916 64 bit (AMD64)]
numpy                   1.21.6
detectron2              0.6 @e:\projects\layout\detrex\detectron2\detectron2
Compiler                MSVC 193632537
CUDA compiler           CUDA 11.7
detectron2 arch flags   e:\projects\layout\detrex\detectron2\detectron2\_C.cp37-win_amd64.pyd; cannot find cuobjdump
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.13.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch
PyTorch debug build     False
GPU available           Yes
GPU 0                   NVIDIA GeForce RTX 3060 (arch=8.6)
Driver version          537.13
CUDA_HOME               C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.7
Pillow                  9.3.0
torchvision             0.14.1 @C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision
torchvision arch flags  C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torchvision\_C.pyd; cannot find cuobjdump
fvcore                  0.1.5.post20221221
iopath                  0.1.9
cv2                     4.8.0
----------------------  -----------------------------------------------------------------------------------------------
PyTorch built with:
  - C++ Version: 199711
  - MSVC 192829337
  - Intel(R) Math Kernel Library Version 2020.0.2 Product Build 20200624 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 2019
  - LAPACK is enabled (usually provided by MKL)
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.5.4
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=C:/cb/pytorch_1000000000000/work/tmp_bin/sccache-cl.exe, CXX_FLAGS=/DWIN32 /D_WINDOWS /GR /EHsc /w /bigobj -DUSE_PTHREADPOOL -openmp:experimental -IC:/cb/pytorch_1000000000000/work/mkl/include -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOCUPTI -DUSE_FBGEMM -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=OFF, USE_NNPACK=OFF, USE_OPENMP=ON, USE_ROCM=OFF, 

[01/08 22:34:04] detectron2 INFO: Command line arguments: Namespace(config_file='projects/deformable_detr/configs/deformable_detr_r50_50ep.py', dist_url='tcp://127.0.0.1:49153', eval_only=False, machine_rank=0, num_gpus=1, num_machines=1, opts=[], resume=False)
[01/08 22:34:04] detectron2 INFO: Contents of args.config_file=projects/deformable_detr/configs/deformable_detr_r50_50ep.py:
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15mdetrex[39m[38;5;15m.[39m[38;5;15mconfig[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mget_config[39m
[38;5;197mfrom[39m[38;5;15m [39m[38;5;15m.[39m[38;5;15mmodels[39m[38;5;15m.[39m[38;5;15mdeformable_detr_r50[39m[38;5;15m [39m[38;5;197mimport[39m[38;5;15m [39m[38;5;15mmodel[39m

[38;5;242m#dataloader = get_config("common/data/coco_detr.py").dataloader[39m
[38;5;15mdataloader[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/data/custom_zillow.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mdataloader[39m
[38;5;15mlr_multiplier[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/coco_schedule.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mlr_multiplier_50ep[39m
[38;5;15moptimizer[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/optim.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mAdamW[39m
[38;5;15mtrain[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mget_config[39m[38;5;15m([39m[38;5;186m"[39m[38;5;186mcommon/train.py[39m[38;5;186m"[39m[38;5;15m)[39m[38;5;197m.[39m[38;5;15mtrain[39m

[38;5;242m# modify training config[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15minit_checkpoint[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mdetectron2://ImageNetPretrained/torchvision/R-50.pkl[39m[38;5;186m"[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186m./output/deformable_detr_r50_50ep[39m[38;5;186m"[39m

[38;5;242m# max training iterations[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mmax_iter[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m375000[39m

[38;5;242m# run evaluation every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15meval_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# log training infomation every 20 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mlog_period[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m20[39m

[38;5;242m# save checkpoint every 5000 iters[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mcheckpointer[39m[38;5;197m.[39m[38;5;15mperiod[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m5000[39m

[38;5;242m# gradient clipping for training[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15menabled[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mTrue[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mmax_norm[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0.1[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mclip_grad[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mnorm_type[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m2[39m

[38;5;242m# set training devices[39m
[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mcuda[39m[38;5;186m"[39m
[38;5;15mmodel[39m[38;5;197m.[39m[38;5;15mdevice[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mdevice[39m

[38;5;242m# modify optimizer config[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mlr[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mbetas[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15m([39m[38;5;141m0.9[39m[38;5;15m,[39m[38;5;15m [39m[38;5;141m0.999[39m[38;5;15m)[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mweight_decay[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m1e-4[39m
[38;5;15moptimizer[39m[38;5;197m.[39m[38;5;15mparams[39m[38;5;197m.[39m[38;5;15mlr_factor_func[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;81mlambda[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m:[39m[38;5;15m [39m[38;5;141m0.1[39m[38;5;15m [39m[38;5;81mif[39m[38;5;15m [39m[38;5;186m"[39m[38;5;186mbackbone[39m[38;5;186m"[39m[38;5;15m [39m[38;5;197min[39m[38;5;15m [39m[38;5;15mmodule_name[39m[38;5;15m [39m[38;5;81melse[39m[38;5;15m [39m[38;5;141m1[39m

[38;5;242m# modify dataloader config[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mnum_workers[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m0[39m

[38;5;242m# please notice that this is total batch size.[39m
[38;5;242m# surpose you're using 4 gpus for training and the batch size for[39m
[38;5;242m# each gpu is 16/4 = 4[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15mtotal_batch_size[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;141m10[39m

[38;5;242m# dump the testing results into output_dir for visualization[39m
[38;5;15mdataloader[39m[38;5;197m.[39m[38;5;15mevaluator[39m[38;5;197m.[39m[38;5;15moutput_dir[39m[38;5;15m [39m[38;5;197m=[39m[38;5;15m [39m[38;5;15mtrain[39m[38;5;197m.[39m[38;5;15moutput_dir[39m

[01/08 22:34:04] d2.config.lazy WARNING: The config contains objects that cannot serialize to a valid yaml. ./output/deformable_detr_r50_50ep\config.yaml is human-readable but cannot be loaded.
[01/08 22:34:04] d2.config.lazy WARNING: Config is saved using cloudpickle at ./output/deformable_detr_r50_50ep\config.yaml.pkl.
[01/08 22:34:04] detectron2 INFO: Full config saved to ./output/deformable_detr_r50_50ep\config.yaml
[01/08 22:34:04] d2.utils.env INFO: Using a generated random seed 4454663
[01/08 22:34:04] detectron2 INFO: Model:
DeformableDETR(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (position_embedding): PositionEmbeddingSine()
  (neck): ChannelMapper(
    (convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (1): ConvNormAct(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
      (2): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
    (extra_convs): ModuleList(
      (0): ConvNormAct(
        (conv): Conv2d(2048, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): GroupNorm(32, 256, eps=1e-05, affine=True)
      )
    )
  )
  (query_embedding): Embedding(300, 512)
  (transformer): DeformableDetrTransformer(
    (encoder): DeformableDetrTransformerEncoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (decoder): DeformableDetrTransformerDecoder(
      (layers): ModuleList(
        (0): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (1): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (2): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (3): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (4): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
        (5): BaseTransformerLayer(
          (attentions): ModuleList(
            (0): MultiheadAttention(
              (attn): MultiheadAttention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)
              )
              (proj_drop): Dropout(p=0.0, inplace=False)
            )
            (1): MultiScaleDeformableAttention(
              (dropout): Dropout(p=0.1, inplace=False)
              (sampling_offsets): Linear(in_features=256, out_features=256, bias=True)
              (attention_weights): Linear(in_features=256, out_features=128, bias=True)
              (value_proj): Linear(in_features=256, out_features=256, bias=True)
              (output_proj): Linear(in_features=256, out_features=256, bias=True)
            )
          )
          (ffns): ModuleList(
            (0): FFN(
              (activation): ReLU(inplace=True)
              (layers): Sequential(
                (0): Sequential(
                  (0): Linear(in_features=256, out_features=1024, bias=True)
                  (1): ReLU(inplace=True)
                  (2): Dropout(p=0.1, inplace=False)
                )
                (1): Linear(in_features=1024, out_features=256, bias=True)
                (2): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (norms): ModuleList(
            (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
            (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          )
        )
      )
    )
    (reference_points): Linear(in_features=256, out_features=2, bias=True)
  )
  (class_embed): ModuleList(
    (0): Linear(in_features=256, out_features=80, bias=True)
    (1): Linear(in_features=256, out_features=80, bias=True)
    (2): Linear(in_features=256, out_features=80, bias=True)
    (3): Linear(in_features=256, out_features=80, bias=True)
    (4): Linear(in_features=256, out_features=80, bias=True)
    (5): Linear(in_features=256, out_features=80, bias=True)
  )
  (bbox_embed): ModuleList(
    (0): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (1): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (2): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (3): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (4): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
    (5): MLP(
      (layers): ModuleList(
        (0): Linear(in_features=256, out_features=256, bias=True)
        (1): Linear(in_features=256, out_features=256, bias=True)
        (2): Linear(in_features=256, out_features=4, bias=True)
      )
    )
  )
  (criterion): Criterion DeformableCriterion
      matcher: Matcher HungarianMatcher
          cost_class: 2.0
          cost_bbox: 5.0
          cost_giou: 2.0
          cost_class_type: focal_loss_cost
          focal cost alpha: 0.25
          focal cost gamma: 2.0
      losses: ['class', 'boxes']
      loss_class_type: focal_loss
      weight_dict: {'loss_class': 1.0, 'loss_bbox': 5.0, 'loss_giou': 2.0, 'loss_class_0': 1.0, 'loss_bbox_0': 5.0, 'loss_giou_0': 2.0, 'loss_class_1': 1.0, 'loss_bbox_1': 5.0, 'loss_giou_1': 2.0, 'loss_class_2': 1.0, 'loss_bbox_2': 5.0, 'loss_giou_2': 2.0, 'loss_class_3': 1.0, 'loss_bbox_3': 5.0, 'loss_giou_3': 2.0, 'loss_class_4': 1.0, 'loss_bbox_4': 5.0, 'loss_giou_4': 2.0, 'loss_class_enc': 1.0, 'loss_bbox_enc': 5.0, 'loss_giou_enc': 2.0}
      num_classes: 80
      eos_coef: 0.1
      focal loss alpha: 0.25
      focal loss gamma: 2.0
)
[01/08 22:34:04] d2.data.datasets.coco INFO: Loaded 200 images in COCO format from ../anno/instances_train2017.json
[01/08 22:34:04] d2.data.build INFO: Removed 0 images with no usable annotations. 200 images left.
[01/08 22:34:04] d2.data.build INFO: Distribution of instances among all 1 categories:
[36m|  category  | #instances   |
|:----------:|:-------------|
|    door    | 428          |
|            |              |[0m
[01/08 22:34:04] d2.data.common INFO: Serializing 200 elements to byte tensors and concatenating them all ...
[01/08 22:34:04] d2.data.common INFO: Serialized dataset takes 0.08 MiB
[01/08 22:34:04] fvcore.common.checkpoint INFO: [Checkpointer] Loading from detectron2://ImageNetPretrained/torchvision/R-50.pkl ...
[01/08 22:34:04] fvcore.common.checkpoint INFO: Reading a file from 'torchvision'
[01/08 22:34:04] d2.checkpoint.c2_model_loading INFO: Following weights matched with submodule backbone:
| Names in Model    | Names in Checkpoint                                                               | Shapes                                          |
|:------------------|:----------------------------------------------------------------------------------|:------------------------------------------------|
| res2.0.conv1.*    | res2.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,1,1)             |
| res2.0.conv2.*    | res2.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.0.conv3.*    | res2.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.0.shortcut.* | res2.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.1.conv1.*    | res2.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.1.conv2.*    | res2.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.1.conv3.*    | res2.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res2.2.conv1.*    | res2.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,256,1,1)            |
| res2.2.conv2.*    | res2.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (64,) (64,) (64,) (64,) (64,64,3,3)             |
| res2.2.conv3.*    | res2.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,64,1,1)        |
| res3.0.conv1.*    | res3.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,256,1,1)       |
| res3.0.conv2.*    | res3.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.0.conv3.*    | res3.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.0.shortcut.* | res3.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (512,) (512,) (512,) (512,) (512,256,1,1)       |
| res3.1.conv1.*    | res3.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.1.conv2.*    | res3.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.1.conv3.*    | res3.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.2.conv1.*    | res3.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.2.conv2.*    | res3.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.2.conv3.*    | res3.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res3.3.conv1.*    | res3.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,512,1,1)       |
| res3.3.conv2.*    | res3.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (128,) (128,) (128,) (128,) (128,128,3,3)       |
| res3.3.conv3.*    | res3.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,128,1,1)       |
| res4.0.conv1.*    | res4.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,512,1,1)       |
| res4.0.conv2.*    | res4.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.0.conv3.*    | res4.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.0.shortcut.* | res4.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (1024,) (1024,) (1024,) (1024,) (1024,512,1,1)  |
| res4.1.conv1.*    | res4.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.1.conv2.*    | res4.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.1.conv3.*    | res4.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.2.conv1.*    | res4.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.2.conv2.*    | res4.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.2.conv3.*    | res4.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.3.conv1.*    | res4.3.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.3.conv2.*    | res4.3.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.3.conv3.*    | res4.3.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.4.conv1.*    | res4.4.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.4.conv2.*    | res4.4.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.4.conv3.*    | res4.4.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res4.5.conv1.*    | res4.5.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,1024,1,1)      |
| res4.5.conv2.*    | res4.5.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (256,) (256,) (256,) (256,) (256,256,3,3)       |
| res4.5.conv3.*    | res4.5.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (1024,) (1024,) (1024,) (1024,) (1024,256,1,1)  |
| res5.0.conv1.*    | res5.0.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,1024,1,1)      |
| res5.0.conv2.*    | res5.0.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.0.conv3.*    | res5.0.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.0.shortcut.* | res5.0.shortcut.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight} | (2048,) (2048,) (2048,) (2048,) (2048,1024,1,1) |
| res5.1.conv1.*    | res5.1.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.1.conv2.*    | res5.1.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.1.conv3.*    | res5.1.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| res5.2.conv1.*    | res5.2.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,2048,1,1)      |
| res5.2.conv2.*    | res5.2.conv2.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (512,) (512,) (512,) (512,) (512,512,3,3)       |
| res5.2.conv3.*    | res5.2.conv3.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}    | (2048,) (2048,) (2048,) (2048,) (2048,512,1,1)  |
| stem.conv1.*      | stem.conv1.{norm.bias,norm.running_mean,norm.running_var,norm.weight,weight}      | (64,) (64,) (64,) (64,) (64,3,7,7)              |
[01/08 22:34:04] fvcore.common.checkpoint WARNING: Some model parameters or buffers are not found in the checkpoint:
[34mbbox_embed.0.layers.0.{bias, weight}[0m
[34mbbox_embed.0.layers.1.{bias, weight}[0m
[34mbbox_embed.0.layers.2.{bias, weight}[0m
[34mbbox_embed.1.layers.0.{bias, weight}[0m
[34mbbox_embed.1.layers.1.{bias, weight}[0m
[34mbbox_embed.1.layers.2.{bias, weight}[0m
[34mbbox_embed.2.layers.0.{bias, weight}[0m
[34mbbox_embed.2.layers.1.{bias, weight}[0m
[34mbbox_embed.2.layers.2.{bias, weight}[0m
[34mbbox_embed.3.layers.0.{bias, weight}[0m
[34mbbox_embed.3.layers.1.{bias, weight}[0m
[34mbbox_embed.3.layers.2.{bias, weight}[0m
[34mbbox_embed.4.layers.0.{bias, weight}[0m
[34mbbox_embed.4.layers.1.{bias, weight}[0m
[34mbbox_embed.4.layers.2.{bias, weight}[0m
[34mbbox_embed.5.layers.0.{bias, weight}[0m
[34mbbox_embed.5.layers.1.{bias, weight}[0m
[34mbbox_embed.5.layers.2.{bias, weight}[0m
[34mclass_embed.0.{bias, weight}[0m
[34mclass_embed.1.{bias, weight}[0m
[34mclass_embed.2.{bias, weight}[0m
[34mclass_embed.3.{bias, weight}[0m
[34mclass_embed.4.{bias, weight}[0m
[34mclass_embed.5.{bias, weight}[0m
[34mneck.convs.0.conv.{bias, weight}[0m
[34mneck.convs.0.norm.{bias, weight}[0m
[34mneck.convs.1.conv.{bias, weight}[0m
[34mneck.convs.1.norm.{bias, weight}[0m
[34mneck.convs.2.conv.{bias, weight}[0m
[34mneck.convs.2.norm.{bias, weight}[0m
[34mneck.extra_convs.0.conv.{bias, weight}[0m
[34mneck.extra_convs.0.norm.{bias, weight}[0m
[34mquery_embedding.weight[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.0.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.0.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.1.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.1.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.2.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.2.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.3.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.3.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.4.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.4.norms.2.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.out_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.0.attn.{in_proj_bias, in_proj_weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.attention_weights.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.output_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.sampling_offsets.{bias, weight}[0m
[34mtransformer.decoder.layers.5.attentions.1.value_proj.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.decoder.layers.5.norms.2.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.0.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.0.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.1.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.1.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.2.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.2.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.3.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.3.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.4.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.4.norms.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.attention_weights.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.output_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.sampling_offsets.{bias, weight}[0m
[34mtransformer.encoder.layers.5.attentions.0.value_proj.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.0.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.ffns.0.layers.1.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.0.{bias, weight}[0m
[34mtransformer.encoder.layers.5.norms.1.{bias, weight}[0m
[34mtransformer.level_embeds[0m
[34mtransformer.reference_points.{bias, weight}[0m
[01/08 22:34:04] fvcore.common.checkpoint WARNING: The checkpoint state_dict contains keys that are not used by the model:
  [35mstem.fc.{bias, weight}[0m
[01/08 22:34:04] d2.engine.train_loop INFO: Starting training from iteration 0
[01/08 22:37:04] d2.engine.train_loop ERROR: Exception during training:
Traceback (most recent call last):
  File "e:\projects\layout\detrex\detectron2\detectron2\engine\train_loop.py", line 149, in train
    self.run_step()
  File "tools/train_net.py", line 101, in run_step
    loss_dict = self.model(data)
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_detr.py", line 193, in forward
    multi_level_feats, multi_level_masks, multi_level_position_embeddings, query_embeds
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 467, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\projects\deformable_detr\modeling\deformable_transformer.py", line 184, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\transformer.py", line 183, in forward
    **kwargs,
  File "C:\Users\User\anaconda3\envs\Layout\lib\site-packages\torch\nn\modules\module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "e:\projects\layout\detrex\detrex\layers\multi_scale_deform_attn.py", line 292, in forward
    value = value.masked_fill(key_padding_mask[..., None], float(0))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 272.00 MiB (GPU 0; 12.00 GiB total capacity; 40.16 GiB already allocated; 0 bytes free; 41.31 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
[01/08 22:37:04] d2.engine.hooks INFO: Overall training speed: 5 iterations in 0:02:08 (25.7865 s / it)
[01/08 22:37:04] d2.engine.hooks INFO: Total training time: 0:02:08 (0:00:00 on hooks)
[01/08 22:37:04] d2.utils.events INFO:  eta: 94 days, 6:43:02  iter: 7  total_loss: 24.87  loss_class: 0.6657  loss_bbox: 1.412  loss_giou: 2.019  loss_class_0: 0.6539  loss_bbox_0: 1.462  loss_giou_0: 2.038  loss_class_1: 0.6162  loss_bbox_1: 1.447  loss_giou_1: 2.019  loss_class_2: 0.6581  loss_bbox_2: 1.409  loss_giou_2: 2.022  loss_class_3: 0.74  loss_bbox_3: 1.421  loss_giou_3: 2.02  loss_class_4: 0.6498  loss_bbox_4: 1.429  loss_giou_4: 2.015  time: 23.2820  data_time: 0.4869  lr: 0.0001  max_mem: 41126M
